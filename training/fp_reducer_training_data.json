[
  {
    "id": "LLM02_TP_0000",
    "category": "LLM02: Insecure Output",
    "severity": "MEDIUM",
    "confidence": 0.74,
    "description": "SQL built from LLM output (synthetic variation)",
    "file_path": "db/auto_sql.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0001",
    "category": "LLM09: Overreliance",
    "severity": "LOW",
    "confidence": 0.73,
    "description": "LLM summary emailed automatically (synthetic variation)",
    "file_path": "decision/approver.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0002",
    "category": "LLM10: Model Theft",
    "severity": "MEDIUM",
    "confidence": 0.83,
    "description": "Endpoint serves model weights (synthetic variation)",
    "file_path": "docs/model_export.md",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM01_FP_0003",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.45,
    "description": "Unit test fixture builds fake prompts (synthetic variation)",
    "file_path": "examples/prompts/prompt_injection.ipynb",
    "code_snippet": "def prompt_fixture(): return f'ignore rules {seed}'",
    "is_true_positive": false
  },
  {
    "id": "LLM06_TP_0004",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.94,
    "description": "LLM output with AWS key logged",
    "file_path": "notebooks/openai_quickstart.ipynb",
    "code_snippet": "logger.info(f'Key leaked: {response}')",
    "is_true_positive": true
  },
  {
    "id": "LLM01_FP_0005",
    "category": "LLM01: Prompt Injection",
    "severity": "LOW",
    "confidence": 0.55,
    "description": "Unit test fixture builds fake prompts",
    "file_path": "examples/prompts/prompt_injection.ipynb",
    "code_snippet": "def prompt_fixture(): return f'ignore rules {seed}'",
    "is_true_positive": false
  },
  {
    "id": "LLM10_FP_0006",
    "category": "LLM10: Model Theft",
    "severity": "HIGH",
    "confidence": 0.38,
    "description": "Docs describing scp export",
    "file_path": "api/completions.py",
    "code_snippet": "scp model.bin user@host",
    "is_true_positive": false
  },
  {
    "id": "LLM05_FP_0007",
    "category": "LLM05: Supply Chain",
    "severity": "MEDIUM",
    "confidence": 0.45,
    "description": "Docs show requirements snippet",
    "file_path": "models/loader.py",
    "code_snippet": "pip install torch==2.2.1",
    "is_true_positive": false
  },
  {
    "id": "LLM06_TP_0008",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.9,
    "description": "LLM output with AWS key logged",
    "file_path": "monitoring/logging.py",
    "code_snippet": "logger.info(f'Key leaked: {response}')",
    "is_true_positive": true
  },
  {
    "id": "LLM02_FP_0009",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.52,
    "description": "SQLAlchemy session.exec mistaken for exec (synthetic variation)",
    "file_path": "db/auto_sql.py",
    "code_snippet": "result = session.exec(select(User))",
    "is_true_positive": false
  },
  {
    "id": "LLM09_TP_0010",
    "category": "LLM09: Overreliance",
    "severity": "MEDIUM",
    "confidence": 0.93,
    "description": "LLM summary emailed automatically",
    "file_path": "decision/approver.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM07_TP_0011",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.88,
    "description": "Plugin executes shell command",
    "file_path": "plugins/registry.py",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM08_TP_0012",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.91,
    "description": "Agent transfers funds autonomously",
    "file_path": "agents/task_runner.py",
    "code_snippet": "bank.transfer(amount, destination, auto_execute=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0013",
    "category": "LLM10: Model Theft",
    "severity": "CRITICAL",
    "confidence": 0.73,
    "description": "Endpoint serves model weights (synthetic variation)",
    "file_path": "api/completions.py",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0014",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.81,
    "description": "LLM response executed via eval",
    "file_path": "docs/examples/output_handling.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM08_TP_0015",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.92,
    "description": "Agent transfers funds autonomously",
    "file_path": "agents/finance_agent.py",
    "code_snippet": "bank.transfer(amount, destination, auto_execute=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM05_TP_0016",
    "category": "LLM05: Supply Chain",
    "severity": "HIGH",
    "confidence": 0.97,
    "description": "Agent executes pip install from LLM",
    "file_path": "models/loader.py",
    "code_snippet": "subprocess.run(['pip', 'install', llm_pkg], check=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM09_FP_0017",
    "category": "LLM09: Overreliance",
    "severity": "LOW",
    "confidence": 0.49,
    "description": "Unit test asserting human review (synthetic variation)",
    "file_path": "workflows/email_broadcast.py",
    "code_snippet": "assert pipeline.requires_human_review is True",
    "is_true_positive": false
  },
  {
    "id": "LLM09_FP_0018",
    "category": "LLM09: Overreliance",
    "severity": "LOW",
    "confidence": 0.39,
    "description": "Unit test asserting human review",
    "file_path": "tests/workflows/test_review.py",
    "code_snippet": "assert pipeline.requires_human_review is True",
    "is_true_positive": false
  },
  {
    "id": "LLM05_TP_0019",
    "category": "LLM05: Supply Chain",
    "severity": "LOW",
    "confidence": 0.9,
    "description": "trust_remote_code=True on AutoModel",
    "file_path": "models/loader.py",
    "code_snippet": "AutoModel.from_pretrained(repo, trust_remote_code=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM09_FP_0020",
    "category": "LLM09: Overreliance",
    "severity": "HIGH",
    "confidence": 0.41,
    "description": "Workflow requires reviewer",
    "file_path": "tests/workflows/test_review.py",
    "code_snippet": "if not reviewer.signoff(result): return",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0021",
    "category": "LLM10: Model Theft",
    "severity": "HIGH",
    "confidence": 0.81,
    "description": "Endpoint serves model weights",
    "file_path": "api/completions.py",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0022",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.76,
    "description": "LLM output with AWS key logged",
    "file_path": "notebooks/openai_quickstart.ipynb",
    "code_snippet": "logger.info(f'Key leaked: {response}')",
    "is_true_positive": true
  },
  {
    "id": "LLM10_FP_0023",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.61,
    "description": "Signed URL enforced (synthetic variation)",
    "file_path": "api/models.py",
    "code_snippet": "return generate_signed_url('model.bin', expires=30)",
    "is_true_positive": false
  },
  {
    "id": "LLM02_FP_0024",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.44,
    "description": "Docs logging example output",
    "file_path": "agents/code_exec.py",
    "code_snippet": "print('LLM output:', response.text)",
    "is_true_positive": false
  },
  {
    "id": "LLM04_TP_0025",
    "category": "LLM04: Model Denial of Service",
    "severity": "CRITICAL",
    "confidence": 0.93,
    "description": "Async gather spawns many completions (synthetic variation)",
    "file_path": "services/parallel_runner.py",
    "code_snippet": "await asyncio.gather(*[call_llm(q) for q in queue])",
    "is_true_positive": true
  },
  {
    "id": "LLM02_FP_0026",
    "category": "LLM02: Insecure Output",
    "severity": "MEDIUM",
    "confidence": 0.52,
    "description": "Docs logging example output",
    "file_path": "docs/examples/output_handling.py",
    "code_snippet": "print('LLM output:', response.text)",
    "is_true_positive": false
  },
  {
    "id": "LLM02_TP_0027",
    "category": "LLM02: Insecure Output",
    "severity": "MEDIUM",
    "confidence": 0.75,
    "description": "SQL built from LLM output",
    "file_path": "agents/code_exec.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM03_TP_0028",
    "category": "LLM03: Training Poisoning",
    "severity": "MEDIUM",
    "confidence": 0.94,
    "description": "Weights loaded via pickle from user path (synthetic variation)",
    "file_path": "models/bert_wrapper.py",
    "code_snippet": "weights = pickle.load(open(model_path, 'rb'))",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0029",
    "category": "LLM09: Overreliance",
    "severity": "MEDIUM",
    "confidence": 0.75,
    "description": "Auto-approves compliance decision",
    "file_path": "decision/approver.py",
    "code_snippet": "if model.confidence > 0.2: return 'approved'",
    "is_true_positive": true
  },
  {
    "id": "LLM04_FP_0030",
    "category": "LLM04: Model Denial of Service",
    "severity": "MEDIUM",
    "confidence": 0.35,
    "description": "Single completion call flagged",
    "file_path": "services/parallel_runner.py",
    "code_snippet": "client.chat.completions.create(model=MODEL, messages=msgs)",
    "is_true_positive": false
  },
  {
    "id": "LLM08_TP_0031",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.78,
    "description": "Agent executes system command",
    "file_path": "agents/task_runner.py",
    "code_snippet": "os.system(plan['action'])",
    "is_true_positive": true
  },
  {
    "id": "LLM10_FP_0032",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.37,
    "description": "Signed URL enforced",
    "file_path": "api/secure_download.py",
    "code_snippet": "return generate_signed_url('model.bin', expires=30)",
    "is_true_positive": false
  },
  {
    "id": "LLM09_TP_0033",
    "category": "LLM09: Overreliance",
    "severity": "LOW",
    "confidence": 0.87,
    "description": "Auto-approves compliance decision",
    "file_path": "workflows/email_broadcast.py",
    "code_snippet": "if model.confidence > 0.2: return 'approved'",
    "is_true_positive": true
  },
  {
    "id": "LLM04_TP_0034",
    "category": "LLM04: Model Denial of Service",
    "severity": "LOW",
    "confidence": 0.82,
    "description": "Unbounded while loop hitting OpenAI",
    "file_path": "workers/auto_refiner.py",
    "code_snippet": "while True:\n    client.chat.completions.create(... )",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0035",
    "category": "LLM09: Overreliance",
    "severity": "HIGH",
    "confidence": 0.77,
    "description": "LLM summary emailed automatically",
    "file_path": "workflows/email_broadcast.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM05_TP_0036",
    "category": "LLM05: Supply Chain",
    "severity": "CRITICAL",
    "confidence": 0.87,
    "description": "trust_remote_code=True on AutoModel",
    "file_path": "models/loader.py",
    "code_snippet": "AutoModel.from_pretrained(repo, trust_remote_code=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0037",
    "category": "LLM02: Insecure Output",
    "severity": "MEDIUM",
    "confidence": 0.96,
    "description": "LLM response executed via eval",
    "file_path": "app/repository.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM04_TP_0038",
    "category": "LLM04: Model Denial of Service",
    "severity": "HIGH",
    "confidence": 0.87,
    "description": "Unbounded while loop hitting OpenAI",
    "file_path": "tests/dos/test_rate_limit.py",
    "code_snippet": "while True:\n    client.chat.completions.create(... )",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0039",
    "category": "LLM09: Overreliance",
    "severity": "MEDIUM",
    "confidence": 0.77,
    "description": "LLM summary emailed automatically",
    "file_path": "decision/approver.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0040",
    "category": "LLM09: Overreliance",
    "severity": "HIGH",
    "confidence": 0.76,
    "description": "LLM summary emailed automatically",
    "file_path": "workflows/email_broadcast.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM05_TP_0041",
    "category": "LLM05: Supply Chain",
    "severity": "LOW",
    "confidence": 0.88,
    "description": "Agent executes pip install from LLM",
    "file_path": "models/loader.py",
    "code_snippet": "subprocess.run(['pip', 'install', llm_pkg], check=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0042",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.91,
    "description": "Direct f-string injection into system prompt",
    "file_path": "tests/test_prompt_injection.py",
    "code_snippet": "messages = [{\"role\": \"system\", \"content\": f'Policy: {user_input}'}]",
    "is_true_positive": true
  },
  {
    "id": "LLM07_FP_0043",
    "category": "LLM07: Insecure Plugin",
    "severity": "HIGH",
    "confidence": 0.68,
    "description": "Plugin registry enforces allowlist",
    "file_path": "plugins/shell_tool.py",
    "code_snippet": "if plugin_id not in ALLOWED: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM06_FP_0044",
    "category": "LLM06: Sensitive Info",
    "severity": "LOW",
    "confidence": 0.37,
    "description": "Env var reference",
    "file_path": "docs/assets/logo.py",
    "code_snippet": "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')",
    "is_true_positive": false
  },
  {
    "id": "LLM01_FP_0045",
    "category": "LLM01: Prompt Injection",
    "severity": "HIGH",
    "confidence": 0.39,
    "description": "Unit test fixture builds fake prompts",
    "file_path": "pipelines/langchain_agent.py",
    "code_snippet": "def prompt_fixture(): return f'ignore rules {seed}'",
    "is_true_positive": false
  },
  {
    "id": "LLM07_FP_0046",
    "category": "LLM07: Insecure Plugin",
    "severity": "LOW",
    "confidence": 0.71,
    "description": "Plugin registry enforces allowlist",
    "file_path": "plugins/manager.py",
    "code_snippet": "if plugin_id not in ALLOWED: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM07_TP_0047",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.77,
    "description": "Plugin zip downloaded from URL",
    "file_path": "docs/plugins.md",
    "code_snippet": "zip_ref.extractall('/opt/plugins')",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0048",
    "category": "LLM02: Insecure Output",
    "severity": "MEDIUM",
    "confidence": 0.76,
    "description": "LLM response executed via eval",
    "file_path": "docs/examples/output_handling.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0049",
    "category": "LLM06: Sensitive Info",
    "severity": "LOW",
    "confidence": 0.88,
    "description": "Hardcoded OpenAI key",
    "file_path": "monitoring/logging.py",
    "code_snippet": "os.environ['OPENAI_API_KEY'] = 'sk-live-123456789'",
    "is_true_positive": true
  },
  {
    "id": "LLM05_FP_0050",
    "category": "LLM05: Supply Chain",
    "severity": "HIGH",
    "confidence": 0.54,
    "description": "Download guarded by sha256 verification",
    "file_path": "docs/getting_started.md",
    "code_snippet": "if sha256(data).hexdigest() != expected_hash: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM09_TP_0051",
    "category": "LLM09: Overreliance",
    "severity": "HIGH",
    "confidence": 0.75,
    "description": "Auto-approves compliance decision",
    "file_path": "decision/approver.py",
    "code_snippet": "if model.confidence > 0.2: return 'approved'",
    "is_true_positive": true
  },
  {
    "id": "LLM05_TP_0052",
    "category": "LLM05: Supply Chain",
    "severity": "HIGH",
    "confidence": 0.82,
    "description": "Agent executes pip install from LLM",
    "file_path": "docs/getting_started.md",
    "code_snippet": "subprocess.run(['pip', 'install', llm_pkg], check=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0053",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.9,
    "description": "LLM response executed via eval (synthetic variation)",
    "file_path": "app/repository.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM09_FP_0054",
    "category": "LLM09: Overreliance",
    "severity": "MEDIUM",
    "confidence": 0.38,
    "description": "Workflow requires reviewer",
    "file_path": "workflows/human_loop.py",
    "code_snippet": "if not reviewer.signoff(result): return",
    "is_true_positive": false
  },
  {
    "id": "LLM06_FP_0055",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.46,
    "description": "Env var reference",
    "file_path": "config/settings.py",
    "code_snippet": "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')",
    "is_true_positive": false
  },
  {
    "id": "LLM07_FP_0056",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.6,
    "description": "Plugin registry enforces allowlist",
    "file_path": "plugins/manager.py",
    "code_snippet": "if plugin_id not in ALLOWED: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM03_FP_0057",
    "category": "LLM03: Training Poisoning",
    "severity": "HIGH",
    "confidence": 0.66,
    "description": "model.eval() inference mode",
    "file_path": "models/bert_wrapper.py",
    "code_snippet": "self.model.eval()",
    "is_true_positive": false
  },
  {
    "id": "LLM04_TP_0058",
    "category": "LLM04: Model Denial of Service",
    "severity": "CRITICAL",
    "confidence": 0.82,
    "description": "Async gather spawns many completions (synthetic variation)",
    "file_path": "tests/dos/test_rate_limit.py",
    "code_snippet": "await asyncio.gather(*[call_llm(q) for q in queue])",
    "is_true_positive": true
  },
  {
    "id": "LLM08_FP_0059",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.54,
    "description": "Manual approval required",
    "file_path": "agents/finance_agent.py",
    "code_snippet": "if not require_human_confirmation(task): raise",
    "is_true_positive": false
  },
  {
    "id": "LLM06_TP_0060",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.93,
    "description": "Hardcoded OpenAI key (synthetic variation)",
    "file_path": "config/settings.py",
    "code_snippet": "os.environ['OPENAI_API_KEY'] = 'sk-live-123456789'",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0061",
    "category": "LLM01: Prompt Injection",
    "severity": "CRITICAL",
    "confidence": 0.82,
    "description": "LangChain template concatenates untrusted context",
    "file_path": "src/chatbot/services/conversation.py",
    "code_snippet": "template = ChatPromptTemplate.from_messages([(\"system\", ctx + prompt)])",
    "is_true_positive": true
  },
  {
    "id": "LLM04_FP_0062",
    "category": "LLM04: Model Denial of Service",
    "severity": "MEDIUM",
    "confidence": 0.44,
    "description": "Pytest simulating rate limit",
    "file_path": "tests/dos/test_rate_limit.py",
    "code_snippet": "for _ in range(5): client.chat.completions.create(... )",
    "is_true_positive": false
  },
  {
    "id": "LLM01_FP_0063",
    "category": "LLM01: Prompt Injection",
    "severity": "LOW",
    "confidence": 0.42,
    "description": "Unit test fixture builds fake prompts",
    "file_path": "examples/prompts/prompt_injection.ipynb",
    "code_snippet": "def prompt_fixture(): return f'ignore rules {seed}'",
    "is_true_positive": false
  },
  {
    "id": "LLM09_TP_0064",
    "category": "LLM09: Overreliance",
    "severity": "CRITICAL",
    "confidence": 0.74,
    "description": "Auto-approves compliance decision",
    "file_path": "decision/approver.py",
    "code_snippet": "if model.confidence > 0.2: return 'approved'",
    "is_true_positive": true
  },
  {
    "id": "LLM09_FP_0065",
    "category": "LLM09: Overreliance",
    "severity": "HIGH",
    "confidence": 0.65,
    "description": "Unit test asserting human review",
    "file_path": "tests/workflows/test_review.py",
    "code_snippet": "assert pipeline.requires_human_review is True",
    "is_true_positive": false
  },
  {
    "id": "LLM07_FP_0066",
    "category": "LLM07: Insecure Plugin",
    "severity": "HIGH",
    "confidence": 0.67,
    "description": "Docs describing plugin install",
    "file_path": "plugins/manager.py",
    "code_snippet": "Install shell plugin by running ./install.sh",
    "is_true_positive": false
  },
  {
    "id": "LLM04_FP_0067",
    "category": "LLM04: Model Denial of Service",
    "severity": "HIGH",
    "confidence": 0.44,
    "description": "Pytest simulating rate limit",
    "file_path": "tests/dos/test_rate_limit.py",
    "code_snippet": "for _ in range(5): client.chat.completions.create(... )",
    "is_true_positive": false
  },
  {
    "id": "LLM05_TP_0068",
    "category": "LLM05: Supply Chain",
    "severity": "LOW",
    "confidence": 0.74,
    "description": "Agent executes pip install from LLM (synthetic variation)",
    "file_path": "docs/getting_started.md",
    "code_snippet": "subprocess.run(['pip', 'install', llm_pkg], check=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM03_FP_0069",
    "category": "LLM03: Training Poisoning",
    "severity": "MEDIUM",
    "confidence": 0.47,
    "description": "torch random_split in tests",
    "file_path": "models/bert_wrapper.py",
    "code_snippet": "train, test = random_split(dataset, [80, 20])",
    "is_true_positive": false
  },
  {
    "id": "LLM01_TP_0070",
    "category": "LLM01: Prompt Injection",
    "severity": "LOW",
    "confidence": 0.94,
    "description": "LangChain template concatenates untrusted context",
    "file_path": "examples/prompts/prompt_injection.ipynb",
    "code_snippet": "template = ChatPromptTemplate.from_messages([(\"system\", ctx + prompt)])",
    "is_true_positive": true
  },
  {
    "id": "LLM07_TP_0071",
    "category": "LLM07: Insecure Plugin",
    "severity": "CRITICAL",
    "confidence": 0.94,
    "description": "Plugin zip downloaded from URL",
    "file_path": "plugins/registry.py",
    "code_snippet": "zip_ref.extractall('/opt/plugins')",
    "is_true_positive": true
  },
  {
    "id": "LLM07_TP_0072",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.78,
    "description": "Plugin executes shell command",
    "file_path": "docs/plugins.md",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM07_TP_0073",
    "category": "LLM07: Insecure Plugin",
    "severity": "CRITICAL",
    "confidence": 0.96,
    "description": "Plugin zip downloaded from URL",
    "file_path": "plugins/manager.py",
    "code_snippet": "zip_ref.extractall('/opt/plugins')",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0074",
    "category": "LLM09: Overreliance",
    "severity": "LOW",
    "confidence": 0.88,
    "description": "LLM summary emailed automatically (synthetic variation)",
    "file_path": "decision/approver.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM08_TP_0075",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.76,
    "description": "Agent executes system command",
    "file_path": "examples/autonomous_agent.md",
    "code_snippet": "os.system(plan['action'])",
    "is_true_positive": true
  },
  {
    "id": "LLM07_TP_0076",
    "category": "LLM07: Insecure Plugin",
    "severity": "LOW",
    "confidence": 0.83,
    "description": "Plugin zip downloaded from URL",
    "file_path": "plugins/registry.py",
    "code_snippet": "zip_ref.extractall('/opt/plugins')",
    "is_true_positive": true
  },
  {
    "id": "LLM01_FP_0077",
    "category": "LLM01: Prompt Injection",
    "severity": "HIGH",
    "confidence": 0.38,
    "description": "Example notebook demonstrates prompts",
    "file_path": "pipelines/langchain_agent.py",
    "code_snippet": "SYSTEM_PROMPT = 'Your name is {username}'",
    "is_true_positive": false
  },
  {
    "id": "LLM01_FP_0078",
    "category": "LLM01: Prompt Injection",
    "severity": "LOW",
    "confidence": 0.58,
    "description": "Unit test fixture builds fake prompts (synthetic variation)",
    "file_path": "pipelines/langchain_agent.py",
    "code_snippet": "def prompt_fixture(): return f'ignore rules {seed}'",
    "is_true_positive": false
  },
  {
    "id": "LLM08_FP_0079",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.44,
    "description": "Manual approval required",
    "file_path": "examples/autonomous_agent.md",
    "code_snippet": "if not require_human_confirmation(task): raise",
    "is_true_positive": false
  },
  {
    "id": "LLM10_FP_0080",
    "category": "LLM10: Model Theft",
    "severity": "MEDIUM",
    "confidence": 0.39,
    "description": "Signed URL enforced (synthetic variation)",
    "file_path": "api/completions.py",
    "code_snippet": "return generate_signed_url('model.bin', expires=30)",
    "is_true_positive": false
  },
  {
    "id": "LLM05_FP_0081",
    "category": "LLM05: Supply Chain",
    "severity": "HIGH",
    "confidence": 0.42,
    "description": "Download guarded by sha256 verification",
    "file_path": "security/downloader.py",
    "code_snippet": "if sha256(data).hexdigest() != expected_hash: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM04_TP_0082",
    "category": "LLM04: Model Denial of Service",
    "severity": "LOW",
    "confidence": 0.8,
    "description": "Async gather spawns many completions",
    "file_path": "workers/auto_refiner.py",
    "code_snippet": "await asyncio.gather(*[call_llm(q) for q in queue])",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0083",
    "category": "LLM06: Sensitive Info",
    "severity": "CRITICAL",
    "confidence": 0.93,
    "description": "LLM output with AWS key logged (synthetic variation)",
    "file_path": "notebooks/openai_quickstart.ipynb",
    "code_snippet": "logger.info(f'Key leaked: {response}')",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0084",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.42,
    "description": "Base64 image asset",
    "file_path": "monitoring/logging.py",
    "code_snippet": "LOGO = 'data:image/png;base64,iVBORw0KGgoAAAANS...'",
    "is_true_positive": false
  },
  {
    "id": "LLM05_FP_0085",
    "category": "LLM05: Supply Chain",
    "severity": "MEDIUM",
    "confidence": 0.66,
    "description": "Download guarded by sha256 verification",
    "file_path": "security/downloader.py",
    "code_snippet": "if sha256(data).hexdigest() != expected_hash: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM06_FP_0086",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.44,
    "description": "Env var reference",
    "file_path": "config/settings.py",
    "code_snippet": "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')",
    "is_true_positive": false
  },
  {
    "id": "LLM10_FP_0087",
    "category": "LLM10: Model Theft",
    "severity": "MEDIUM",
    "confidence": 0.66,
    "description": "Docs describing scp export (synthetic variation)",
    "file_path": "api/models.py",
    "code_snippet": "scp model.bin user@host",
    "is_true_positive": false
  },
  {
    "id": "LLM04_TP_0088",
    "category": "LLM04: Model Denial of Service",
    "severity": "HIGH",
    "confidence": 0.95,
    "description": "Async gather spawns many completions",
    "file_path": "routes/ask.py",
    "code_snippet": "await asyncio.gather(*[call_llm(q) for q in queue])",
    "is_true_positive": true
  },
  {
    "id": "LLM05_FP_0089",
    "category": "LLM05: Supply Chain",
    "severity": "LOW",
    "confidence": 0.62,
    "description": "Docs show requirements snippet",
    "file_path": "models/loader.py",
    "code_snippet": "pip install torch==2.2.1",
    "is_true_positive": false
  },
  {
    "id": "LLM04_FP_0090",
    "category": "LLM04: Model Denial of Service",
    "severity": "LOW",
    "confidence": 0.38,
    "description": "Pytest simulating rate limit (synthetic variation)",
    "file_path": "tests/dos/test_rate_limit.py",
    "code_snippet": "for _ in range(5): client.chat.completions.create(... )",
    "is_true_positive": false
  },
  {
    "id": "LLM04_TP_0091",
    "category": "LLM04: Model Denial of Service",
    "severity": "HIGH",
    "confidence": 0.82,
    "description": "Async gather spawns many completions",
    "file_path": "tests/dos/test_rate_limit.py",
    "code_snippet": "await asyncio.gather(*[call_llm(q) for q in queue])",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0092",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.77,
    "description": "LLM output with AWS key logged (synthetic variation)",
    "file_path": "config/settings.py",
    "code_snippet": "logger.info(f'Key leaked: {response}')",
    "is_true_positive": true
  },
  {
    "id": "LLM04_TP_0093",
    "category": "LLM04: Model Denial of Service",
    "severity": "MEDIUM",
    "confidence": 0.91,
    "description": "Unbounded while loop hitting OpenAI (synthetic variation)",
    "file_path": "services/parallel_runner.py",
    "code_snippet": "while True:\n    client.chat.completions.create(... )",
    "is_true_positive": true
  },
  {
    "id": "LLM10_FP_0094",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.46,
    "description": "Docs describing scp export",
    "file_path": "api/models.py",
    "code_snippet": "scp model.bin user@host",
    "is_true_positive": false
  },
  {
    "id": "LLM05_TP_0095",
    "category": "LLM05: Supply Chain",
    "severity": "LOW",
    "confidence": 0.97,
    "description": "trust_remote_code=True on AutoModel",
    "file_path": "docs/getting_started.md",
    "code_snippet": "AutoModel.from_pretrained(repo, trust_remote_code=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM03_FP_0096",
    "category": "LLM03: Training Poisoning",
    "severity": "LOW",
    "confidence": 0.56,
    "description": "model.eval() inference mode",
    "file_path": "training/data_loader.py",
    "code_snippet": "self.model.eval()",
    "is_true_positive": false
  },
  {
    "id": "LLM08_TP_0097",
    "category": "LLM08: Excessive Agency",
    "severity": "CRITICAL",
    "confidence": 0.73,
    "description": "Agent transfers funds autonomously (synthetic variation)",
    "file_path": "agents/controller.py",
    "code_snippet": "bank.transfer(amount, destination, auto_execute=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM08_TP_0098",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.93,
    "description": "Agent transfers funds autonomously",
    "file_path": "agents/task_runner.py",
    "code_snippet": "bank.transfer(amount, destination, auto_execute=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM02_FP_0099",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.57,
    "description": "SQLAlchemy session.exec mistaken for exec",
    "file_path": "docs/examples/output_handling.py",
    "code_snippet": "result = session.exec(select(User))",
    "is_true_positive": false
  },
  {
    "id": "LLM09_TP_0100",
    "category": "LLM09: Overreliance",
    "severity": "CRITICAL",
    "confidence": 0.79,
    "description": "LLM summary emailed automatically",
    "file_path": "workflows/human_loop.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM10_FP_0101",
    "category": "LLM10: Model Theft",
    "severity": "HIGH",
    "confidence": 0.43,
    "description": "Signed URL enforced",
    "file_path": "api/completions.py",
    "code_snippet": "return generate_signed_url('model.bin', expires=30)",
    "is_true_positive": false
  },
  {
    "id": "LLM03_TP_0102",
    "category": "LLM03: Training Poisoning",
    "severity": "LOW",
    "confidence": 0.81,
    "description": "Training data pulled from unsecured URL",
    "file_path": "training/load_weights.py",
    "code_snippet": "data = json.loads(requests.get(feed).text)",
    "is_true_positive": true
  },
  {
    "id": "LLM08_TP_0103",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.9,
    "description": "Agent transfers funds autonomously",
    "file_path": "agents/controller.py",
    "code_snippet": "bank.transfer(amount, destination, auto_execute=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM04_FP_0104",
    "category": "LLM04: Model Denial of Service",
    "severity": "LOW",
    "confidence": 0.55,
    "description": "Single completion call flagged",
    "file_path": "tests/dos/test_rate_limit.py",
    "code_snippet": "client.chat.completions.create(model=MODEL, messages=msgs)",
    "is_true_positive": false
  },
  {
    "id": "LLM05_FP_0105",
    "category": "LLM05: Supply Chain",
    "severity": "LOW",
    "confidence": 0.64,
    "description": "Docs show requirements snippet",
    "file_path": "models/loader.py",
    "code_snippet": "pip install torch==2.2.1",
    "is_true_positive": false
  },
  {
    "id": "LLM10_FP_0106",
    "category": "LLM10: Model Theft",
    "severity": "MEDIUM",
    "confidence": 0.6,
    "description": "Docs describing scp export",
    "file_path": "api/models.py",
    "code_snippet": "scp model.bin user@host",
    "is_true_positive": false
  },
  {
    "id": "LLM05_TP_0107",
    "category": "LLM05: Supply Chain",
    "severity": "LOW",
    "confidence": 0.87,
    "description": "Agent executes pip install from LLM",
    "file_path": "security/downloader.py",
    "code_snippet": "subprocess.run(['pip', 'install', llm_pkg], check=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0108",
    "category": "LLM06: Sensitive Info",
    "severity": "LOW",
    "confidence": 0.71,
    "description": "Env var reference",
    "file_path": "notebooks/openai_quickstart.ipynb",
    "code_snippet": "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')",
    "is_true_positive": false
  },
  {
    "id": "LLM10_FP_0109",
    "category": "LLM10: Model Theft",
    "severity": "HIGH",
    "confidence": 0.36,
    "description": "Signed URL enforced",
    "file_path": "api/secure_download.py",
    "code_snippet": "return generate_signed_url('model.bin', expires=30)",
    "is_true_positive": false
  },
  {
    "id": "LLM08_TP_0110",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.98,
    "description": "Agent executes system command",
    "file_path": "agents/controller.py",
    "code_snippet": "os.system(plan['action'])",
    "is_true_positive": true
  },
  {
    "id": "LLM08_FP_0111",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.47,
    "description": "Demo described in README",
    "file_path": "agents/controller.py",
    "code_snippet": "agent.run('book a flight')",
    "is_true_positive": false
  },
  {
    "id": "LLM03_TP_0112",
    "category": "LLM03: Training Poisoning",
    "severity": "CRITICAL",
    "confidence": 0.93,
    "description": "Weights loaded via pickle from user path",
    "file_path": "tests/fakes/datasets.py",
    "code_snippet": "weights = pickle.load(open(model_path, 'rb'))",
    "is_true_positive": true
  },
  {
    "id": "LLM08_TP_0113",
    "category": "LLM08: Excessive Agency",
    "severity": "LOW",
    "confidence": 0.97,
    "description": "Agent executes system command",
    "file_path": "agents/controller.py",
    "code_snippet": "os.system(plan['action'])",
    "is_true_positive": true
  },
  {
    "id": "LLM09_FP_0114",
    "category": "LLM09: Overreliance",
    "severity": "MEDIUM",
    "confidence": 0.37,
    "description": "Workflow requires reviewer",
    "file_path": "tests/workflows/test_review.py",
    "code_snippet": "if not reviewer.signoff(result): return",
    "is_true_positive": false
  },
  {
    "id": "LLM10_FP_0115",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.45,
    "description": "Docs describing scp export (synthetic variation)",
    "file_path": "api/models.py",
    "code_snippet": "scp model.bin user@host",
    "is_true_positive": false
  },
  {
    "id": "LLM05_TP_0116",
    "category": "LLM05: Supply Chain",
    "severity": "LOW",
    "confidence": 0.97,
    "description": "Agent executes pip install from LLM",
    "file_path": "models/loader.py",
    "code_snippet": "subprocess.run(['pip', 'install', llm_pkg], check=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM04_FP_0117",
    "category": "LLM04: Model Denial of Service",
    "severity": "HIGH",
    "confidence": 0.5,
    "description": "Pytest simulating rate limit (synthetic variation)",
    "file_path": "workers/auto_refiner.py",
    "code_snippet": "for _ in range(5): client.chat.completions.create(... )",
    "is_true_positive": false
  },
  {
    "id": "LLM02_TP_0118",
    "category": "LLM02: Insecure Output",
    "severity": "CRITICAL",
    "confidence": 0.96,
    "description": "LLM response executed via eval (synthetic variation)",
    "file_path": "db/auto_sql.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM05_TP_0119",
    "category": "LLM05: Supply Chain",
    "severity": "MEDIUM",
    "confidence": 0.83,
    "description": "Agent executes pip install from LLM (synthetic variation)",
    "file_path": "security/downloader.py",
    "code_snippet": "subprocess.run(['pip', 'install', llm_pkg], check=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM04_FP_0120",
    "category": "LLM04: Model Denial of Service",
    "severity": "MEDIUM",
    "confidence": 0.64,
    "description": "Single completion call flagged",
    "file_path": "workers/auto_refiner.py",
    "code_snippet": "client.chat.completions.create(model=MODEL, messages=msgs)",
    "is_true_positive": false
  },
  {
    "id": "LLM06_FP_0121",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.62,
    "description": "Base64 image asset",
    "file_path": "notebooks/openai_quickstart.ipynb",
    "code_snippet": "LOGO = 'data:image/png;base64,iVBORw0KGgoAAAANS...'",
    "is_true_positive": false
  },
  {
    "id": "LLM10_FP_0122",
    "category": "LLM10: Model Theft",
    "severity": "MEDIUM",
    "confidence": 0.55,
    "description": "Docs describing scp export",
    "file_path": "api/completions.py",
    "code_snippet": "scp model.bin user@host",
    "is_true_positive": false
  },
  {
    "id": "LLM09_FP_0123",
    "category": "LLM09: Overreliance",
    "severity": "MEDIUM",
    "confidence": 0.67,
    "description": "Unit test asserting human review",
    "file_path": "tests/workflows/test_review.py",
    "code_snippet": "assert pipeline.requires_human_review is True",
    "is_true_positive": false
  },
  {
    "id": "LLM04_FP_0124",
    "category": "LLM04: Model Denial of Service",
    "severity": "LOW",
    "confidence": 0.47,
    "description": "Single completion call flagged",
    "file_path": "tests/dos/test_rate_limit.py",
    "code_snippet": "client.chat.completions.create(model=MODEL, messages=msgs)",
    "is_true_positive": false
  },
  {
    "id": "LLM07_TP_0125",
    "category": "LLM07: Insecure Plugin",
    "severity": "LOW",
    "confidence": 0.74,
    "description": "Plugin executes shell command",
    "file_path": "docs/plugins.md",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0126",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.69,
    "description": "Base64 image asset (synthetic variation)",
    "file_path": "notebooks/openai_quickstart.ipynb",
    "code_snippet": "LOGO = 'data:image/png;base64,iVBORw0KGgoAAAANS...'",
    "is_true_positive": false
  },
  {
    "id": "LLM03_TP_0127",
    "category": "LLM03: Training Poisoning",
    "severity": "CRITICAL",
    "confidence": 0.92,
    "description": "Training data pulled from unsecured URL (synthetic variation)",
    "file_path": "training/data_loader.py",
    "code_snippet": "data = json.loads(requests.get(feed).text)",
    "is_true_positive": true
  },
  {
    "id": "LLM10_FP_0128",
    "category": "LLM10: Model Theft",
    "severity": "HIGH",
    "confidence": 0.67,
    "description": "Signed URL enforced",
    "file_path": "api/secure_download.py",
    "code_snippet": "return generate_signed_url('model.bin', expires=30)",
    "is_true_positive": false
  },
  {
    "id": "LLM06_FP_0129",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.38,
    "description": "Base64 image asset",
    "file_path": "notebooks/openai_quickstart.ipynb",
    "code_snippet": "LOGO = 'data:image/png;base64,iVBORw0KGgoAAAANS...'",
    "is_true_positive": false
  },
  {
    "id": "LLM05_FP_0130",
    "category": "LLM05: Supply Chain",
    "severity": "LOW",
    "confidence": 0.63,
    "description": "Docs show requirements snippet",
    "file_path": "security/downloader.py",
    "code_snippet": "pip install torch==2.2.1",
    "is_true_positive": false
  },
  {
    "id": "LLM02_TP_0131",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.79,
    "description": "SQL built from LLM output (synthetic variation)",
    "file_path": "agents/code_exec.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0132",
    "category": "LLM06: Sensitive Info",
    "severity": "CRITICAL",
    "confidence": 0.86,
    "description": "Hardcoded OpenAI key",
    "file_path": "monitoring/logging.py",
    "code_snippet": "os.environ['OPENAI_API_KEY'] = 'sk-live-123456789'",
    "is_true_positive": true
  },
  {
    "id": "LLM03_TP_0133",
    "category": "LLM03: Training Poisoning",
    "severity": "CRITICAL",
    "confidence": 0.96,
    "description": "Weights loaded via pickle from user path (synthetic variation)",
    "file_path": "training/load_weights.py",
    "code_snippet": "weights = pickle.load(open(model_path, 'rb'))",
    "is_true_positive": true
  },
  {
    "id": "LLM08_FP_0134",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.35,
    "description": "Demo described in README",
    "file_path": "agents/controller.py",
    "code_snippet": "agent.run('book a flight')",
    "is_true_positive": false
  },
  {
    "id": "LLM05_FP_0135",
    "category": "LLM05: Supply Chain",
    "severity": "MEDIUM",
    "confidence": 0.7,
    "description": "Docs show requirements snippet",
    "file_path": "models/loader.py",
    "code_snippet": "pip install torch==2.2.1",
    "is_true_positive": false
  },
  {
    "id": "LLM05_FP_0136",
    "category": "LLM05: Supply Chain",
    "severity": "MEDIUM",
    "confidence": 0.66,
    "description": "Download guarded by sha256 verification (synthetic variation)",
    "file_path": "docs/getting_started.md",
    "code_snippet": "if sha256(data).hexdigest() != expected_hash: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM07_FP_0137",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.56,
    "description": "Plugin registry enforces allowlist",
    "file_path": "plugins/manager.py",
    "code_snippet": "if plugin_id not in ALLOWED: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM05_TP_0138",
    "category": "LLM05: Supply Chain",
    "severity": "LOW",
    "confidence": 0.86,
    "description": "Agent executes pip install from LLM",
    "file_path": "docs/getting_started.md",
    "code_snippet": "subprocess.run(['pip', 'install', llm_pkg], check=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM01_FP_0139",
    "category": "LLM01: Prompt Injection",
    "severity": "LOW",
    "confidence": 0.57,
    "description": "Example notebook demonstrates prompts",
    "file_path": "tests/test_prompt_injection.py",
    "code_snippet": "SYSTEM_PROMPT = 'Your name is {username}'",
    "is_true_positive": false
  },
  {
    "id": "LLM04_FP_0140",
    "category": "LLM04: Model Denial of Service",
    "severity": "HIGH",
    "confidence": 0.59,
    "description": "Single completion call flagged",
    "file_path": "workers/auto_refiner.py",
    "code_snippet": "client.chat.completions.create(model=MODEL, messages=msgs)",
    "is_true_positive": false
  },
  {
    "id": "LLM08_TP_0141",
    "category": "LLM08: Excessive Agency",
    "severity": "LOW",
    "confidence": 0.95,
    "description": "Agent executes system command",
    "file_path": "agents/task_runner.py",
    "code_snippet": "os.system(plan['action'])",
    "is_true_positive": true
  },
  {
    "id": "LLM07_TP_0142",
    "category": "LLM07: Insecure Plugin",
    "severity": "HIGH",
    "confidence": 0.93,
    "description": "Plugin executes shell command (synthetic variation)",
    "file_path": "plugins/registry.py",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM08_FP_0143",
    "category": "LLM08: Excessive Agency",
    "severity": "LOW",
    "confidence": 0.52,
    "description": "Demo described in README (synthetic variation)",
    "file_path": "agents/controller.py",
    "code_snippet": "agent.run('book a flight')",
    "is_true_positive": false
  },
  {
    "id": "LLM04_FP_0144",
    "category": "LLM04: Model Denial of Service",
    "severity": "LOW",
    "confidence": 0.64,
    "description": "Pytest simulating rate limit (synthetic variation)",
    "file_path": "routes/ask.py",
    "code_snippet": "for _ in range(5): client.chat.completions.create(... )",
    "is_true_positive": false
  },
  {
    "id": "LLM09_TP_0145",
    "category": "LLM09: Overreliance",
    "severity": "CRITICAL",
    "confidence": 0.93,
    "description": "LLM summary emailed automatically",
    "file_path": "workflows/human_loop.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM02_FP_0146",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.68,
    "description": "Docs logging example output",
    "file_path": "agents/code_exec.py",
    "code_snippet": "print('LLM output:', response.text)",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0147",
    "category": "LLM10: Model Theft",
    "severity": "HIGH",
    "confidence": 0.88,
    "description": "Endpoint serves model weights (synthetic variation)",
    "file_path": "docs/model_export.md",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM01_FP_0148",
    "category": "LLM01: Prompt Injection",
    "severity": "LOW",
    "confidence": 0.39,
    "description": "Example notebook demonstrates prompts",
    "file_path": "examples/prompts/prompt_injection.ipynb",
    "code_snippet": "SYSTEM_PROMPT = 'Your name is {username}'",
    "is_true_positive": false
  },
  {
    "id": "LLM03_TP_0149",
    "category": "LLM03: Training Poisoning",
    "severity": "MEDIUM",
    "confidence": 0.95,
    "description": "Weights loaded via pickle from user path",
    "file_path": "models/bert_wrapper.py",
    "code_snippet": "weights = pickle.load(open(model_path, 'rb'))",
    "is_true_positive": true
  },
  {
    "id": "LLM08_FP_0150",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.49,
    "description": "Demo described in README",
    "file_path": "agents/finance_agent.py",
    "code_snippet": "agent.run('book a flight')",
    "is_true_positive": false
  },
  {
    "id": "LLM04_FP_0151",
    "category": "LLM04: Model Denial of Service",
    "severity": "HIGH",
    "confidence": 0.68,
    "description": "Single completion call flagged",
    "file_path": "routes/ask.py",
    "code_snippet": "client.chat.completions.create(model=MODEL, messages=msgs)",
    "is_true_positive": false
  },
  {
    "id": "LLM01_TP_0152",
    "category": "LLM01: Prompt Injection",
    "severity": "CRITICAL",
    "confidence": 0.73,
    "description": "Direct f-string injection into system prompt (synthetic variation)",
    "file_path": "src/chatbot/services/conversation.py",
    "code_snippet": "messages = [{\"role\": \"system\", \"content\": f'Policy: {user_input}'}]",
    "is_true_positive": true
  },
  {
    "id": "LLM10_FP_0153",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.72,
    "description": "Signed URL enforced",
    "file_path": "api/secure_download.py",
    "code_snippet": "return generate_signed_url('model.bin', expires=30)",
    "is_true_positive": false
  },
  {
    "id": "LLM04_TP_0154",
    "category": "LLM04: Model Denial of Service",
    "severity": "MEDIUM",
    "confidence": 0.79,
    "description": "Unbounded while loop hitting OpenAI (synthetic variation)",
    "file_path": "services/parallel_runner.py",
    "code_snippet": "while True:\n    client.chat.completions.create(... )",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0155",
    "category": "LLM10: Model Theft",
    "severity": "HIGH",
    "confidence": 0.92,
    "description": "Endpoint serves model weights (synthetic variation)",
    "file_path": "api/completions.py",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0156",
    "category": "LLM01: Prompt Injection",
    "severity": "HIGH",
    "confidence": 0.7,
    "description": "LangChain template concatenates untrusted context (synthetic variation)",
    "file_path": "pipelines/langchain_agent.py",
    "code_snippet": "template = ChatPromptTemplate.from_messages([(\"system\", ctx + prompt)])",
    "is_true_positive": true
  },
  {
    "id": "LLM03_FP_0157",
    "category": "LLM03: Training Poisoning",
    "severity": "MEDIUM",
    "confidence": 0.52,
    "description": "torch random_split in tests",
    "file_path": "training/data_loader.py",
    "code_snippet": "train, test = random_split(dataset, [80, 20])",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0158",
    "category": "LLM10: Model Theft",
    "severity": "HIGH",
    "confidence": 0.83,
    "description": "Endpoint serves model weights",
    "file_path": "api/models.py",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM01_FP_0159",
    "category": "LLM01: Prompt Injection",
    "severity": "HIGH",
    "confidence": 0.39,
    "description": "Example notebook demonstrates prompts",
    "file_path": "examples/prompts/prompt_injection.ipynb",
    "code_snippet": "SYSTEM_PROMPT = 'Your name is {username}'",
    "is_true_positive": false
  },
  {
    "id": "LLM08_TP_0160",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.72,
    "description": "Agent transfers funds autonomously (synthetic variation)",
    "file_path": "agents/controller.py",
    "code_snippet": "bank.transfer(amount, destination, auto_execute=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0161",
    "category": "LLM10: Model Theft",
    "severity": "HIGH",
    "confidence": 0.83,
    "description": "API exposes logprobs enabling extraction",
    "file_path": "docs/model_export.md",
    "code_snippet": "client.chat.completions.create(logprobs=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM02_FP_0162",
    "category": "LLM02: Insecure Output",
    "severity": "MEDIUM",
    "confidence": 0.52,
    "description": "SQLAlchemy session.exec mistaken for exec (synthetic variation)",
    "file_path": "db/auto_sql.py",
    "code_snippet": "result = session.exec(select(User))",
    "is_true_positive": false
  },
  {
    "id": "LLM06_FP_0163",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.39,
    "description": "Base64 image asset",
    "file_path": "docs/assets/logo.py",
    "code_snippet": "LOGO = 'data:image/png;base64,iVBORw0KGgoAAAANS...'",
    "is_true_positive": false
  },
  {
    "id": "LLM05_TP_0164",
    "category": "LLM05: Supply Chain",
    "severity": "LOW",
    "confidence": 0.73,
    "description": "trust_remote_code=True on AutoModel (synthetic variation)",
    "file_path": "security/downloader.py",
    "code_snippet": "AutoModel.from_pretrained(repo, trust_remote_code=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM07_TP_0165",
    "category": "LLM07: Insecure Plugin",
    "severity": "LOW",
    "confidence": 0.86,
    "description": "Plugin zip downloaded from URL",
    "file_path": "plugins/manager.py",
    "code_snippet": "zip_ref.extractall('/opt/plugins')",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0166",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.7,
    "description": "Base64 image asset",
    "file_path": "config/settings.py",
    "code_snippet": "LOGO = 'data:image/png;base64,iVBORw0KGgoAAAANS...'",
    "is_true_positive": false
  },
  {
    "id": "LLM01_FP_0167",
    "category": "LLM01: Prompt Injection",
    "severity": "LOW",
    "confidence": 0.56,
    "description": "Example notebook demonstrates prompts (synthetic variation)",
    "file_path": "tests/test_prompt_injection.py",
    "code_snippet": "SYSTEM_PROMPT = 'Your name is {username}'",
    "is_true_positive": false
  },
  {
    "id": "LLM08_TP_0168",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.73,
    "description": "Agent transfers funds autonomously (synthetic variation)",
    "file_path": "agents/controller.py",
    "code_snippet": "bank.transfer(amount, destination, auto_execute=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM04_FP_0169",
    "category": "LLM04: Model Denial of Service",
    "severity": "LOW",
    "confidence": 0.42,
    "description": "Single completion call flagged",
    "file_path": "routes/ask.py",
    "code_snippet": "client.chat.completions.create(model=MODEL, messages=msgs)",
    "is_true_positive": false
  },
  {
    "id": "LLM05_FP_0170",
    "category": "LLM05: Supply Chain",
    "severity": "LOW",
    "confidence": 0.67,
    "description": "Download guarded by sha256 verification",
    "file_path": "models/loader.py",
    "code_snippet": "if sha256(data).hexdigest() != expected_hash: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM07_TP_0171",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.81,
    "description": "Plugin executes shell command",
    "file_path": "plugins/shell_tool.py",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM03_TP_0172",
    "category": "LLM03: Training Poisoning",
    "severity": "LOW",
    "confidence": 0.74,
    "description": "Weights loaded via pickle from user path",
    "file_path": "training/data_loader.py",
    "code_snippet": "weights = pickle.load(open(model_path, 'rb'))",
    "is_true_positive": true
  },
  {
    "id": "LLM01_FP_0173",
    "category": "LLM01: Prompt Injection",
    "severity": "HIGH",
    "confidence": 0.51,
    "description": "Example notebook demonstrates prompts",
    "file_path": "examples/prompts/prompt_injection.ipynb",
    "code_snippet": "SYSTEM_PROMPT = 'Your name is {username}'",
    "is_true_positive": false
  },
  {
    "id": "LLM07_TP_0174",
    "category": "LLM07: Insecure Plugin",
    "severity": "CRITICAL",
    "confidence": 0.73,
    "description": "Plugin executes shell command",
    "file_path": "plugins/registry.py",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0175",
    "category": "LLM10: Model Theft",
    "severity": "MEDIUM",
    "confidence": 0.81,
    "description": "API exposes logprobs enabling extraction",
    "file_path": "api/models.py",
    "code_snippet": "client.chat.completions.create(logprobs=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0176",
    "category": "LLM01: Prompt Injection",
    "severity": "HIGH",
    "confidence": 0.78,
    "description": "Direct f-string injection into system prompt (synthetic variation)",
    "file_path": "pipelines/langchain_agent.py",
    "code_snippet": "messages = [{\"role\": \"system\", \"content\": f'Policy: {user_input}'}]",
    "is_true_positive": true
  },
  {
    "id": "LLM08_FP_0177",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.55,
    "description": "Manual approval required (synthetic variation)",
    "file_path": "agents/task_runner.py",
    "code_snippet": "if not require_human_confirmation(task): raise",
    "is_true_positive": false
  },
  {
    "id": "LLM09_FP_0178",
    "category": "LLM09: Overreliance",
    "severity": "MEDIUM",
    "confidence": 0.67,
    "description": "Unit test asserting human review (synthetic variation)",
    "file_path": "decision/approver.py",
    "code_snippet": "assert pipeline.requires_human_review is True",
    "is_true_positive": false
  },
  {
    "id": "LLM01_TP_0179",
    "category": "LLM01: Prompt Injection",
    "severity": "CRITICAL",
    "confidence": 0.86,
    "description": "Direct f-string injection into system prompt",
    "file_path": "tests/test_prompt_injection.py",
    "code_snippet": "messages = [{\"role\": \"system\", \"content\": f'Policy: {user_input}'}]",
    "is_true_positive": true
  },
  {
    "id": "LLM07_TP_0180",
    "category": "LLM07: Insecure Plugin",
    "severity": "HIGH",
    "confidence": 0.75,
    "description": "Plugin zip downloaded from URL",
    "file_path": "plugins/shell_tool.py",
    "code_snippet": "zip_ref.extractall('/opt/plugins')",
    "is_true_positive": true
  },
  {
    "id": "LLM08_FP_0181",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.66,
    "description": "Demo described in README (synthetic variation)",
    "file_path": "agents/finance_agent.py",
    "code_snippet": "agent.run('book a flight')",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0182",
    "category": "LLM10: Model Theft",
    "severity": "HIGH",
    "confidence": 0.91,
    "description": "Endpoint serves model weights (synthetic variation)",
    "file_path": "docs/model_export.md",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM03_TP_0183",
    "category": "LLM03: Training Poisoning",
    "severity": "HIGH",
    "confidence": 0.8,
    "description": "Training data pulled from unsecured URL",
    "file_path": "training/load_weights.py",
    "code_snippet": "data = json.loads(requests.get(feed).text)",
    "is_true_positive": true
  },
  {
    "id": "LLM03_TP_0184",
    "category": "LLM03: Training Poisoning",
    "severity": "MEDIUM",
    "confidence": 0.75,
    "description": "Training data pulled from unsecured URL (synthetic variation)",
    "file_path": "tests/fakes/datasets.py",
    "code_snippet": "data = json.loads(requests.get(feed).text)",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0185",
    "category": "LLM02: Insecure Output",
    "severity": "CRITICAL",
    "confidence": 0.89,
    "description": "SQL built from LLM output",
    "file_path": "docs/examples/output_handling.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0186",
    "category": "LLM10: Model Theft",
    "severity": "CRITICAL",
    "confidence": 0.72,
    "description": "API exposes logprobs enabling extraction",
    "file_path": "api/completions.py",
    "code_snippet": "client.chat.completions.create(logprobs=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM05_FP_0187",
    "category": "LLM05: Supply Chain",
    "severity": "HIGH",
    "confidence": 0.38,
    "description": "Docs show requirements snippet",
    "file_path": "docs/getting_started.md",
    "code_snippet": "pip install torch==2.2.1",
    "is_true_positive": false
  },
  {
    "id": "LLM01_TP_0188",
    "category": "LLM01: Prompt Injection",
    "severity": "LOW",
    "confidence": 0.87,
    "description": "LangChain template concatenates untrusted context",
    "file_path": "src/chatbot/services/conversation.py",
    "code_snippet": "template = ChatPromptTemplate.from_messages([(\"system\", ctx + prompt)])",
    "is_true_positive": true
  },
  {
    "id": "LLM08_FP_0189",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.59,
    "description": "Manual approval required",
    "file_path": "examples/autonomous_agent.md",
    "code_snippet": "if not require_human_confirmation(task): raise",
    "is_true_positive": false
  },
  {
    "id": "LLM08_TP_0190",
    "category": "LLM08: Excessive Agency",
    "severity": "LOW",
    "confidence": 0.93,
    "description": "Agent transfers funds autonomously",
    "file_path": "examples/autonomous_agent.md",
    "code_snippet": "bank.transfer(amount, destination, auto_execute=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0191",
    "category": "LLM02: Insecure Output",
    "severity": "MEDIUM",
    "confidence": 0.9,
    "description": "LLM response executed via eval",
    "file_path": "agents/code_exec.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0192",
    "category": "LLM09: Overreliance",
    "severity": "HIGH",
    "confidence": 0.96,
    "description": "Auto-approves compliance decision",
    "file_path": "workflows/human_loop.py",
    "code_snippet": "if model.confidence > 0.2: return 'approved'",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0193",
    "category": "LLM06: Sensitive Info",
    "severity": "LOW",
    "confidence": 0.47,
    "description": "Env var reference",
    "file_path": "config/settings.py",
    "code_snippet": "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')",
    "is_true_positive": false
  },
  {
    "id": "LLM07_TP_0194",
    "category": "LLM07: Insecure Plugin",
    "severity": "LOW",
    "confidence": 0.86,
    "description": "Plugin executes shell command (synthetic variation)",
    "file_path": "plugins/registry.py",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0195",
    "category": "LLM06: Sensitive Info",
    "severity": "LOW",
    "confidence": 0.79,
    "description": "LLM output with AWS key logged",
    "file_path": "monitoring/logging.py",
    "code_snippet": "logger.info(f'Key leaked: {response}')",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0196",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.48,
    "description": "Env var reference",
    "file_path": "docs/assets/logo.py",
    "code_snippet": "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')",
    "is_true_positive": false
  },
  {
    "id": "LLM03_FP_0197",
    "category": "LLM03: Training Poisoning",
    "severity": "LOW",
    "confidence": 0.43,
    "description": "model.eval() inference mode (synthetic variation)",
    "file_path": "models/bert_wrapper.py",
    "code_snippet": "self.model.eval()",
    "is_true_positive": false
  },
  {
    "id": "LLM02_TP_0198",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.95,
    "description": "LLM response executed via eval",
    "file_path": "agents/code_exec.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0199",
    "category": "LLM10: Model Theft",
    "severity": "MEDIUM",
    "confidence": 0.9,
    "description": "Endpoint serves model weights (synthetic variation)",
    "file_path": "api/completions.py",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0200",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.46,
    "description": "Env var reference",
    "file_path": "docs/assets/logo.py",
    "code_snippet": "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')",
    "is_true_positive": false
  },
  {
    "id": "LLM08_TP_0201",
    "category": "LLM08: Excessive Agency",
    "severity": "CRITICAL",
    "confidence": 0.95,
    "description": "Agent transfers funds autonomously (synthetic variation)",
    "file_path": "agents/controller.py",
    "code_snippet": "bank.transfer(amount, destination, auto_execute=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM10_FP_0202",
    "category": "LLM10: Model Theft",
    "severity": "MEDIUM",
    "confidence": 0.54,
    "description": "Docs describing scp export",
    "file_path": "api/secure_download.py",
    "code_snippet": "scp model.bin user@host",
    "is_true_positive": false
  },
  {
    "id": "LLM03_FP_0203",
    "category": "LLM03: Training Poisoning",
    "severity": "LOW",
    "confidence": 0.59,
    "description": "torch random_split in tests",
    "file_path": "tests/fakes/datasets.py",
    "code_snippet": "train, test = random_split(dataset, [80, 20])",
    "is_true_positive": false
  },
  {
    "id": "LLM09_FP_0204",
    "category": "LLM09: Overreliance",
    "severity": "LOW",
    "confidence": 0.63,
    "description": "Workflow requires reviewer (synthetic variation)",
    "file_path": "workflows/human_loop.py",
    "code_snippet": "if not reviewer.signoff(result): return",
    "is_true_positive": false
  },
  {
    "id": "LLM09_TP_0205",
    "category": "LLM09: Overreliance",
    "severity": "MEDIUM",
    "confidence": 0.93,
    "description": "LLM summary emailed automatically",
    "file_path": "decision/approver.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0206",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.81,
    "description": "LangChain template concatenates untrusted context (synthetic variation)",
    "file_path": "tests/test_prompt_injection.py",
    "code_snippet": "template = ChatPromptTemplate.from_messages([(\"system\", ctx + prompt)])",
    "is_true_positive": true
  },
  {
    "id": "LLM04_TP_0207",
    "category": "LLM04: Model Denial of Service",
    "severity": "MEDIUM",
    "confidence": 0.74,
    "description": "Unbounded while loop hitting OpenAI (synthetic variation)",
    "file_path": "routes/ask.py",
    "code_snippet": "while True:\n    client.chat.completions.create(... )",
    "is_true_positive": true
  },
  {
    "id": "LLM08_FP_0208",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.58,
    "description": "Manual approval required",
    "file_path": "examples/autonomous_agent.md",
    "code_snippet": "if not require_human_confirmation(task): raise",
    "is_true_positive": false
  },
  {
    "id": "LLM01_TP_0209",
    "category": "LLM01: Prompt Injection",
    "severity": "LOW",
    "confidence": 0.92,
    "description": "Direct f-string injection into system prompt (synthetic variation)",
    "file_path": "examples/prompts/prompt_injection.ipynb",
    "code_snippet": "messages = [{\"role\": \"system\", \"content\": f'Policy: {user_input}'}]",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0210",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.73,
    "description": "SQL built from LLM output",
    "file_path": "docs/examples/output_handling.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0211",
    "category": "LLM10: Model Theft",
    "severity": "HIGH",
    "confidence": 0.82,
    "description": "Endpoint serves model weights",
    "file_path": "api/completions.py",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM04_FP_0212",
    "category": "LLM04: Model Denial of Service",
    "severity": "HIGH",
    "confidence": 0.71,
    "description": "Single completion call flagged (synthetic variation)",
    "file_path": "workers/auto_refiner.py",
    "code_snippet": "client.chat.completions.create(model=MODEL, messages=msgs)",
    "is_true_positive": false
  },
  {
    "id": "LLM09_TP_0213",
    "category": "LLM09: Overreliance",
    "severity": "CRITICAL",
    "confidence": 0.71,
    "description": "Auto-approves compliance decision",
    "file_path": "tests/workflows/test_review.py",
    "code_snippet": "if model.confidence > 0.2: return 'approved'",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0214",
    "category": "LLM06: Sensitive Info",
    "severity": "LOW",
    "confidence": 0.8,
    "description": "Hardcoded OpenAI key",
    "file_path": "config/settings.py",
    "code_snippet": "os.environ['OPENAI_API_KEY'] = 'sk-live-123456789'",
    "is_true_positive": true
  },
  {
    "id": "LLM02_FP_0215",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.48,
    "description": "Docs logging example output",
    "file_path": "db/auto_sql.py",
    "code_snippet": "print('LLM output:', response.text)",
    "is_true_positive": false
  },
  {
    "id": "LLM03_FP_0216",
    "category": "LLM03: Training Poisoning",
    "severity": "HIGH",
    "confidence": 0.42,
    "description": "model.eval() inference mode (synthetic variation)",
    "file_path": "models/bert_wrapper.py",
    "code_snippet": "self.model.eval()",
    "is_true_positive": false
  },
  {
    "id": "LLM08_TP_0217",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.95,
    "description": "Agent transfers funds autonomously",
    "file_path": "agents/finance_agent.py",
    "code_snippet": "bank.transfer(amount, destination, auto_execute=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM05_TP_0218",
    "category": "LLM05: Supply Chain",
    "severity": "LOW",
    "confidence": 0.91,
    "description": "Agent executes pip install from LLM (synthetic variation)",
    "file_path": "docs/getting_started.md",
    "code_snippet": "subprocess.run(['pip', 'install', llm_pkg], check=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0219",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.4,
    "description": "Env var reference",
    "file_path": "config/settings.py",
    "code_snippet": "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')",
    "is_true_positive": false
  },
  {
    "id": "LLM07_FP_0220",
    "category": "LLM07: Insecure Plugin",
    "severity": "LOW",
    "confidence": 0.53,
    "description": "Docs describing plugin install",
    "file_path": "plugins/registry.py",
    "code_snippet": "Install shell plugin by running ./install.sh",
    "is_true_positive": false
  },
  {
    "id": "LLM09_TP_0221",
    "category": "LLM09: Overreliance",
    "severity": "LOW",
    "confidence": 0.82,
    "description": "Auto-approves compliance decision",
    "file_path": "tests/workflows/test_review.py",
    "code_snippet": "if model.confidence > 0.2: return 'approved'",
    "is_true_positive": true
  },
  {
    "id": "LLM03_TP_0222",
    "category": "LLM03: Training Poisoning",
    "severity": "LOW",
    "confidence": 0.79,
    "description": "Weights loaded via pickle from user path (synthetic variation)",
    "file_path": "training/data_loader.py",
    "code_snippet": "weights = pickle.load(open(model_path, 'rb'))",
    "is_true_positive": true
  },
  {
    "id": "LLM08_FP_0223",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.51,
    "description": "Demo described in README",
    "file_path": "agents/task_runner.py",
    "code_snippet": "agent.run('book a flight')",
    "is_true_positive": false
  },
  {
    "id": "LLM06_FP_0224",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.71,
    "description": "Base64 image asset",
    "file_path": "config/settings.py",
    "code_snippet": "LOGO = 'data:image/png;base64,iVBORw0KGgoAAAANS...'",
    "is_true_positive": false
  },
  {
    "id": "LLM02_FP_0225",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.65,
    "description": "Docs logging example output",
    "file_path": "app/repository.py",
    "code_snippet": "print('LLM output:', response.text)",
    "is_true_positive": false
  },
  {
    "id": "LLM01_TP_0226",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.72,
    "description": "LangChain template concatenates untrusted context",
    "file_path": "src/chatbot/services/conversation.py",
    "code_snippet": "template = ChatPromptTemplate.from_messages([(\"system\", ctx + prompt)])",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0227",
    "category": "LLM06: Sensitive Info",
    "severity": "CRITICAL",
    "confidence": 0.97,
    "description": "Hardcoded OpenAI key",
    "file_path": "monitoring/logging.py",
    "code_snippet": "os.environ['OPENAI_API_KEY'] = 'sk-live-123456789'",
    "is_true_positive": true
  },
  {
    "id": "LLM02_FP_0228",
    "category": "LLM02: Insecure Output",
    "severity": "MEDIUM",
    "confidence": 0.59,
    "description": "Docs logging example output (synthetic variation)",
    "file_path": "docs/examples/output_handling.py",
    "code_snippet": "print('LLM output:', response.text)",
    "is_true_positive": false
  },
  {
    "id": "LLM02_TP_0229",
    "category": "LLM02: Insecure Output",
    "severity": "CRITICAL",
    "confidence": 0.96,
    "description": "LLM response executed via eval (synthetic variation)",
    "file_path": "docs/examples/output_handling.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM05_FP_0230",
    "category": "LLM05: Supply Chain",
    "severity": "HIGH",
    "confidence": 0.69,
    "description": "Docs show requirements snippet",
    "file_path": "docs/getting_started.md",
    "code_snippet": "pip install torch==2.2.1",
    "is_true_positive": false
  },
  {
    "id": "LLM02_TP_0231",
    "category": "LLM02: Insecure Output",
    "severity": "MEDIUM",
    "confidence": 0.95,
    "description": "LLM response executed via eval",
    "file_path": "docs/examples/output_handling.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM02_FP_0232",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.37,
    "description": "Docs logging example output",
    "file_path": "app/repository.py",
    "code_snippet": "print('LLM output:', response.text)",
    "is_true_positive": false
  },
  {
    "id": "LLM05_FP_0233",
    "category": "LLM05: Supply Chain",
    "severity": "HIGH",
    "confidence": 0.43,
    "description": "Docs show requirements snippet",
    "file_path": "docs/getting_started.md",
    "code_snippet": "pip install torch==2.2.1",
    "is_true_positive": false
  },
  {
    "id": "LLM03_TP_0234",
    "category": "LLM03: Training Poisoning",
    "severity": "HIGH",
    "confidence": 0.86,
    "description": "Weights loaded via pickle from user path",
    "file_path": "training/data_loader.py",
    "code_snippet": "weights = pickle.load(open(model_path, 'rb'))",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0235",
    "category": "LLM09: Overreliance",
    "severity": "HIGH",
    "confidence": 0.81,
    "description": "Auto-approves compliance decision",
    "file_path": "decision/approver.py",
    "code_snippet": "if model.confidence > 0.2: return 'approved'",
    "is_true_positive": true
  },
  {
    "id": "LLM08_TP_0236",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.97,
    "description": "Agent executes system command",
    "file_path": "agents/finance_agent.py",
    "code_snippet": "os.system(plan['action'])",
    "is_true_positive": true
  },
  {
    "id": "LLM08_TP_0237",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.91,
    "description": "Agent executes system command (synthetic variation)",
    "file_path": "agents/task_runner.py",
    "code_snippet": "os.system(plan['action'])",
    "is_true_positive": true
  },
  {
    "id": "LLM09_FP_0238",
    "category": "LLM09: Overreliance",
    "severity": "HIGH",
    "confidence": 0.41,
    "description": "Workflow requires reviewer (synthetic variation)",
    "file_path": "decision/approver.py",
    "code_snippet": "if not reviewer.signoff(result): return",
    "is_true_positive": false
  },
  {
    "id": "LLM06_FP_0239",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.68,
    "description": "Env var reference",
    "file_path": "config/settings.py",
    "code_snippet": "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')",
    "is_true_positive": false
  },
  {
    "id": "LLM05_TP_0240",
    "category": "LLM05: Supply Chain",
    "severity": "HIGH",
    "confidence": 0.87,
    "description": "Agent executes pip install from LLM (synthetic variation)",
    "file_path": "agents/tool_executor.py",
    "code_snippet": "subprocess.run(['pip', 'install', llm_pkg], check=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM03_FP_0241",
    "category": "LLM03: Training Poisoning",
    "severity": "HIGH",
    "confidence": 0.58,
    "description": "torch random_split in tests",
    "file_path": "training/load_weights.py",
    "code_snippet": "train, test = random_split(dataset, [80, 20])",
    "is_true_positive": false
  },
  {
    "id": "LLM06_FP_0242",
    "category": "LLM06: Sensitive Info",
    "severity": "LOW",
    "confidence": 0.37,
    "description": "Env var reference",
    "file_path": "notebooks/openai_quickstart.ipynb",
    "code_snippet": "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0243",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.84,
    "description": "Endpoint serves model weights",
    "file_path": "docs/model_export.md",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM05_FP_0244",
    "category": "LLM05: Supply Chain",
    "severity": "LOW",
    "confidence": 0.65,
    "description": "Download guarded by sha256 verification",
    "file_path": "security/downloader.py",
    "code_snippet": "if sha256(data).hexdigest() != expected_hash: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM05_TP_0245",
    "category": "LLM05: Supply Chain",
    "severity": "CRITICAL",
    "confidence": 0.82,
    "description": "trust_remote_code=True on AutoModel",
    "file_path": "agents/tool_executor.py",
    "code_snippet": "AutoModel.from_pretrained(repo, trust_remote_code=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0246",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.72,
    "description": "Base64 image asset",
    "file_path": "config/settings.py",
    "code_snippet": "LOGO = 'data:image/png;base64,iVBORw0KGgoAAAANS...'",
    "is_true_positive": false
  },
  {
    "id": "LLM07_TP_0247",
    "category": "LLM07: Insecure Plugin",
    "severity": "HIGH",
    "confidence": 0.77,
    "description": "Plugin zip downloaded from URL (synthetic variation)",
    "file_path": "plugins/shell_tool.py",
    "code_snippet": "zip_ref.extractall('/opt/plugins')",
    "is_true_positive": true
  },
  {
    "id": "LLM08_TP_0248",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.96,
    "description": "Agent transfers funds autonomously",
    "file_path": "agents/finance_agent.py",
    "code_snippet": "bank.transfer(amount, destination, auto_execute=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM07_TP_0249",
    "category": "LLM07: Insecure Plugin",
    "severity": "HIGH",
    "confidence": 0.75,
    "description": "Plugin executes shell command (synthetic variation)",
    "file_path": "plugins/registry.py",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0250",
    "category": "LLM09: Overreliance",
    "severity": "LOW",
    "confidence": 0.73,
    "description": "LLM summary emailed automatically",
    "file_path": "tests/workflows/test_review.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM08_FP_0251",
    "category": "LLM08: Excessive Agency",
    "severity": "LOW",
    "confidence": 0.37,
    "description": "Manual approval required",
    "file_path": "agents/controller.py",
    "code_snippet": "if not require_human_confirmation(task): raise",
    "is_true_positive": false
  },
  {
    "id": "LLM08_TP_0252",
    "category": "LLM08: Excessive Agency",
    "severity": "CRITICAL",
    "confidence": 0.74,
    "description": "Agent transfers funds autonomously (synthetic variation)",
    "file_path": "agents/finance_agent.py",
    "code_snippet": "bank.transfer(amount, destination, auto_execute=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0253",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.37,
    "description": "Base64 image asset",
    "file_path": "notebooks/openai_quickstart.ipynb",
    "code_snippet": "LOGO = 'data:image/png;base64,iVBORw0KGgoAAAANS...'",
    "is_true_positive": false
  },
  {
    "id": "LLM06_FP_0254",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.52,
    "description": "Env var reference",
    "file_path": "docs/assets/logo.py",
    "code_snippet": "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')",
    "is_true_positive": false
  },
  {
    "id": "LLM10_FP_0255",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.5,
    "description": "Signed URL enforced",
    "file_path": "api/completions.py",
    "code_snippet": "return generate_signed_url('model.bin', expires=30)",
    "is_true_positive": false
  },
  {
    "id": "LLM06_FP_0256",
    "category": "LLM06: Sensitive Info",
    "severity": "LOW",
    "confidence": 0.57,
    "description": "Base64 image asset",
    "file_path": "monitoring/logging.py",
    "code_snippet": "LOGO = 'data:image/png;base64,iVBORw0KGgoAAAANS...'",
    "is_true_positive": false
  },
  {
    "id": "LLM01_TP_0257",
    "category": "LLM01: Prompt Injection",
    "severity": "CRITICAL",
    "confidence": 0.85,
    "description": "Direct f-string injection into system prompt (synthetic variation)",
    "file_path": "tests/test_prompt_injection.py",
    "code_snippet": "messages = [{\"role\": \"system\", \"content\": f'Policy: {user_input}'}]",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0258",
    "category": "LLM09: Overreliance",
    "severity": "CRITICAL",
    "confidence": 0.98,
    "description": "LLM summary emailed automatically",
    "file_path": "workflows/email_broadcast.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM05_FP_0259",
    "category": "LLM05: Supply Chain",
    "severity": "MEDIUM",
    "confidence": 0.65,
    "description": "Download guarded by sha256 verification",
    "file_path": "docs/getting_started.md",
    "code_snippet": "if sha256(data).hexdigest() != expected_hash: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM02_FP_0260",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.53,
    "description": "Docs logging example output",
    "file_path": "agents/code_exec.py",
    "code_snippet": "print('LLM output:', response.text)",
    "is_true_positive": false
  },
  {
    "id": "LLM10_FP_0261",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.54,
    "description": "Signed URL enforced",
    "file_path": "docs/model_export.md",
    "code_snippet": "return generate_signed_url('model.bin', expires=30)",
    "is_true_positive": false
  },
  {
    "id": "LLM07_TP_0262",
    "category": "LLM07: Insecure Plugin",
    "severity": "LOW",
    "confidence": 0.75,
    "description": "Plugin executes shell command",
    "file_path": "plugins/shell_tool.py",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM07_TP_0263",
    "category": "LLM07: Insecure Plugin",
    "severity": "CRITICAL",
    "confidence": 0.94,
    "description": "Plugin executes shell command",
    "file_path": "docs/plugins.md",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM01_FP_0264",
    "category": "LLM01: Prompt Injection",
    "severity": "HIGH",
    "confidence": 0.53,
    "description": "Unit test fixture builds fake prompts",
    "file_path": "tests/test_prompt_injection.py",
    "code_snippet": "def prompt_fixture(): return f'ignore rules {seed}'",
    "is_true_positive": false
  },
  {
    "id": "LLM03_TP_0265",
    "category": "LLM03: Training Poisoning",
    "severity": "HIGH",
    "confidence": 0.87,
    "description": "Weights loaded via pickle from user path (synthetic variation)",
    "file_path": "tests/fakes/datasets.py",
    "code_snippet": "weights = pickle.load(open(model_path, 'rb'))",
    "is_true_positive": true
  },
  {
    "id": "LLM04_TP_0266",
    "category": "LLM04: Model Denial of Service",
    "severity": "HIGH",
    "confidence": 0.92,
    "description": "Async gather spawns many completions",
    "file_path": "services/parallel_runner.py",
    "code_snippet": "await asyncio.gather(*[call_llm(q) for q in queue])",
    "is_true_positive": true
  },
  {
    "id": "LLM08_TP_0267",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.73,
    "description": "Agent executes system command",
    "file_path": "agents/controller.py",
    "code_snippet": "os.system(plan['action'])",
    "is_true_positive": true
  },
  {
    "id": "LLM07_FP_0268",
    "category": "LLM07: Insecure Plugin",
    "severity": "LOW",
    "confidence": 0.46,
    "description": "Docs describing plugin install (synthetic variation)",
    "file_path": "plugins/registry.py",
    "code_snippet": "Install shell plugin by running ./install.sh",
    "is_true_positive": false
  },
  {
    "id": "LLM02_TP_0269",
    "category": "LLM02: Insecure Output",
    "severity": "CRITICAL",
    "confidence": 0.76,
    "description": "SQL built from LLM output",
    "file_path": "app/repository.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM05_FP_0270",
    "category": "LLM05: Supply Chain",
    "severity": "LOW",
    "confidence": 0.58,
    "description": "Download guarded by sha256 verification",
    "file_path": "agents/tool_executor.py",
    "code_snippet": "if sha256(data).hexdigest() != expected_hash: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM04_TP_0271",
    "category": "LLM04: Model Denial of Service",
    "severity": "LOW",
    "confidence": 0.73,
    "description": "Unbounded while loop hitting OpenAI",
    "file_path": "services/parallel_runner.py",
    "code_snippet": "while True:\n    client.chat.completions.create(... )",
    "is_true_positive": true
  },
  {
    "id": "LLM08_TP_0272",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.81,
    "description": "Agent transfers funds autonomously",
    "file_path": "agents/finance_agent.py",
    "code_snippet": "bank.transfer(amount, destination, auto_execute=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM08_TP_0273",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.78,
    "description": "Agent transfers funds autonomously (synthetic variation)",
    "file_path": "agents/controller.py",
    "code_snippet": "bank.transfer(amount, destination, auto_execute=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM02_FP_0274",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.5,
    "description": "SQLAlchemy session.exec mistaken for exec",
    "file_path": "agents/code_exec.py",
    "code_snippet": "result = session.exec(select(User))",
    "is_true_positive": false
  },
  {
    "id": "LLM01_FP_0275",
    "category": "LLM01: Prompt Injection",
    "severity": "LOW",
    "confidence": 0.7,
    "description": "Example notebook demonstrates prompts",
    "file_path": "examples/prompts/prompt_injection.ipynb",
    "code_snippet": "SYSTEM_PROMPT = 'Your name is {username}'",
    "is_true_positive": false
  },
  {
    "id": "LLM05_FP_0276",
    "category": "LLM05: Supply Chain",
    "severity": "HIGH",
    "confidence": 0.57,
    "description": "Docs show requirements snippet",
    "file_path": "docs/getting_started.md",
    "code_snippet": "pip install torch==2.2.1",
    "is_true_positive": false
  },
  {
    "id": "LLM06_TP_0277",
    "category": "LLM06: Sensitive Info",
    "severity": "CRITICAL",
    "confidence": 0.78,
    "description": "LLM output with AWS key logged",
    "file_path": "monitoring/logging.py",
    "code_snippet": "logger.info(f'Key leaked: {response}')",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0278",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.7,
    "description": "LLM output with AWS key logged",
    "file_path": "config/settings.py",
    "code_snippet": "logger.info(f'Key leaked: {response}')",
    "is_true_positive": true
  },
  {
    "id": "LLM05_FP_0279",
    "category": "LLM05: Supply Chain",
    "severity": "HIGH",
    "confidence": 0.67,
    "description": "Docs show requirements snippet",
    "file_path": "agents/tool_executor.py",
    "code_snippet": "pip install torch==2.2.1",
    "is_true_positive": false
  },
  {
    "id": "LLM07_TP_0280",
    "category": "LLM07: Insecure Plugin",
    "severity": "LOW",
    "confidence": 0.75,
    "description": "Plugin executes shell command (synthetic variation)",
    "file_path": "docs/plugins.md",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0281",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.44,
    "description": "Env var reference",
    "file_path": "config/settings.py",
    "code_snippet": "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')",
    "is_true_positive": false
  },
  {
    "id": "LLM06_TP_0282",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.89,
    "description": "Hardcoded OpenAI key (synthetic variation)",
    "file_path": "config/settings.py",
    "code_snippet": "os.environ['OPENAI_API_KEY'] = 'sk-live-123456789'",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0283",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.89,
    "description": "LLM response executed via eval",
    "file_path": "docs/examples/output_handling.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM05_TP_0284",
    "category": "LLM05: Supply Chain",
    "severity": "MEDIUM",
    "confidence": 0.83,
    "description": "trust_remote_code=True on AutoModel",
    "file_path": "agents/tool_executor.py",
    "code_snippet": "AutoModel.from_pretrained(repo, trust_remote_code=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0285",
    "category": "LLM10: Model Theft",
    "severity": "MEDIUM",
    "confidence": 0.89,
    "description": "API exposes logprobs enabling extraction",
    "file_path": "api/completions.py",
    "code_snippet": "client.chat.completions.create(logprobs=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0286",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.72,
    "description": "SQL built from LLM output",
    "file_path": "agents/code_exec.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0287",
    "category": "LLM09: Overreliance",
    "severity": "HIGH",
    "confidence": 0.94,
    "description": "Auto-approves compliance decision",
    "file_path": "workflows/email_broadcast.py",
    "code_snippet": "if model.confidence > 0.2: return 'approved'",
    "is_true_positive": true
  },
  {
    "id": "LLM04_FP_0288",
    "category": "LLM04: Model Denial of Service",
    "severity": "HIGH",
    "confidence": 0.51,
    "description": "Pytest simulating rate limit (synthetic variation)",
    "file_path": "workers/auto_refiner.py",
    "code_snippet": "for _ in range(5): client.chat.completions.create(... )",
    "is_true_positive": false
  },
  {
    "id": "LLM03_TP_0289",
    "category": "LLM03: Training Poisoning",
    "severity": "CRITICAL",
    "confidence": 0.89,
    "description": "Weights loaded via pickle from user path",
    "file_path": "training/data_loader.py",
    "code_snippet": "weights = pickle.load(open(model_path, 'rb'))",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0290",
    "category": "LLM01: Prompt Injection",
    "severity": "LOW",
    "confidence": 0.71,
    "description": "Direct f-string injection into system prompt",
    "file_path": "pipelines/langchain_agent.py",
    "code_snippet": "messages = [{\"role\": \"system\", \"content\": f'Policy: {user_input}'}]",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0291",
    "category": "LLM02: Insecure Output",
    "severity": "CRITICAL",
    "confidence": 0.71,
    "description": "LLM response executed via eval",
    "file_path": "agents/code_exec.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM03_FP_0292",
    "category": "LLM03: Training Poisoning",
    "severity": "MEDIUM",
    "confidence": 0.52,
    "description": "model.eval() inference mode",
    "file_path": "tests/fakes/datasets.py",
    "code_snippet": "self.model.eval()",
    "is_true_positive": false
  },
  {
    "id": "LLM07_TP_0293",
    "category": "LLM07: Insecure Plugin",
    "severity": "LOW",
    "confidence": 0.75,
    "description": "Plugin executes shell command",
    "file_path": "plugins/registry.py",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0294",
    "category": "LLM09: Overreliance",
    "severity": "LOW",
    "confidence": 0.97,
    "description": "Auto-approves compliance decision",
    "file_path": "decision/approver.py",
    "code_snippet": "if model.confidence > 0.2: return 'approved'",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0295",
    "category": "LLM09: Overreliance",
    "severity": "MEDIUM",
    "confidence": 0.83,
    "description": "LLM summary emailed automatically (synthetic variation)",
    "file_path": "workflows/email_broadcast.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM04_FP_0296",
    "category": "LLM04: Model Denial of Service",
    "severity": "HIGH",
    "confidence": 0.51,
    "description": "Single completion call flagged",
    "file_path": "workers/auto_refiner.py",
    "code_snippet": "client.chat.completions.create(model=MODEL, messages=msgs)",
    "is_true_positive": false
  },
  {
    "id": "LLM01_TP_0297",
    "category": "LLM01: Prompt Injection",
    "severity": "LOW",
    "confidence": 0.83,
    "description": "Direct f-string injection into system prompt",
    "file_path": "src/chatbot/services/conversation.py",
    "code_snippet": "messages = [{\"role\": \"system\", \"content\": f'Policy: {user_input}'}]",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0298",
    "category": "LLM01: Prompt Injection",
    "severity": "CRITICAL",
    "confidence": 0.77,
    "description": "Direct f-string injection into system prompt (synthetic variation)",
    "file_path": "examples/prompts/prompt_injection.ipynb",
    "code_snippet": "messages = [{\"role\": \"system\", \"content\": f'Policy: {user_input}'}]",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0299",
    "category": "LLM01: Prompt Injection",
    "severity": "HIGH",
    "confidence": 0.86,
    "description": "LangChain template concatenates untrusted context",
    "file_path": "pipelines/langchain_agent.py",
    "code_snippet": "template = ChatPromptTemplate.from_messages([(\"system\", ctx + prompt)])",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0300",
    "category": "LLM06: Sensitive Info",
    "severity": "CRITICAL",
    "confidence": 0.78,
    "description": "Hardcoded OpenAI key (synthetic variation)",
    "file_path": "monitoring/logging.py",
    "code_snippet": "os.environ['OPENAI_API_KEY'] = 'sk-live-123456789'",
    "is_true_positive": true
  },
  {
    "id": "LLM10_FP_0301",
    "category": "LLM10: Model Theft",
    "severity": "HIGH",
    "confidence": 0.53,
    "description": "Signed URL enforced",
    "file_path": "docs/model_export.md",
    "code_snippet": "return generate_signed_url('model.bin', expires=30)",
    "is_true_positive": false
  },
  {
    "id": "LLM07_FP_0302",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.41,
    "description": "Docs describing plugin install",
    "file_path": "docs/plugins.md",
    "code_snippet": "Install shell plugin by running ./install.sh",
    "is_true_positive": false
  },
  {
    "id": "LLM09_TP_0303",
    "category": "LLM09: Overreliance",
    "severity": "MEDIUM",
    "confidence": 0.93,
    "description": "Auto-approves compliance decision",
    "file_path": "workflows/human_loop.py",
    "code_snippet": "if model.confidence > 0.2: return 'approved'",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0304",
    "category": "LLM09: Overreliance",
    "severity": "CRITICAL",
    "confidence": 0.77,
    "description": "LLM summary emailed automatically (synthetic variation)",
    "file_path": "workflows/email_broadcast.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM02_FP_0305",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.62,
    "description": "Docs logging example output (synthetic variation)",
    "file_path": "agents/code_exec.py",
    "code_snippet": "print('LLM output:', response.text)",
    "is_true_positive": false
  },
  {
    "id": "LLM05_TP_0306",
    "category": "LLM05: Supply Chain",
    "severity": "MEDIUM",
    "confidence": 0.93,
    "description": "trust_remote_code=True on AutoModel",
    "file_path": "models/loader.py",
    "code_snippet": "AutoModel.from_pretrained(repo, trust_remote_code=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0307",
    "category": "LLM09: Overreliance",
    "severity": "HIGH",
    "confidence": 0.97,
    "description": "Auto-approves compliance decision (synthetic variation)",
    "file_path": "workflows/human_loop.py",
    "code_snippet": "if model.confidence > 0.2: return 'approved'",
    "is_true_positive": true
  },
  {
    "id": "LLM04_FP_0308",
    "category": "LLM04: Model Denial of Service",
    "severity": "LOW",
    "confidence": 0.61,
    "description": "Single completion call flagged",
    "file_path": "tests/dos/test_rate_limit.py",
    "code_snippet": "client.chat.completions.create(model=MODEL, messages=msgs)",
    "is_true_positive": false
  },
  {
    "id": "LLM07_FP_0309",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.52,
    "description": "Docs describing plugin install",
    "file_path": "plugins/registry.py",
    "code_snippet": "Install shell plugin by running ./install.sh",
    "is_true_positive": false
  },
  {
    "id": "LLM05_TP_0310",
    "category": "LLM05: Supply Chain",
    "severity": "LOW",
    "confidence": 0.92,
    "description": "Agent executes pip install from LLM",
    "file_path": "security/downloader.py",
    "code_snippet": "subprocess.run(['pip', 'install', llm_pkg], check=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0311",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.37,
    "description": "Base64 image asset",
    "file_path": "config/settings.py",
    "code_snippet": "LOGO = 'data:image/png;base64,iVBORw0KGgoAAAANS...'",
    "is_true_positive": false
  },
  {
    "id": "LLM03_TP_0312",
    "category": "LLM03: Training Poisoning",
    "severity": "MEDIUM",
    "confidence": 0.75,
    "description": "Weights loaded via pickle from user path (synthetic variation)",
    "file_path": "tests/fakes/datasets.py",
    "code_snippet": "weights = pickle.load(open(model_path, 'rb'))",
    "is_true_positive": true
  },
  {
    "id": "LLM10_FP_0313",
    "category": "LLM10: Model Theft",
    "severity": "MEDIUM",
    "confidence": 0.63,
    "description": "Docs describing scp export",
    "file_path": "api/secure_download.py",
    "code_snippet": "scp model.bin user@host",
    "is_true_positive": false
  },
  {
    "id": "LLM08_TP_0314",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.9,
    "description": "Agent executes system command",
    "file_path": "agents/task_runner.py",
    "code_snippet": "os.system(plan['action'])",
    "is_true_positive": true
  },
  {
    "id": "LLM09_FP_0315",
    "category": "LLM09: Overreliance",
    "severity": "LOW",
    "confidence": 0.7,
    "description": "Workflow requires reviewer",
    "file_path": "decision/approver.py",
    "code_snippet": "if not reviewer.signoff(result): return",
    "is_true_positive": false
  },
  {
    "id": "LLM01_TP_0316",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.7,
    "description": "Direct f-string injection into system prompt",
    "file_path": "src/chatbot/services/conversation.py",
    "code_snippet": "messages = [{\"role\": \"system\", \"content\": f'Policy: {user_input}'}]",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0317",
    "category": "LLM06: Sensitive Info",
    "severity": "LOW",
    "confidence": 0.7,
    "description": "LLM output with AWS key logged",
    "file_path": "docs/assets/logo.py",
    "code_snippet": "logger.info(f'Key leaked: {response}')",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0318",
    "category": "LLM01: Prompt Injection",
    "severity": "LOW",
    "confidence": 0.84,
    "description": "LangChain template concatenates untrusted context",
    "file_path": "tests/test_prompt_injection.py",
    "code_snippet": "template = ChatPromptTemplate.from_messages([(\"system\", ctx + prompt)])",
    "is_true_positive": true
  },
  {
    "id": "LLM07_FP_0319",
    "category": "LLM07: Insecure Plugin",
    "severity": "LOW",
    "confidence": 0.54,
    "description": "Plugin registry enforces allowlist (synthetic variation)",
    "file_path": "plugins/shell_tool.py",
    "code_snippet": "if plugin_id not in ALLOWED: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0320",
    "category": "LLM10: Model Theft",
    "severity": "CRITICAL",
    "confidence": 0.72,
    "description": "API exposes logprobs enabling extraction",
    "file_path": "api/secure_download.py",
    "code_snippet": "client.chat.completions.create(logprobs=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM08_FP_0321",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.66,
    "description": "Manual approval required (synthetic variation)",
    "file_path": "agents/controller.py",
    "code_snippet": "if not require_human_confirmation(task): raise",
    "is_true_positive": false
  },
  {
    "id": "LLM01_TP_0322",
    "category": "LLM01: Prompt Injection",
    "severity": "CRITICAL",
    "confidence": 0.72,
    "description": "LangChain template concatenates untrusted context (synthetic variation)",
    "file_path": "examples/prompts/prompt_injection.ipynb",
    "code_snippet": "template = ChatPromptTemplate.from_messages([(\"system\", ctx + prompt)])",
    "is_true_positive": true
  },
  {
    "id": "LLM03_TP_0323",
    "category": "LLM03: Training Poisoning",
    "severity": "LOW",
    "confidence": 0.95,
    "description": "Weights loaded via pickle from user path",
    "file_path": "tests/fakes/datasets.py",
    "code_snippet": "weights = pickle.load(open(model_path, 'rb'))",
    "is_true_positive": true
  },
  {
    "id": "LLM04_TP_0324",
    "category": "LLM04: Model Denial of Service",
    "severity": "LOW",
    "confidence": 0.96,
    "description": "Async gather spawns many completions",
    "file_path": "routes/ask.py",
    "code_snippet": "await asyncio.gather(*[call_llm(q) for q in queue])",
    "is_true_positive": true
  },
  {
    "id": "LLM05_FP_0325",
    "category": "LLM05: Supply Chain",
    "severity": "MEDIUM",
    "confidence": 0.36,
    "description": "Docs show requirements snippet (synthetic variation)",
    "file_path": "agents/tool_executor.py",
    "code_snippet": "pip install torch==2.2.1",
    "is_true_positive": false
  },
  {
    "id": "LLM03_FP_0326",
    "category": "LLM03: Training Poisoning",
    "severity": "MEDIUM",
    "confidence": 0.41,
    "description": "model.eval() inference mode (synthetic variation)",
    "file_path": "training/data_loader.py",
    "code_snippet": "self.model.eval()",
    "is_true_positive": false
  },
  {
    "id": "LLM07_FP_0327",
    "category": "LLM07: Insecure Plugin",
    "severity": "HIGH",
    "confidence": 0.4,
    "description": "Docs describing plugin install",
    "file_path": "docs/plugins.md",
    "code_snippet": "Install shell plugin by running ./install.sh",
    "is_true_positive": false
  },
  {
    "id": "LLM02_TP_0328",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.82,
    "description": "SQL built from LLM output",
    "file_path": "agents/code_exec.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0329",
    "category": "LLM06: Sensitive Info",
    "severity": "LOW",
    "confidence": 0.58,
    "description": "Base64 image asset",
    "file_path": "config/settings.py",
    "code_snippet": "LOGO = 'data:image/png;base64,iVBORw0KGgoAAAANS...'",
    "is_true_positive": false
  },
  {
    "id": "LLM08_TP_0330",
    "category": "LLM08: Excessive Agency",
    "severity": "CRITICAL",
    "confidence": 0.75,
    "description": "Agent executes system command",
    "file_path": "examples/autonomous_agent.md",
    "code_snippet": "os.system(plan['action'])",
    "is_true_positive": true
  },
  {
    "id": "LLM07_TP_0331",
    "category": "LLM07: Insecure Plugin",
    "severity": "LOW",
    "confidence": 0.72,
    "description": "Plugin zip downloaded from URL (synthetic variation)",
    "file_path": "plugins/manager.py",
    "code_snippet": "zip_ref.extractall('/opt/plugins')",
    "is_true_positive": true
  },
  {
    "id": "LLM03_FP_0332",
    "category": "LLM03: Training Poisoning",
    "severity": "LOW",
    "confidence": 0.38,
    "description": "model.eval() inference mode",
    "file_path": "tests/fakes/datasets.py",
    "code_snippet": "self.model.eval()",
    "is_true_positive": false
  },
  {
    "id": "LLM08_TP_0333",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.72,
    "description": "Agent executes system command",
    "file_path": "agents/finance_agent.py",
    "code_snippet": "os.system(plan['action'])",
    "is_true_positive": true
  },
  {
    "id": "LLM09_FP_0334",
    "category": "LLM09: Overreliance",
    "severity": "LOW",
    "confidence": 0.38,
    "description": "Unit test asserting human review",
    "file_path": "decision/approver.py",
    "code_snippet": "assert pipeline.requires_human_review is True",
    "is_true_positive": false
  },
  {
    "id": "LLM10_FP_0335",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.46,
    "description": "Docs describing scp export",
    "file_path": "docs/model_export.md",
    "code_snippet": "scp model.bin user@host",
    "is_true_positive": false
  },
  {
    "id": "LLM02_FP_0336",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.49,
    "description": "SQLAlchemy session.exec mistaken for exec (synthetic variation)",
    "file_path": "db/auto_sql.py",
    "code_snippet": "result = session.exec(select(User))",
    "is_true_positive": false
  },
  {
    "id": "LLM05_TP_0337",
    "category": "LLM05: Supply Chain",
    "severity": "MEDIUM",
    "confidence": 0.82,
    "description": "trust_remote_code=True on AutoModel",
    "file_path": "models/loader.py",
    "code_snippet": "AutoModel.from_pretrained(repo, trust_remote_code=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM08_FP_0338",
    "category": "LLM08: Excessive Agency",
    "severity": "LOW",
    "confidence": 0.62,
    "description": "Demo described in README",
    "file_path": "agents/controller.py",
    "code_snippet": "agent.run('book a flight')",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0339",
    "category": "LLM10: Model Theft",
    "severity": "HIGH",
    "confidence": 0.7,
    "description": "Endpoint serves model weights",
    "file_path": "api/completions.py",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0340",
    "category": "LLM10: Model Theft",
    "severity": "HIGH",
    "confidence": 0.82,
    "description": "API exposes logprobs enabling extraction",
    "file_path": "docs/model_export.md",
    "code_snippet": "client.chat.completions.create(logprobs=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0341",
    "category": "LLM10: Model Theft",
    "severity": "CRITICAL",
    "confidence": 0.79,
    "description": "API exposes logprobs enabling extraction",
    "file_path": "api/completions.py",
    "code_snippet": "client.chat.completions.create(logprobs=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0342",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.81,
    "description": "LLM output with AWS key logged",
    "file_path": "monitoring/logging.py",
    "code_snippet": "logger.info(f'Key leaked: {response}')",
    "is_true_positive": true
  },
  {
    "id": "LLM07_TP_0343",
    "category": "LLM07: Insecure Plugin",
    "severity": "LOW",
    "confidence": 0.97,
    "description": "Plugin executes shell command",
    "file_path": "plugins/manager.py",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM04_TP_0344",
    "category": "LLM04: Model Denial of Service",
    "severity": "CRITICAL",
    "confidence": 0.89,
    "description": "Async gather spawns many completions (synthetic variation)",
    "file_path": "workers/auto_refiner.py",
    "code_snippet": "await asyncio.gather(*[call_llm(q) for q in queue])",
    "is_true_positive": true
  },
  {
    "id": "LLM05_TP_0345",
    "category": "LLM05: Supply Chain",
    "severity": "CRITICAL",
    "confidence": 0.72,
    "description": "trust_remote_code=True on AutoModel",
    "file_path": "security/downloader.py",
    "code_snippet": "AutoModel.from_pretrained(repo, trust_remote_code=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM08_FP_0346",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.61,
    "description": "Demo described in README",
    "file_path": "agents/finance_agent.py",
    "code_snippet": "agent.run('book a flight')",
    "is_true_positive": false
  },
  {
    "id": "LLM10_FP_0347",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.59,
    "description": "Signed URL enforced",
    "file_path": "api/models.py",
    "code_snippet": "return generate_signed_url('model.bin', expires=30)",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0348",
    "category": "LLM10: Model Theft",
    "severity": "CRITICAL",
    "confidence": 0.73,
    "description": "API exposes logprobs enabling extraction (synthetic variation)",
    "file_path": "api/secure_download.py",
    "code_snippet": "client.chat.completions.create(logprobs=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM04_TP_0349",
    "category": "LLM04: Model Denial of Service",
    "severity": "HIGH",
    "confidence": 0.81,
    "description": "Unbounded while loop hitting OpenAI",
    "file_path": "tests/dos/test_rate_limit.py",
    "code_snippet": "while True:\n    client.chat.completions.create(... )",
    "is_true_positive": true
  },
  {
    "id": "LLM10_FP_0350",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.53,
    "description": "Signed URL enforced (synthetic variation)",
    "file_path": "api/secure_download.py",
    "code_snippet": "return generate_signed_url('model.bin', expires=30)",
    "is_true_positive": false
  },
  {
    "id": "LLM02_TP_0351",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.8,
    "description": "LLM response executed via eval",
    "file_path": "app/repository.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0352",
    "category": "LLM09: Overreliance",
    "severity": "CRITICAL",
    "confidence": 0.9,
    "description": "LLM summary emailed automatically",
    "file_path": "decision/approver.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0353",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.88,
    "description": "LLM response executed via eval",
    "file_path": "agents/code_exec.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM03_FP_0354",
    "category": "LLM03: Training Poisoning",
    "severity": "HIGH",
    "confidence": 0.41,
    "description": "torch random_split in tests",
    "file_path": "training/load_weights.py",
    "code_snippet": "train, test = random_split(dataset, [80, 20])",
    "is_true_positive": false
  },
  {
    "id": "LLM08_TP_0355",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.88,
    "description": "Agent executes system command",
    "file_path": "agents/task_runner.py",
    "code_snippet": "os.system(plan['action'])",
    "is_true_positive": true
  },
  {
    "id": "LLM01_FP_0356",
    "category": "LLM01: Prompt Injection",
    "severity": "HIGH",
    "confidence": 0.51,
    "description": "Unit test fixture builds fake prompts (synthetic variation)",
    "file_path": "examples/prompts/prompt_injection.ipynb",
    "code_snippet": "def prompt_fixture(): return f'ignore rules {seed}'",
    "is_true_positive": false
  },
  {
    "id": "LLM04_TP_0357",
    "category": "LLM04: Model Denial of Service",
    "severity": "MEDIUM",
    "confidence": 0.8,
    "description": "Unbounded while loop hitting OpenAI (synthetic variation)",
    "file_path": "workers/auto_refiner.py",
    "code_snippet": "while True:\n    client.chat.completions.create(... )",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0358",
    "category": "LLM02: Insecure Output",
    "severity": "CRITICAL",
    "confidence": 0.87,
    "description": "SQL built from LLM output",
    "file_path": "app/repository.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0359",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.96,
    "description": "LLM output with AWS key logged",
    "file_path": "monitoring/logging.py",
    "code_snippet": "logger.info(f'Key leaked: {response}')",
    "is_true_positive": true
  },
  {
    "id": "LLM03_TP_0360",
    "category": "LLM03: Training Poisoning",
    "severity": "LOW",
    "confidence": 0.75,
    "description": "Training data pulled from unsecured URL",
    "file_path": "tests/fakes/datasets.py",
    "code_snippet": "data = json.loads(requests.get(feed).text)",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0361",
    "category": "LLM09: Overreliance",
    "severity": "CRITICAL",
    "confidence": 0.75,
    "description": "Auto-approves compliance decision",
    "file_path": "tests/workflows/test_review.py",
    "code_snippet": "if model.confidence > 0.2: return 'approved'",
    "is_true_positive": true
  },
  {
    "id": "LLM03_FP_0362",
    "category": "LLM03: Training Poisoning",
    "severity": "LOW",
    "confidence": 0.42,
    "description": "model.eval() inference mode",
    "file_path": "tests/fakes/datasets.py",
    "code_snippet": "self.model.eval()",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0363",
    "category": "LLM10: Model Theft",
    "severity": "CRITICAL",
    "confidence": 0.74,
    "description": "API exposes logprobs enabling extraction",
    "file_path": "api/models.py",
    "code_snippet": "client.chat.completions.create(logprobs=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0364",
    "category": "LLM09: Overreliance",
    "severity": "CRITICAL",
    "confidence": 0.82,
    "description": "LLM summary emailed automatically",
    "file_path": "tests/workflows/test_review.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM08_TP_0365",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.71,
    "description": "Agent transfers funds autonomously (synthetic variation)",
    "file_path": "agents/task_runner.py",
    "code_snippet": "bank.transfer(amount, destination, auto_execute=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM05_TP_0366",
    "category": "LLM05: Supply Chain",
    "severity": "LOW",
    "confidence": 0.86,
    "description": "Agent executes pip install from LLM (synthetic variation)",
    "file_path": "security/downloader.py",
    "code_snippet": "subprocess.run(['pip', 'install', llm_pkg], check=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM09_FP_0367",
    "category": "LLM09: Overreliance",
    "severity": "HIGH",
    "confidence": 0.51,
    "description": "Unit test asserting human review (synthetic variation)",
    "file_path": "decision/approver.py",
    "code_snippet": "assert pipeline.requires_human_review is True",
    "is_true_positive": false
  },
  {
    "id": "LLM07_TP_0368",
    "category": "LLM07: Insecure Plugin",
    "severity": "LOW",
    "confidence": 0.83,
    "description": "Plugin executes shell command",
    "file_path": "plugins/registry.py",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0369",
    "category": "LLM02: Insecure Output",
    "severity": "MEDIUM",
    "confidence": 0.93,
    "description": "LLM response executed via eval",
    "file_path": "db/auto_sql.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0370",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.4,
    "description": "Base64 image asset (synthetic variation)",
    "file_path": "monitoring/logging.py",
    "code_snippet": "LOGO = 'data:image/png;base64,iVBORw0KGgoAAAANS...'",
    "is_true_positive": false
  },
  {
    "id": "LLM04_FP_0371",
    "category": "LLM04: Model Denial of Service",
    "severity": "HIGH",
    "confidence": 0.55,
    "description": "Pytest simulating rate limit",
    "file_path": "routes/ask.py",
    "code_snippet": "for _ in range(5): client.chat.completions.create(... )",
    "is_true_positive": false
  },
  {
    "id": "LLM05_TP_0372",
    "category": "LLM05: Supply Chain",
    "severity": "MEDIUM",
    "confidence": 0.97,
    "description": "Agent executes pip install from LLM",
    "file_path": "models/loader.py",
    "code_snippet": "subprocess.run(['pip', 'install', llm_pkg], check=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM01_FP_0373",
    "category": "LLM01: Prompt Injection",
    "severity": "LOW",
    "confidence": 0.4,
    "description": "Unit test fixture builds fake prompts",
    "file_path": "pipelines/langchain_agent.py",
    "code_snippet": "def prompt_fixture(): return f'ignore rules {seed}'",
    "is_true_positive": false
  },
  {
    "id": "LLM04_FP_0374",
    "category": "LLM04: Model Denial of Service",
    "severity": "LOW",
    "confidence": 0.56,
    "description": "Pytest simulating rate limit (synthetic variation)",
    "file_path": "tests/dos/test_rate_limit.py",
    "code_snippet": "for _ in range(5): client.chat.completions.create(... )",
    "is_true_positive": false
  },
  {
    "id": "LLM07_TP_0375",
    "category": "LLM07: Insecure Plugin",
    "severity": "CRITICAL",
    "confidence": 0.84,
    "description": "Plugin executes shell command (synthetic variation)",
    "file_path": "plugins/shell_tool.py",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0376",
    "category": "LLM06: Sensitive Info",
    "severity": "LOW",
    "confidence": 0.94,
    "description": "LLM output with AWS key logged",
    "file_path": "config/settings.py",
    "code_snippet": "logger.info(f'Key leaked: {response}')",
    "is_true_positive": true
  },
  {
    "id": "LLM02_FP_0377",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.64,
    "description": "Docs logging example output",
    "file_path": "app/repository.py",
    "code_snippet": "print('LLM output:', response.text)",
    "is_true_positive": false
  },
  {
    "id": "LLM07_FP_0378",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.66,
    "description": "Docs describing plugin install",
    "file_path": "plugins/registry.py",
    "code_snippet": "Install shell plugin by running ./install.sh",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0379",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.71,
    "description": "API exposes logprobs enabling extraction",
    "file_path": "api/secure_download.py",
    "code_snippet": "client.chat.completions.create(logprobs=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM08_TP_0380",
    "category": "LLM08: Excessive Agency",
    "severity": "CRITICAL",
    "confidence": 0.7,
    "description": "Agent transfers funds autonomously",
    "file_path": "examples/autonomous_agent.md",
    "code_snippet": "bank.transfer(amount, destination, auto_execute=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM04_FP_0381",
    "category": "LLM04: Model Denial of Service",
    "severity": "LOW",
    "confidence": 0.67,
    "description": "Single completion call flagged",
    "file_path": "routes/ask.py",
    "code_snippet": "client.chat.completions.create(model=MODEL, messages=msgs)",
    "is_true_positive": false
  },
  {
    "id": "LLM02_FP_0382",
    "category": "LLM02: Insecure Output",
    "severity": "MEDIUM",
    "confidence": 0.6,
    "description": "Docs logging example output",
    "file_path": "agents/code_exec.py",
    "code_snippet": "print('LLM output:', response.text)",
    "is_true_positive": false
  },
  {
    "id": "LLM01_TP_0383",
    "category": "LLM01: Prompt Injection",
    "severity": "CRITICAL",
    "confidence": 0.88,
    "description": "LangChain template concatenates untrusted context",
    "file_path": "pipelines/langchain_agent.py",
    "code_snippet": "template = ChatPromptTemplate.from_messages([(\"system\", ctx + prompt)])",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0384",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.85,
    "description": "Direct f-string injection into system prompt",
    "file_path": "pipelines/langchain_agent.py",
    "code_snippet": "messages = [{\"role\": \"system\", \"content\": f'Policy: {user_input}'}]",
    "is_true_positive": true
  },
  {
    "id": "LLM01_FP_0385",
    "category": "LLM01: Prompt Injection",
    "severity": "HIGH",
    "confidence": 0.4,
    "description": "Unit test fixture builds fake prompts (synthetic variation)",
    "file_path": "examples/prompts/prompt_injection.ipynb",
    "code_snippet": "def prompt_fixture(): return f'ignore rules {seed}'",
    "is_true_positive": false
  },
  {
    "id": "LLM07_TP_0386",
    "category": "LLM07: Insecure Plugin",
    "severity": "HIGH",
    "confidence": 0.8,
    "description": "Plugin executes shell command (synthetic variation)",
    "file_path": "plugins/shell_tool.py",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM07_FP_0387",
    "category": "LLM07: Insecure Plugin",
    "severity": "LOW",
    "confidence": 0.55,
    "description": "Plugin registry enforces allowlist (synthetic variation)",
    "file_path": "plugins/manager.py",
    "code_snippet": "if plugin_id not in ALLOWED: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM03_TP_0388",
    "category": "LLM03: Training Poisoning",
    "severity": "CRITICAL",
    "confidence": 0.87,
    "description": "Training data pulled from unsecured URL",
    "file_path": "training/load_weights.py",
    "code_snippet": "data = json.loads(requests.get(feed).text)",
    "is_true_positive": true
  },
  {
    "id": "LLM04_TP_0389",
    "category": "LLM04: Model Denial of Service",
    "severity": "LOW",
    "confidence": 0.87,
    "description": "Unbounded while loop hitting OpenAI",
    "file_path": "services/parallel_runner.py",
    "code_snippet": "while True:\n    client.chat.completions.create(... )",
    "is_true_positive": true
  },
  {
    "id": "LLM07_TP_0390",
    "category": "LLM07: Insecure Plugin",
    "severity": "HIGH",
    "confidence": 0.88,
    "description": "Plugin executes shell command (synthetic variation)",
    "file_path": "plugins/manager.py",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM10_FP_0391",
    "category": "LLM10: Model Theft",
    "severity": "HIGH",
    "confidence": 0.67,
    "description": "Docs describing scp export (synthetic variation)",
    "file_path": "api/models.py",
    "code_snippet": "scp model.bin user@host",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0392",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.92,
    "description": "API exposes logprobs enabling extraction",
    "file_path": "api/secure_download.py",
    "code_snippet": "client.chat.completions.create(logprobs=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM04_TP_0393",
    "category": "LLM04: Model Denial of Service",
    "severity": "CRITICAL",
    "confidence": 0.88,
    "description": "Unbounded while loop hitting OpenAI (synthetic variation)",
    "file_path": "services/parallel_runner.py",
    "code_snippet": "while True:\n    client.chat.completions.create(... )",
    "is_true_positive": true
  },
  {
    "id": "LLM01_FP_0394",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.67,
    "description": "Example notebook demonstrates prompts",
    "file_path": "pipelines/langchain_agent.py",
    "code_snippet": "SYSTEM_PROMPT = 'Your name is {username}'",
    "is_true_positive": false
  },
  {
    "id": "LLM06_TP_0395",
    "category": "LLM06: Sensitive Info",
    "severity": "LOW",
    "confidence": 0.7,
    "description": "Hardcoded OpenAI key (synthetic variation)",
    "file_path": "docs/assets/logo.py",
    "code_snippet": "os.environ['OPENAI_API_KEY'] = 'sk-live-123456789'",
    "is_true_positive": true
  },
  {
    "id": "LLM05_TP_0396",
    "category": "LLM05: Supply Chain",
    "severity": "HIGH",
    "confidence": 0.88,
    "description": "trust_remote_code=True on AutoModel",
    "file_path": "security/downloader.py",
    "code_snippet": "AutoModel.from_pretrained(repo, trust_remote_code=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM07_TP_0397",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.78,
    "description": "Plugin zip downloaded from URL",
    "file_path": "plugins/shell_tool.py",
    "code_snippet": "zip_ref.extractall('/opt/plugins')",
    "is_true_positive": true
  },
  {
    "id": "LLM09_FP_0398",
    "category": "LLM09: Overreliance",
    "severity": "MEDIUM",
    "confidence": 0.57,
    "description": "Workflow requires reviewer",
    "file_path": "workflows/human_loop.py",
    "code_snippet": "if not reviewer.signoff(result): return",
    "is_true_positive": false
  },
  {
    "id": "LLM02_TP_0399",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.77,
    "description": "SQL built from LLM output",
    "file_path": "db/auto_sql.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0400",
    "category": "LLM02: Insecure Output",
    "severity": "MEDIUM",
    "confidence": 0.73,
    "description": "LLM response executed via eval",
    "file_path": "app/repository.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0401",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.8,
    "description": "LangChain template concatenates untrusted context",
    "file_path": "tests/test_prompt_injection.py",
    "code_snippet": "template = ChatPromptTemplate.from_messages([(\"system\", ctx + prompt)])",
    "is_true_positive": true
  },
  {
    "id": "LLM05_FP_0402",
    "category": "LLM05: Supply Chain",
    "severity": "MEDIUM",
    "confidence": 0.65,
    "description": "Docs show requirements snippet (synthetic variation)",
    "file_path": "models/loader.py",
    "code_snippet": "pip install torch==2.2.1",
    "is_true_positive": false
  },
  {
    "id": "LLM02_TP_0403",
    "category": "LLM02: Insecure Output",
    "severity": "CRITICAL",
    "confidence": 0.84,
    "description": "LLM response executed via eval (synthetic variation)",
    "file_path": "docs/examples/output_handling.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0404",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.95,
    "description": "Endpoint serves model weights",
    "file_path": "api/secure_download.py",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0405",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.77,
    "description": "LLM response executed via eval",
    "file_path": "agents/code_exec.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM07_FP_0406",
    "category": "LLM07: Insecure Plugin",
    "severity": "HIGH",
    "confidence": 0.65,
    "description": "Plugin registry enforces allowlist",
    "file_path": "plugins/shell_tool.py",
    "code_snippet": "if plugin_id not in ALLOWED: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM07_TP_0407",
    "category": "LLM07: Insecure Plugin",
    "severity": "HIGH",
    "confidence": 0.78,
    "description": "Plugin executes shell command (synthetic variation)",
    "file_path": "docs/plugins.md",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0408",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.93,
    "description": "Hardcoded OpenAI key",
    "file_path": "monitoring/logging.py",
    "code_snippet": "os.environ['OPENAI_API_KEY'] = 'sk-live-123456789'",
    "is_true_positive": true
  },
  {
    "id": "LLM07_TP_0409",
    "category": "LLM07: Insecure Plugin",
    "severity": "HIGH",
    "confidence": 0.79,
    "description": "Plugin zip downloaded from URL",
    "file_path": "plugins/registry.py",
    "code_snippet": "zip_ref.extractall('/opt/plugins')",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0410",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.83,
    "description": "LangChain template concatenates untrusted context",
    "file_path": "tests/test_prompt_injection.py",
    "code_snippet": "template = ChatPromptTemplate.from_messages([(\"system\", ctx + prompt)])",
    "is_true_positive": true
  },
  {
    "id": "LLM08_FP_0411",
    "category": "LLM08: Excessive Agency",
    "severity": "LOW",
    "confidence": 0.35,
    "description": "Manual approval required",
    "file_path": "agents/task_runner.py",
    "code_snippet": "if not require_human_confirmation(task): raise",
    "is_true_positive": false
  },
  {
    "id": "LLM04_TP_0412",
    "category": "LLM04: Model Denial of Service",
    "severity": "LOW",
    "confidence": 0.91,
    "description": "Unbounded while loop hitting OpenAI",
    "file_path": "routes/ask.py",
    "code_snippet": "while True:\n    client.chat.completions.create(... )",
    "is_true_positive": true
  },
  {
    "id": "LLM05_TP_0413",
    "category": "LLM05: Supply Chain",
    "severity": "CRITICAL",
    "confidence": 0.97,
    "description": "trust_remote_code=True on AutoModel",
    "file_path": "security/downloader.py",
    "code_snippet": "AutoModel.from_pretrained(repo, trust_remote_code=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM03_FP_0414",
    "category": "LLM03: Training Poisoning",
    "severity": "LOW",
    "confidence": 0.68,
    "description": "torch random_split in tests",
    "file_path": "training/data_loader.py",
    "code_snippet": "train, test = random_split(dataset, [80, 20])",
    "is_true_positive": false
  },
  {
    "id": "LLM06_TP_0415",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.88,
    "description": "Hardcoded OpenAI key",
    "file_path": "notebooks/openai_quickstart.ipynb",
    "code_snippet": "os.environ['OPENAI_API_KEY'] = 'sk-live-123456789'",
    "is_true_positive": true
  },
  {
    "id": "LLM10_FP_0416",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.46,
    "description": "Docs describing scp export",
    "file_path": "api/completions.py",
    "code_snippet": "scp model.bin user@host",
    "is_true_positive": false
  },
  {
    "id": "LLM07_FP_0417",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.45,
    "description": "Docs describing plugin install (synthetic variation)",
    "file_path": "plugins/registry.py",
    "code_snippet": "Install shell plugin by running ./install.sh",
    "is_true_positive": false
  },
  {
    "id": "LLM04_TP_0418",
    "category": "LLM04: Model Denial of Service",
    "severity": "LOW",
    "confidence": 0.75,
    "description": "Unbounded while loop hitting OpenAI",
    "file_path": "services/parallel_runner.py",
    "code_snippet": "while True:\n    client.chat.completions.create(... )",
    "is_true_positive": true
  },
  {
    "id": "LLM07_TP_0419",
    "category": "LLM07: Insecure Plugin",
    "severity": "CRITICAL",
    "confidence": 0.79,
    "description": "Plugin zip downloaded from URL (synthetic variation)",
    "file_path": "plugins/manager.py",
    "code_snippet": "zip_ref.extractall('/opt/plugins')",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0420",
    "category": "LLM02: Insecure Output",
    "severity": "MEDIUM",
    "confidence": 0.93,
    "description": "SQL built from LLM output",
    "file_path": "agents/code_exec.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM02_FP_0421",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.37,
    "description": "Docs logging example output (synthetic variation)",
    "file_path": "docs/examples/output_handling.py",
    "code_snippet": "print('LLM output:', response.text)",
    "is_true_positive": false
  },
  {
    "id": "LLM03_TP_0422",
    "category": "LLM03: Training Poisoning",
    "severity": "MEDIUM",
    "confidence": 0.73,
    "description": "Weights loaded via pickle from user path (synthetic variation)",
    "file_path": "models/bert_wrapper.py",
    "code_snippet": "weights = pickle.load(open(model_path, 'rb'))",
    "is_true_positive": true
  },
  {
    "id": "LLM03_TP_0423",
    "category": "LLM03: Training Poisoning",
    "severity": "MEDIUM",
    "confidence": 0.76,
    "description": "Training data pulled from unsecured URL",
    "file_path": "training/load_weights.py",
    "code_snippet": "data = json.loads(requests.get(feed).text)",
    "is_true_positive": true
  },
  {
    "id": "LLM02_FP_0424",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.72,
    "description": "Docs logging example output (synthetic variation)",
    "file_path": "agents/code_exec.py",
    "code_snippet": "print('LLM output:', response.text)",
    "is_true_positive": false
  },
  {
    "id": "LLM08_FP_0425",
    "category": "LLM08: Excessive Agency",
    "severity": "LOW",
    "confidence": 0.37,
    "description": "Manual approval required",
    "file_path": "agents/controller.py",
    "code_snippet": "if not require_human_confirmation(task): raise",
    "is_true_positive": false
  },
  {
    "id": "LLM03_FP_0426",
    "category": "LLM03: Training Poisoning",
    "severity": "MEDIUM",
    "confidence": 0.36,
    "description": "model.eval() inference mode",
    "file_path": "models/bert_wrapper.py",
    "code_snippet": "self.model.eval()",
    "is_true_positive": false
  },
  {
    "id": "LLM03_TP_0427",
    "category": "LLM03: Training Poisoning",
    "severity": "HIGH",
    "confidence": 0.82,
    "description": "Training data pulled from unsecured URL (synthetic variation)",
    "file_path": "tests/fakes/datasets.py",
    "code_snippet": "data = json.loads(requests.get(feed).text)",
    "is_true_positive": true
  },
  {
    "id": "LLM10_FP_0428",
    "category": "LLM10: Model Theft",
    "severity": "MEDIUM",
    "confidence": 0.5,
    "description": "Signed URL enforced",
    "file_path": "api/secure_download.py",
    "code_snippet": "return generate_signed_url('model.bin', expires=30)",
    "is_true_positive": false
  },
  {
    "id": "LLM01_TP_0429",
    "category": "LLM01: Prompt Injection",
    "severity": "CRITICAL",
    "confidence": 0.76,
    "description": "LangChain template concatenates untrusted context",
    "file_path": "pipelines/langchain_agent.py",
    "code_snippet": "template = ChatPromptTemplate.from_messages([(\"system\", ctx + prompt)])",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0430",
    "category": "LLM09: Overreliance",
    "severity": "HIGH",
    "confidence": 0.83,
    "description": "Auto-approves compliance decision",
    "file_path": "tests/workflows/test_review.py",
    "code_snippet": "if model.confidence > 0.2: return 'approved'",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0431",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.42,
    "description": "Base64 image asset",
    "file_path": "docs/assets/logo.py",
    "code_snippet": "LOGO = 'data:image/png;base64,iVBORw0KGgoAAAANS...'",
    "is_true_positive": false
  },
  {
    "id": "LLM04_TP_0432",
    "category": "LLM04: Model Denial of Service",
    "severity": "CRITICAL",
    "confidence": 0.85,
    "description": "Async gather spawns many completions",
    "file_path": "workers/auto_refiner.py",
    "code_snippet": "await asyncio.gather(*[call_llm(q) for q in queue])",
    "is_true_positive": true
  },
  {
    "id": "LLM04_FP_0433",
    "category": "LLM04: Model Denial of Service",
    "severity": "HIGH",
    "confidence": 0.44,
    "description": "Single completion call flagged",
    "file_path": "services/parallel_runner.py",
    "code_snippet": "client.chat.completions.create(model=MODEL, messages=msgs)",
    "is_true_positive": false
  },
  {
    "id": "LLM01_FP_0434",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.7,
    "description": "Unit test fixture builds fake prompts",
    "file_path": "examples/prompts/prompt_injection.ipynb",
    "code_snippet": "def prompt_fixture(): return f'ignore rules {seed}'",
    "is_true_positive": false
  },
  {
    "id": "LLM03_TP_0435",
    "category": "LLM03: Training Poisoning",
    "severity": "LOW",
    "confidence": 0.9,
    "description": "Weights loaded via pickle from user path",
    "file_path": "tests/fakes/datasets.py",
    "code_snippet": "weights = pickle.load(open(model_path, 'rb'))",
    "is_true_positive": true
  },
  {
    "id": "LLM10_FP_0436",
    "category": "LLM10: Model Theft",
    "severity": "HIGH",
    "confidence": 0.46,
    "description": "Signed URL enforced",
    "file_path": "docs/model_export.md",
    "code_snippet": "return generate_signed_url('model.bin', expires=30)",
    "is_true_positive": false
  },
  {
    "id": "LLM02_TP_0437",
    "category": "LLM02: Insecure Output",
    "severity": "CRITICAL",
    "confidence": 0.7,
    "description": "LLM response executed via eval",
    "file_path": "agents/code_exec.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM04_FP_0438",
    "category": "LLM04: Model Denial of Service",
    "severity": "MEDIUM",
    "confidence": 0.37,
    "description": "Pytest simulating rate limit (synthetic variation)",
    "file_path": "services/parallel_runner.py",
    "code_snippet": "for _ in range(5): client.chat.completions.create(... )",
    "is_true_positive": false
  },
  {
    "id": "LLM03_FP_0439",
    "category": "LLM03: Training Poisoning",
    "severity": "MEDIUM",
    "confidence": 0.61,
    "description": "model.eval() inference mode",
    "file_path": "training/data_loader.py",
    "code_snippet": "self.model.eval()",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0440",
    "category": "LLM10: Model Theft",
    "severity": "MEDIUM",
    "confidence": 0.97,
    "description": "API exposes logprobs enabling extraction",
    "file_path": "api/secure_download.py",
    "code_snippet": "client.chat.completions.create(logprobs=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM07_FP_0441",
    "category": "LLM07: Insecure Plugin",
    "severity": "LOW",
    "confidence": 0.61,
    "description": "Docs describing plugin install",
    "file_path": "plugins/registry.py",
    "code_snippet": "Install shell plugin by running ./install.sh",
    "is_true_positive": false
  },
  {
    "id": "LLM10_FP_0442",
    "category": "LLM10: Model Theft",
    "severity": "MEDIUM",
    "confidence": 0.46,
    "description": "Signed URL enforced",
    "file_path": "api/completions.py",
    "code_snippet": "return generate_signed_url('model.bin', expires=30)",
    "is_true_positive": false
  },
  {
    "id": "LLM03_TP_0443",
    "category": "LLM03: Training Poisoning",
    "severity": "LOW",
    "confidence": 0.75,
    "description": "Training data pulled from unsecured URL",
    "file_path": "models/bert_wrapper.py",
    "code_snippet": "data = json.loads(requests.get(feed).text)",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0444",
    "category": "LLM10: Model Theft",
    "severity": "MEDIUM",
    "confidence": 0.79,
    "description": "Endpoint serves model weights (synthetic variation)",
    "file_path": "docs/model_export.md",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0445",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.6,
    "description": "Env var reference",
    "file_path": "notebooks/openai_quickstart.ipynb",
    "code_snippet": "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')",
    "is_true_positive": false
  },
  {
    "id": "LLM06_TP_0446",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.89,
    "description": "LLM output with AWS key logged",
    "file_path": "monitoring/logging.py",
    "code_snippet": "logger.info(f'Key leaked: {response}')",
    "is_true_positive": true
  },
  {
    "id": "LLM02_FP_0447",
    "category": "LLM02: Insecure Output",
    "severity": "MEDIUM",
    "confidence": 0.62,
    "description": "SQLAlchemy session.exec mistaken for exec",
    "file_path": "docs/examples/output_handling.py",
    "code_snippet": "result = session.exec(select(User))",
    "is_true_positive": false
  },
  {
    "id": "LLM07_TP_0448",
    "category": "LLM07: Insecure Plugin",
    "severity": "CRITICAL",
    "confidence": 0.73,
    "description": "Plugin zip downloaded from URL",
    "file_path": "plugins/registry.py",
    "code_snippet": "zip_ref.extractall('/opt/plugins')",
    "is_true_positive": true
  },
  {
    "id": "LLM10_FP_0449",
    "category": "LLM10: Model Theft",
    "severity": "MEDIUM",
    "confidence": 0.38,
    "description": "Signed URL enforced",
    "file_path": "api/completions.py",
    "code_snippet": "return generate_signed_url('model.bin', expires=30)",
    "is_true_positive": false
  },
  {
    "id": "LLM05_TP_0450",
    "category": "LLM05: Supply Chain",
    "severity": "LOW",
    "confidence": 0.8,
    "description": "Agent executes pip install from LLM",
    "file_path": "models/loader.py",
    "code_snippet": "subprocess.run(['pip', 'install', llm_pkg], check=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM03_FP_0451",
    "category": "LLM03: Training Poisoning",
    "severity": "HIGH",
    "confidence": 0.71,
    "description": "torch random_split in tests",
    "file_path": "tests/fakes/datasets.py",
    "code_snippet": "train, test = random_split(dataset, [80, 20])",
    "is_true_positive": false
  },
  {
    "id": "LLM01_TP_0452",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.71,
    "description": "Direct f-string injection into system prompt",
    "file_path": "examples/prompts/prompt_injection.ipynb",
    "code_snippet": "messages = [{\"role\": \"system\", \"content\": f'Policy: {user_input}'}]",
    "is_true_positive": true
  },
  {
    "id": "LLM04_TP_0453",
    "category": "LLM04: Model Denial of Service",
    "severity": "HIGH",
    "confidence": 0.77,
    "description": "Async gather spawns many completions (synthetic variation)",
    "file_path": "routes/ask.py",
    "code_snippet": "await asyncio.gather(*[call_llm(q) for q in queue])",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0454",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.8,
    "description": "API exposes logprobs enabling extraction",
    "file_path": "api/completions.py",
    "code_snippet": "client.chat.completions.create(logprobs=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM05_FP_0455",
    "category": "LLM05: Supply Chain",
    "severity": "LOW",
    "confidence": 0.36,
    "description": "Download guarded by sha256 verification (synthetic variation)",
    "file_path": "agents/tool_executor.py",
    "code_snippet": "if sha256(data).hexdigest() != expected_hash: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM05_FP_0456",
    "category": "LLM05: Supply Chain",
    "severity": "MEDIUM",
    "confidence": 0.64,
    "description": "Download guarded by sha256 verification",
    "file_path": "models/loader.py",
    "code_snippet": "if sha256(data).hexdigest() != expected_hash: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM05_TP_0457",
    "category": "LLM05: Supply Chain",
    "severity": "HIGH",
    "confidence": 0.95,
    "description": "Agent executes pip install from LLM",
    "file_path": "agents/tool_executor.py",
    "code_snippet": "subprocess.run(['pip', 'install', llm_pkg], check=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM08_TP_0458",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.76,
    "description": "Agent executes system command (synthetic variation)",
    "file_path": "examples/autonomous_agent.md",
    "code_snippet": "os.system(plan['action'])",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0459",
    "category": "LLM01: Prompt Injection",
    "severity": "HIGH",
    "confidence": 0.93,
    "description": "Direct f-string injection into system prompt",
    "file_path": "src/chatbot/services/conversation.py",
    "code_snippet": "messages = [{\"role\": \"system\", \"content\": f'Policy: {user_input}'}]",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0460",
    "category": "LLM10: Model Theft",
    "severity": "CRITICAL",
    "confidence": 0.97,
    "description": "Endpoint serves model weights",
    "file_path": "docs/model_export.md",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM08_FP_0461",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.38,
    "description": "Manual approval required",
    "file_path": "examples/autonomous_agent.md",
    "code_snippet": "if not require_human_confirmation(task): raise",
    "is_true_positive": false
  },
  {
    "id": "LLM01_TP_0462",
    "category": "LLM01: Prompt Injection",
    "severity": "CRITICAL",
    "confidence": 0.75,
    "description": "Direct f-string injection into system prompt",
    "file_path": "src/chatbot/services/conversation.py",
    "code_snippet": "messages = [{\"role\": \"system\", \"content\": f'Policy: {user_input}'}]",
    "is_true_positive": true
  },
  {
    "id": "LLM04_FP_0463",
    "category": "LLM04: Model Denial of Service",
    "severity": "MEDIUM",
    "confidence": 0.38,
    "description": "Single completion call flagged",
    "file_path": "workers/auto_refiner.py",
    "code_snippet": "client.chat.completions.create(model=MODEL, messages=msgs)",
    "is_true_positive": false
  },
  {
    "id": "LLM04_FP_0464",
    "category": "LLM04: Model Denial of Service",
    "severity": "MEDIUM",
    "confidence": 0.69,
    "description": "Single completion call flagged",
    "file_path": "routes/ask.py",
    "code_snippet": "client.chat.completions.create(model=MODEL, messages=msgs)",
    "is_true_positive": false
  },
  {
    "id": "LLM02_TP_0465",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.85,
    "description": "SQL built from LLM output",
    "file_path": "app/repository.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM01_FP_0466",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.41,
    "description": "Example notebook demonstrates prompts",
    "file_path": "src/chatbot/services/conversation.py",
    "code_snippet": "SYSTEM_PROMPT = 'Your name is {username}'",
    "is_true_positive": false
  },
  {
    "id": "LLM10_FP_0467",
    "category": "LLM10: Model Theft",
    "severity": "HIGH",
    "confidence": 0.64,
    "description": "Signed URL enforced",
    "file_path": "api/models.py",
    "code_snippet": "return generate_signed_url('model.bin', expires=30)",
    "is_true_positive": false
  },
  {
    "id": "LLM09_FP_0468",
    "category": "LLM09: Overreliance",
    "severity": "MEDIUM",
    "confidence": 0.59,
    "description": "Unit test asserting human review",
    "file_path": "workflows/human_loop.py",
    "code_snippet": "assert pipeline.requires_human_review is True",
    "is_true_positive": false
  },
  {
    "id": "LLM08_TP_0469",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.87,
    "description": "Agent executes system command",
    "file_path": "examples/autonomous_agent.md",
    "code_snippet": "os.system(plan['action'])",
    "is_true_positive": true
  },
  {
    "id": "LLM07_TP_0470",
    "category": "LLM07: Insecure Plugin",
    "severity": "LOW",
    "confidence": 0.91,
    "description": "Plugin zip downloaded from URL",
    "file_path": "plugins/manager.py",
    "code_snippet": "zip_ref.extractall('/opt/plugins')",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0471",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.94,
    "description": "LLM output with AWS key logged",
    "file_path": "config/settings.py",
    "code_snippet": "logger.info(f'Key leaked: {response}')",
    "is_true_positive": true
  },
  {
    "id": "LLM02_FP_0472",
    "category": "LLM02: Insecure Output",
    "severity": "MEDIUM",
    "confidence": 0.71,
    "description": "SQLAlchemy session.exec mistaken for exec",
    "file_path": "db/auto_sql.py",
    "code_snippet": "result = session.exec(select(User))",
    "is_true_positive": false
  },
  {
    "id": "LLM06_TP_0473",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.82,
    "description": "LLM output with AWS key logged",
    "file_path": "notebooks/openai_quickstart.ipynb",
    "code_snippet": "logger.info(f'Key leaked: {response}')",
    "is_true_positive": true
  },
  {
    "id": "LLM07_FP_0474",
    "category": "LLM07: Insecure Plugin",
    "severity": "HIGH",
    "confidence": 0.64,
    "description": "Docs describing plugin install (synthetic variation)",
    "file_path": "plugins/shell_tool.py",
    "code_snippet": "Install shell plugin by running ./install.sh",
    "is_true_positive": false
  },
  {
    "id": "LLM09_TP_0475",
    "category": "LLM09: Overreliance",
    "severity": "MEDIUM",
    "confidence": 0.95,
    "description": "Auto-approves compliance decision (synthetic variation)",
    "file_path": "workflows/email_broadcast.py",
    "code_snippet": "if model.confidence > 0.2: return 'approved'",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0476",
    "category": "LLM01: Prompt Injection",
    "severity": "HIGH",
    "confidence": 0.9,
    "description": "LangChain template concatenates untrusted context (synthetic variation)",
    "file_path": "src/chatbot/services/conversation.py",
    "code_snippet": "template = ChatPromptTemplate.from_messages([(\"system\", ctx + prompt)])",
    "is_true_positive": true
  },
  {
    "id": "LLM08_TP_0477",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.8,
    "description": "Agent transfers funds autonomously",
    "file_path": "agents/finance_agent.py",
    "code_snippet": "bank.transfer(amount, destination, auto_execute=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM03_FP_0478",
    "category": "LLM03: Training Poisoning",
    "severity": "MEDIUM",
    "confidence": 0.41,
    "description": "model.eval() inference mode",
    "file_path": "tests/fakes/datasets.py",
    "code_snippet": "self.model.eval()",
    "is_true_positive": false
  },
  {
    "id": "LLM02_TP_0479",
    "category": "LLM02: Insecure Output",
    "severity": "MEDIUM",
    "confidence": 0.94,
    "description": "SQL built from LLM output",
    "file_path": "agents/code_exec.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM04_FP_0480",
    "category": "LLM04: Model Denial of Service",
    "severity": "MEDIUM",
    "confidence": 0.59,
    "description": "Single completion call flagged",
    "file_path": "services/parallel_runner.py",
    "code_snippet": "client.chat.completions.create(model=MODEL, messages=msgs)",
    "is_true_positive": false
  },
  {
    "id": "LLM01_TP_0481",
    "category": "LLM01: Prompt Injection",
    "severity": "LOW",
    "confidence": 0.76,
    "description": "Direct f-string injection into system prompt",
    "file_path": "pipelines/langchain_agent.py",
    "code_snippet": "messages = [{\"role\": \"system\", \"content\": f'Policy: {user_input}'}]",
    "is_true_positive": true
  },
  {
    "id": "LLM05_FP_0482",
    "category": "LLM05: Supply Chain",
    "severity": "MEDIUM",
    "confidence": 0.67,
    "description": "Download guarded by sha256 verification",
    "file_path": "security/downloader.py",
    "code_snippet": "if sha256(data).hexdigest() != expected_hash: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM04_TP_0483",
    "category": "LLM04: Model Denial of Service",
    "severity": "LOW",
    "confidence": 0.84,
    "description": "Async gather spawns many completions",
    "file_path": "workers/auto_refiner.py",
    "code_snippet": "await asyncio.gather(*[call_llm(q) for q in queue])",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0484",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.39,
    "description": "Base64 image asset (synthetic variation)",
    "file_path": "config/settings.py",
    "code_snippet": "LOGO = 'data:image/png;base64,iVBORw0KGgoAAAANS...'",
    "is_true_positive": false
  },
  {
    "id": "LLM05_FP_0485",
    "category": "LLM05: Supply Chain",
    "severity": "HIGH",
    "confidence": 0.61,
    "description": "Download guarded by sha256 verification",
    "file_path": "docs/getting_started.md",
    "code_snippet": "if sha256(data).hexdigest() != expected_hash: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM05_TP_0486",
    "category": "LLM05: Supply Chain",
    "severity": "CRITICAL",
    "confidence": 0.88,
    "description": "trust_remote_code=True on AutoModel",
    "file_path": "models/loader.py",
    "code_snippet": "AutoModel.from_pretrained(repo, trust_remote_code=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM01_FP_0487",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.5,
    "description": "Example notebook demonstrates prompts",
    "file_path": "tests/test_prompt_injection.py",
    "code_snippet": "SYSTEM_PROMPT = 'Your name is {username}'",
    "is_true_positive": false
  },
  {
    "id": "LLM10_FP_0488",
    "category": "LLM10: Model Theft",
    "severity": "HIGH",
    "confidence": 0.61,
    "description": "Signed URL enforced",
    "file_path": "api/secure_download.py",
    "code_snippet": "return generate_signed_url('model.bin', expires=30)",
    "is_true_positive": false
  },
  {
    "id": "LLM08_FP_0489",
    "category": "LLM08: Excessive Agency",
    "severity": "LOW",
    "confidence": 0.66,
    "description": "Demo described in README",
    "file_path": "agents/controller.py",
    "code_snippet": "agent.run('book a flight')",
    "is_true_positive": false
  },
  {
    "id": "LLM03_TP_0490",
    "category": "LLM03: Training Poisoning",
    "severity": "HIGH",
    "confidence": 0.9,
    "description": "Weights loaded via pickle from user path",
    "file_path": "training/load_weights.py",
    "code_snippet": "weights = pickle.load(open(model_path, 'rb'))",
    "is_true_positive": true
  },
  {
    "id": "LLM03_FP_0491",
    "category": "LLM03: Training Poisoning",
    "severity": "LOW",
    "confidence": 0.48,
    "description": "model.eval() inference mode",
    "file_path": "training/data_loader.py",
    "code_snippet": "self.model.eval()",
    "is_true_positive": false
  },
  {
    "id": "LLM05_TP_0492",
    "category": "LLM05: Supply Chain",
    "severity": "HIGH",
    "confidence": 0.86,
    "description": "Agent executes pip install from LLM",
    "file_path": "docs/getting_started.md",
    "code_snippet": "subprocess.run(['pip', 'install', llm_pkg], check=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0493",
    "category": "LLM02: Insecure Output",
    "severity": "MEDIUM",
    "confidence": 0.84,
    "description": "LLM response executed via eval",
    "file_path": "docs/examples/output_handling.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM07_TP_0494",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.74,
    "description": "Plugin zip downloaded from URL (synthetic variation)",
    "file_path": "plugins/shell_tool.py",
    "code_snippet": "zip_ref.extractall('/opt/plugins')",
    "is_true_positive": true
  },
  {
    "id": "LLM07_FP_0495",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.67,
    "description": "Docs describing plugin install (synthetic variation)",
    "file_path": "plugins/manager.py",
    "code_snippet": "Install shell plugin by running ./install.sh",
    "is_true_positive": false
  },
  {
    "id": "LLM02_TP_0496",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.7,
    "description": "LLM response executed via eval (synthetic variation)",
    "file_path": "app/repository.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM03_FP_0497",
    "category": "LLM03: Training Poisoning",
    "severity": "LOW",
    "confidence": 0.4,
    "description": "torch random_split in tests",
    "file_path": "models/bert_wrapper.py",
    "code_snippet": "train, test = random_split(dataset, [80, 20])",
    "is_true_positive": false
  },
  {
    "id": "LLM07_TP_0498",
    "category": "LLM07: Insecure Plugin",
    "severity": "LOW",
    "confidence": 0.71,
    "description": "Plugin zip downloaded from URL (synthetic variation)",
    "file_path": "docs/plugins.md",
    "code_snippet": "zip_ref.extractall('/opt/plugins')",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0499",
    "category": "LLM06: Sensitive Info",
    "severity": "LOW",
    "confidence": 0.6,
    "description": "Base64 image asset",
    "file_path": "monitoring/logging.py",
    "code_snippet": "LOGO = 'data:image/png;base64,iVBORw0KGgoAAAANS...'",
    "is_true_positive": false
  },
  {
    "id": "LLM04_TP_0500",
    "category": "LLM04: Model Denial of Service",
    "severity": "MEDIUM",
    "confidence": 0.73,
    "description": "Async gather spawns many completions",
    "file_path": "routes/ask.py",
    "code_snippet": "await asyncio.gather(*[call_llm(q) for q in queue])",
    "is_true_positive": true
  },
  {
    "id": "LLM05_TP_0501",
    "category": "LLM05: Supply Chain",
    "severity": "HIGH",
    "confidence": 0.83,
    "description": "trust_remote_code=True on AutoModel",
    "file_path": "docs/getting_started.md",
    "code_snippet": "AutoModel.from_pretrained(repo, trust_remote_code=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0502",
    "category": "LLM09: Overreliance",
    "severity": "CRITICAL",
    "confidence": 0.8,
    "description": "Auto-approves compliance decision (synthetic variation)",
    "file_path": "workflows/human_loop.py",
    "code_snippet": "if model.confidence > 0.2: return 'approved'",
    "is_true_positive": true
  },
  {
    "id": "LLM07_TP_0503",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.91,
    "description": "Plugin executes shell command",
    "file_path": "plugins/manager.py",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM03_TP_0504",
    "category": "LLM03: Training Poisoning",
    "severity": "HIGH",
    "confidence": 0.92,
    "description": "Training data pulled from unsecured URL",
    "file_path": "models/bert_wrapper.py",
    "code_snippet": "data = json.loads(requests.get(feed).text)",
    "is_true_positive": true
  },
  {
    "id": "LLM10_FP_0505",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.61,
    "description": "Signed URL enforced",
    "file_path": "api/models.py",
    "code_snippet": "return generate_signed_url('model.bin', expires=30)",
    "is_true_positive": false
  },
  {
    "id": "LLM07_TP_0506",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.76,
    "description": "Plugin zip downloaded from URL",
    "file_path": "docs/plugins.md",
    "code_snippet": "zip_ref.extractall('/opt/plugins')",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0507",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.82,
    "description": "Direct f-string injection into system prompt",
    "file_path": "tests/test_prompt_injection.py",
    "code_snippet": "messages = [{\"role\": \"system\", \"content\": f'Policy: {user_input}'}]",
    "is_true_positive": true
  },
  {
    "id": "LLM09_FP_0508",
    "category": "LLM09: Overreliance",
    "severity": "LOW",
    "confidence": 0.64,
    "description": "Workflow requires reviewer",
    "file_path": "workflows/human_loop.py",
    "code_snippet": "if not reviewer.signoff(result): return",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0509",
    "category": "LLM10: Model Theft",
    "severity": "HIGH",
    "confidence": 0.9,
    "description": "API exposes logprobs enabling extraction (synthetic variation)",
    "file_path": "api/completions.py",
    "code_snippet": "client.chat.completions.create(logprobs=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0510",
    "category": "LLM01: Prompt Injection",
    "severity": "HIGH",
    "confidence": 0.77,
    "description": "Direct f-string injection into system prompt (synthetic variation)",
    "file_path": "examples/prompts/prompt_injection.ipynb",
    "code_snippet": "messages = [{\"role\": \"system\", \"content\": f'Policy: {user_input}'}]",
    "is_true_positive": true
  },
  {
    "id": "LLM02_FP_0511",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.64,
    "description": "Docs logging example output (synthetic variation)",
    "file_path": "db/auto_sql.py",
    "code_snippet": "print('LLM output:', response.text)",
    "is_true_positive": false
  },
  {
    "id": "LLM02_FP_0512",
    "category": "LLM02: Insecure Output",
    "severity": "MEDIUM",
    "confidence": 0.45,
    "description": "SQLAlchemy session.exec mistaken for exec (synthetic variation)",
    "file_path": "docs/examples/output_handling.py",
    "code_snippet": "result = session.exec(select(User))",
    "is_true_positive": false
  },
  {
    "id": "LLM03_FP_0513",
    "category": "LLM03: Training Poisoning",
    "severity": "HIGH",
    "confidence": 0.47,
    "description": "model.eval() inference mode",
    "file_path": "tests/fakes/datasets.py",
    "code_snippet": "self.model.eval()",
    "is_true_positive": false
  },
  {
    "id": "LLM02_FP_0514",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.6,
    "description": "SQLAlchemy session.exec mistaken for exec (synthetic variation)",
    "file_path": "agents/code_exec.py",
    "code_snippet": "result = session.exec(select(User))",
    "is_true_positive": false
  },
  {
    "id": "LLM06_FP_0515",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.65,
    "description": "Base64 image asset (synthetic variation)",
    "file_path": "notebooks/openai_quickstart.ipynb",
    "code_snippet": "LOGO = 'data:image/png;base64,iVBORw0KGgoAAAANS...'",
    "is_true_positive": false
  },
  {
    "id": "LLM07_TP_0516",
    "category": "LLM07: Insecure Plugin",
    "severity": "CRITICAL",
    "confidence": 0.89,
    "description": "Plugin zip downloaded from URL",
    "file_path": "plugins/registry.py",
    "code_snippet": "zip_ref.extractall('/opt/plugins')",
    "is_true_positive": true
  },
  {
    "id": "LLM07_FP_0517",
    "category": "LLM07: Insecure Plugin",
    "severity": "LOW",
    "confidence": 0.61,
    "description": "Plugin registry enforces allowlist (synthetic variation)",
    "file_path": "plugins/shell_tool.py",
    "code_snippet": "if plugin_id not in ALLOWED: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM03_TP_0518",
    "category": "LLM03: Training Poisoning",
    "severity": "MEDIUM",
    "confidence": 0.87,
    "description": "Weights loaded via pickle from user path",
    "file_path": "models/bert_wrapper.py",
    "code_snippet": "weights = pickle.load(open(model_path, 'rb'))",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0519",
    "category": "LLM10: Model Theft",
    "severity": "CRITICAL",
    "confidence": 0.73,
    "description": "Endpoint serves model weights",
    "file_path": "docs/model_export.md",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0520",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.97,
    "description": "LangChain template concatenates untrusted context",
    "file_path": "src/chatbot/services/conversation.py",
    "code_snippet": "template = ChatPromptTemplate.from_messages([(\"system\", ctx + prompt)])",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0521",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.83,
    "description": "Hardcoded OpenAI key",
    "file_path": "docs/assets/logo.py",
    "code_snippet": "os.environ['OPENAI_API_KEY'] = 'sk-live-123456789'",
    "is_true_positive": true
  },
  {
    "id": "LLM07_TP_0522",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.84,
    "description": "Plugin executes shell command",
    "file_path": "plugins/shell_tool.py",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM08_FP_0523",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.44,
    "description": "Manual approval required",
    "file_path": "examples/autonomous_agent.md",
    "code_snippet": "if not require_human_confirmation(task): raise",
    "is_true_positive": false
  },
  {
    "id": "LLM01_TP_0524",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.72,
    "description": "LangChain template concatenates untrusted context",
    "file_path": "examples/prompts/prompt_injection.ipynb",
    "code_snippet": "template = ChatPromptTemplate.from_messages([(\"system\", ctx + prompt)])",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0525",
    "category": "LLM10: Model Theft",
    "severity": "HIGH",
    "confidence": 0.73,
    "description": "API exposes logprobs enabling extraction",
    "file_path": "docs/model_export.md",
    "code_snippet": "client.chat.completions.create(logprobs=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0526",
    "category": "LLM01: Prompt Injection",
    "severity": "LOW",
    "confidence": 0.93,
    "description": "LangChain template concatenates untrusted context",
    "file_path": "src/chatbot/services/conversation.py",
    "code_snippet": "template = ChatPromptTemplate.from_messages([(\"system\", ctx + prompt)])",
    "is_true_positive": true
  },
  {
    "id": "LLM10_FP_0527",
    "category": "LLM10: Model Theft",
    "severity": "MEDIUM",
    "confidence": 0.48,
    "description": "Signed URL enforced (synthetic variation)",
    "file_path": "docs/model_export.md",
    "code_snippet": "return generate_signed_url('model.bin', expires=30)",
    "is_true_positive": false
  },
  {
    "id": "LLM04_FP_0528",
    "category": "LLM04: Model Denial of Service",
    "severity": "HIGH",
    "confidence": 0.59,
    "description": "Pytest simulating rate limit",
    "file_path": "tests/dos/test_rate_limit.py",
    "code_snippet": "for _ in range(5): client.chat.completions.create(... )",
    "is_true_positive": false
  },
  {
    "id": "LLM02_TP_0529",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.8,
    "description": "LLM response executed via eval",
    "file_path": "agents/code_exec.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM05_TP_0530",
    "category": "LLM05: Supply Chain",
    "severity": "LOW",
    "confidence": 0.95,
    "description": "Agent executes pip install from LLM",
    "file_path": "models/loader.py",
    "code_snippet": "subprocess.run(['pip', 'install', llm_pkg], check=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM07_TP_0531",
    "category": "LLM07: Insecure Plugin",
    "severity": "LOW",
    "confidence": 0.96,
    "description": "Plugin executes shell command",
    "file_path": "plugins/manager.py",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM08_FP_0532",
    "category": "LLM08: Excessive Agency",
    "severity": "LOW",
    "confidence": 0.63,
    "description": "Manual approval required (synthetic variation)",
    "file_path": "agents/controller.py",
    "code_snippet": "if not require_human_confirmation(task): raise",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0533",
    "category": "LLM10: Model Theft",
    "severity": "MEDIUM",
    "confidence": 0.97,
    "description": "API exposes logprobs enabling extraction (synthetic variation)",
    "file_path": "docs/model_export.md",
    "code_snippet": "client.chat.completions.create(logprobs=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM01_FP_0534",
    "category": "LLM01: Prompt Injection",
    "severity": "HIGH",
    "confidence": 0.64,
    "description": "Example notebook demonstrates prompts",
    "file_path": "examples/prompts/prompt_injection.ipynb",
    "code_snippet": "SYSTEM_PROMPT = 'Your name is {username}'",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0535",
    "category": "LLM10: Model Theft",
    "severity": "CRITICAL",
    "confidence": 0.88,
    "description": "Endpoint serves model weights",
    "file_path": "api/models.py",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0536",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.78,
    "description": "LLM output with AWS key logged",
    "file_path": "docs/assets/logo.py",
    "code_snippet": "logger.info(f'Key leaked: {response}')",
    "is_true_positive": true
  },
  {
    "id": "LLM05_TP_0537",
    "category": "LLM05: Supply Chain",
    "severity": "CRITICAL",
    "confidence": 0.87,
    "description": "trust_remote_code=True on AutoModel",
    "file_path": "agents/tool_executor.py",
    "code_snippet": "AutoModel.from_pretrained(repo, trust_remote_code=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0538",
    "category": "LLM09: Overreliance",
    "severity": "MEDIUM",
    "confidence": 0.76,
    "description": "LLM summary emailed automatically",
    "file_path": "workflows/email_broadcast.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0539",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.55,
    "description": "Env var reference",
    "file_path": "monitoring/logging.py",
    "code_snippet": "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')",
    "is_true_positive": false
  },
  {
    "id": "LLM02_FP_0540",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.63,
    "description": "Docs logging example output",
    "file_path": "docs/examples/output_handling.py",
    "code_snippet": "print('LLM output:', response.text)",
    "is_true_positive": false
  },
  {
    "id": "LLM05_FP_0541",
    "category": "LLM05: Supply Chain",
    "severity": "HIGH",
    "confidence": 0.39,
    "description": "Download guarded by sha256 verification",
    "file_path": "models/loader.py",
    "code_snippet": "if sha256(data).hexdigest() != expected_hash: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM01_FP_0542",
    "category": "LLM01: Prompt Injection",
    "severity": "LOW",
    "confidence": 0.71,
    "description": "Unit test fixture builds fake prompts",
    "file_path": "tests/test_prompt_injection.py",
    "code_snippet": "def prompt_fixture(): return f'ignore rules {seed}'",
    "is_true_positive": false
  },
  {
    "id": "LLM03_FP_0543",
    "category": "LLM03: Training Poisoning",
    "severity": "HIGH",
    "confidence": 0.36,
    "description": "model.eval() inference mode",
    "file_path": "training/load_weights.py",
    "code_snippet": "self.model.eval()",
    "is_true_positive": false
  },
  {
    "id": "LLM02_FP_0544",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.54,
    "description": "SQLAlchemy session.exec mistaken for exec",
    "file_path": "docs/examples/output_handling.py",
    "code_snippet": "result = session.exec(select(User))",
    "is_true_positive": false
  },
  {
    "id": "LLM05_FP_0545",
    "category": "LLM05: Supply Chain",
    "severity": "MEDIUM",
    "confidence": 0.5,
    "description": "Docs show requirements snippet",
    "file_path": "security/downloader.py",
    "code_snippet": "pip install torch==2.2.1",
    "is_true_positive": false
  },
  {
    "id": "LLM06_FP_0546",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.44,
    "description": "Env var reference",
    "file_path": "notebooks/openai_quickstart.ipynb",
    "code_snippet": "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')",
    "is_true_positive": false
  },
  {
    "id": "LLM08_FP_0547",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.71,
    "description": "Demo described in README (synthetic variation)",
    "file_path": "agents/task_runner.py",
    "code_snippet": "agent.run('book a flight')",
    "is_true_positive": false
  },
  {
    "id": "LLM03_FP_0548",
    "category": "LLM03: Training Poisoning",
    "severity": "LOW",
    "confidence": 0.62,
    "description": "torch random_split in tests (synthetic variation)",
    "file_path": "training/load_weights.py",
    "code_snippet": "train, test = random_split(dataset, [80, 20])",
    "is_true_positive": false
  },
  {
    "id": "LLM01_TP_0549",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.86,
    "description": "LangChain template concatenates untrusted context (synthetic variation)",
    "file_path": "pipelines/langchain_agent.py",
    "code_snippet": "template = ChatPromptTemplate.from_messages([(\"system\", ctx + prompt)])",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0550",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.96,
    "description": "Hardcoded OpenAI key",
    "file_path": "notebooks/openai_quickstart.ipynb",
    "code_snippet": "os.environ['OPENAI_API_KEY'] = 'sk-live-123456789'",
    "is_true_positive": true
  },
  {
    "id": "LLM10_FP_0551",
    "category": "LLM10: Model Theft",
    "severity": "HIGH",
    "confidence": 0.55,
    "description": "Docs describing scp export (synthetic variation)",
    "file_path": "docs/model_export.md",
    "code_snippet": "scp model.bin user@host",
    "is_true_positive": false
  },
  {
    "id": "LLM06_TP_0552",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.82,
    "description": "Hardcoded OpenAI key",
    "file_path": "notebooks/openai_quickstart.ipynb",
    "code_snippet": "os.environ['OPENAI_API_KEY'] = 'sk-live-123456789'",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0553",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.8,
    "description": "LLM response executed via eval (synthetic variation)",
    "file_path": "app/repository.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0554",
    "category": "LLM10: Model Theft",
    "severity": "HIGH",
    "confidence": 0.82,
    "description": "Endpoint serves model weights",
    "file_path": "api/models.py",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM10_FP_0555",
    "category": "LLM10: Model Theft",
    "severity": "HIGH",
    "confidence": 0.68,
    "description": "Signed URL enforced",
    "file_path": "api/models.py",
    "code_snippet": "return generate_signed_url('model.bin', expires=30)",
    "is_true_positive": false
  },
  {
    "id": "LLM02_TP_0556",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.84,
    "description": "SQL built from LLM output",
    "file_path": "agents/code_exec.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM08_TP_0557",
    "category": "LLM08: Excessive Agency",
    "severity": "LOW",
    "confidence": 0.97,
    "description": "Agent transfers funds autonomously (synthetic variation)",
    "file_path": "agents/controller.py",
    "code_snippet": "bank.transfer(amount, destination, auto_execute=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0558",
    "category": "LLM09: Overreliance",
    "severity": "MEDIUM",
    "confidence": 0.94,
    "description": "Auto-approves compliance decision",
    "file_path": "workflows/email_broadcast.py",
    "code_snippet": "if model.confidence > 0.2: return 'approved'",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0559",
    "category": "LLM02: Insecure Output",
    "severity": "MEDIUM",
    "confidence": 0.71,
    "description": "SQL built from LLM output",
    "file_path": "agents/code_exec.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0560",
    "category": "LLM01: Prompt Injection",
    "severity": "HIGH",
    "confidence": 0.86,
    "description": "Direct f-string injection into system prompt",
    "file_path": "pipelines/langchain_agent.py",
    "code_snippet": "messages = [{\"role\": \"system\", \"content\": f'Policy: {user_input}'}]",
    "is_true_positive": true
  },
  {
    "id": "LLM04_FP_0561",
    "category": "LLM04: Model Denial of Service",
    "severity": "MEDIUM",
    "confidence": 0.58,
    "description": "Pytest simulating rate limit",
    "file_path": "tests/dos/test_rate_limit.py",
    "code_snippet": "for _ in range(5): client.chat.completions.create(... )",
    "is_true_positive": false
  },
  {
    "id": "LLM01_TP_0562",
    "category": "LLM01: Prompt Injection",
    "severity": "LOW",
    "confidence": 0.91,
    "description": "Direct f-string injection into system prompt",
    "file_path": "src/chatbot/services/conversation.py",
    "code_snippet": "messages = [{\"role\": \"system\", \"content\": f'Policy: {user_input}'}]",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0563",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.87,
    "description": "LLM response executed via eval (synthetic variation)",
    "file_path": "app/repository.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM08_TP_0564",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.85,
    "description": "Agent transfers funds autonomously (synthetic variation)",
    "file_path": "examples/autonomous_agent.md",
    "code_snippet": "bank.transfer(amount, destination, auto_execute=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM07_FP_0565",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.6,
    "description": "Docs describing plugin install",
    "file_path": "plugins/manager.py",
    "code_snippet": "Install shell plugin by running ./install.sh",
    "is_true_positive": false
  },
  {
    "id": "LLM06_FP_0566",
    "category": "LLM06: Sensitive Info",
    "severity": "LOW",
    "confidence": 0.37,
    "description": "Env var reference",
    "file_path": "monitoring/logging.py",
    "code_snippet": "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')",
    "is_true_positive": false
  },
  {
    "id": "LLM07_TP_0567",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.91,
    "description": "Plugin executes shell command",
    "file_path": "plugins/registry.py",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0568",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.76,
    "description": "Hardcoded OpenAI key",
    "file_path": "monitoring/logging.py",
    "code_snippet": "os.environ['OPENAI_API_KEY'] = 'sk-live-123456789'",
    "is_true_positive": true
  },
  {
    "id": "LLM04_TP_0569",
    "category": "LLM04: Model Denial of Service",
    "severity": "LOW",
    "confidence": 0.78,
    "description": "Unbounded while loop hitting OpenAI (synthetic variation)",
    "file_path": "tests/dos/test_rate_limit.py",
    "code_snippet": "while True:\n    client.chat.completions.create(... )",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0570",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.74,
    "description": "SQL built from LLM output",
    "file_path": "app/repository.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0571",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.84,
    "description": "LLM response executed via eval",
    "file_path": "db/auto_sql.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM05_FP_0572",
    "category": "LLM05: Supply Chain",
    "severity": "MEDIUM",
    "confidence": 0.7,
    "description": "Docs show requirements snippet (synthetic variation)",
    "file_path": "docs/getting_started.md",
    "code_snippet": "pip install torch==2.2.1",
    "is_true_positive": false
  },
  {
    "id": "LLM06_TP_0573",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.94,
    "description": "Hardcoded OpenAI key (synthetic variation)",
    "file_path": "docs/assets/logo.py",
    "code_snippet": "os.environ['OPENAI_API_KEY'] = 'sk-live-123456789'",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0574",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.64,
    "description": "Base64 image asset",
    "file_path": "docs/assets/logo.py",
    "code_snippet": "LOGO = 'data:image/png;base64,iVBORw0KGgoAAAANS...'",
    "is_true_positive": false
  },
  {
    "id": "LLM02_TP_0575",
    "category": "LLM02: Insecure Output",
    "severity": "MEDIUM",
    "confidence": 0.95,
    "description": "LLM response executed via eval (synthetic variation)",
    "file_path": "app/repository.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM02_FP_0576",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.56,
    "description": "SQLAlchemy session.exec mistaken for exec",
    "file_path": "agents/code_exec.py",
    "code_snippet": "result = session.exec(select(User))",
    "is_true_positive": false
  },
  {
    "id": "LLM04_FP_0577",
    "category": "LLM04: Model Denial of Service",
    "severity": "HIGH",
    "confidence": 0.64,
    "description": "Pytest simulating rate limit",
    "file_path": "tests/dos/test_rate_limit.py",
    "code_snippet": "for _ in range(5): client.chat.completions.create(... )",
    "is_true_positive": false
  },
  {
    "id": "LLM04_FP_0578",
    "category": "LLM04: Model Denial of Service",
    "severity": "MEDIUM",
    "confidence": 0.54,
    "description": "Pytest simulating rate limit (synthetic variation)",
    "file_path": "services/parallel_runner.py",
    "code_snippet": "for _ in range(5): client.chat.completions.create(... )",
    "is_true_positive": false
  },
  {
    "id": "LLM06_TP_0579",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.82,
    "description": "Hardcoded OpenAI key (synthetic variation)",
    "file_path": "monitoring/logging.py",
    "code_snippet": "os.environ['OPENAI_API_KEY'] = 'sk-live-123456789'",
    "is_true_positive": true
  },
  {
    "id": "LLM10_FP_0580",
    "category": "LLM10: Model Theft",
    "severity": "MEDIUM",
    "confidence": 0.36,
    "description": "Signed URL enforced",
    "file_path": "docs/model_export.md",
    "code_snippet": "return generate_signed_url('model.bin', expires=30)",
    "is_true_positive": false
  },
  {
    "id": "LLM04_TP_0581",
    "category": "LLM04: Model Denial of Service",
    "severity": "LOW",
    "confidence": 0.89,
    "description": "Async gather spawns many completions",
    "file_path": "services/parallel_runner.py",
    "code_snippet": "await asyncio.gather(*[call_llm(q) for q in queue])",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0582",
    "category": "LLM06: Sensitive Info",
    "severity": "LOW",
    "confidence": 0.97,
    "description": "LLM output with AWS key logged",
    "file_path": "notebooks/openai_quickstart.ipynb",
    "code_snippet": "logger.info(f'Key leaked: {response}')",
    "is_true_positive": true
  },
  {
    "id": "LLM09_FP_0583",
    "category": "LLM09: Overreliance",
    "severity": "HIGH",
    "confidence": 0.55,
    "description": "Unit test asserting human review (synthetic variation)",
    "file_path": "workflows/human_loop.py",
    "code_snippet": "assert pipeline.requires_human_review is True",
    "is_true_positive": false
  },
  {
    "id": "LLM07_TP_0584",
    "category": "LLM07: Insecure Plugin",
    "severity": "CRITICAL",
    "confidence": 0.97,
    "description": "Plugin executes shell command (synthetic variation)",
    "file_path": "plugins/registry.py",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM07_TP_0585",
    "category": "LLM07: Insecure Plugin",
    "severity": "CRITICAL",
    "confidence": 0.95,
    "description": "Plugin zip downloaded from URL (synthetic variation)",
    "file_path": "docs/plugins.md",
    "code_snippet": "zip_ref.extractall('/opt/plugins')",
    "is_true_positive": true
  },
  {
    "id": "LLM03_TP_0586",
    "category": "LLM03: Training Poisoning",
    "severity": "HIGH",
    "confidence": 0.76,
    "description": "Training data pulled from unsecured URL (synthetic variation)",
    "file_path": "training/data_loader.py",
    "code_snippet": "data = json.loads(requests.get(feed).text)",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0587",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.65,
    "description": "Env var reference",
    "file_path": "monitoring/logging.py",
    "code_snippet": "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')",
    "is_true_positive": false
  },
  {
    "id": "LLM08_FP_0588",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.41,
    "description": "Demo described in README",
    "file_path": "agents/task_runner.py",
    "code_snippet": "agent.run('book a flight')",
    "is_true_positive": false
  },
  {
    "id": "LLM01_TP_0589",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.88,
    "description": "Direct f-string injection into system prompt (synthetic variation)",
    "file_path": "pipelines/langchain_agent.py",
    "code_snippet": "messages = [{\"role\": \"system\", \"content\": f'Policy: {user_input}'}]",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0590",
    "category": "LLM10: Model Theft",
    "severity": "MEDIUM",
    "confidence": 0.84,
    "description": "Endpoint serves model weights",
    "file_path": "api/secure_download.py",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM10_FP_0591",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.52,
    "description": "Docs describing scp export",
    "file_path": "api/models.py",
    "code_snippet": "scp model.bin user@host",
    "is_true_positive": false
  },
  {
    "id": "LLM08_TP_0592",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.87,
    "description": "Agent executes system command",
    "file_path": "agents/task_runner.py",
    "code_snippet": "os.system(plan['action'])",
    "is_true_positive": true
  },
  {
    "id": "LLM03_FP_0593",
    "category": "LLM03: Training Poisoning",
    "severity": "HIGH",
    "confidence": 0.57,
    "description": "model.eval() inference mode (synthetic variation)",
    "file_path": "models/bert_wrapper.py",
    "code_snippet": "self.model.eval()",
    "is_true_positive": false
  },
  {
    "id": "LLM07_TP_0594",
    "category": "LLM07: Insecure Plugin",
    "severity": "CRITICAL",
    "confidence": 0.93,
    "description": "Plugin executes shell command",
    "file_path": "plugins/manager.py",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM03_TP_0595",
    "category": "LLM03: Training Poisoning",
    "severity": "LOW",
    "confidence": 0.84,
    "description": "Training data pulled from unsecured URL (synthetic variation)",
    "file_path": "training/data_loader.py",
    "code_snippet": "data = json.loads(requests.get(feed).text)",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0596",
    "category": "LLM10: Model Theft",
    "severity": "CRITICAL",
    "confidence": 0.8,
    "description": "Endpoint serves model weights (synthetic variation)",
    "file_path": "docs/model_export.md",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0597",
    "category": "LLM09: Overreliance",
    "severity": "HIGH",
    "confidence": 0.86,
    "description": "LLM summary emailed automatically",
    "file_path": "tests/workflows/test_review.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0598",
    "category": "LLM10: Model Theft",
    "severity": "CRITICAL",
    "confidence": 0.91,
    "description": "Endpoint serves model weights",
    "file_path": "api/secure_download.py",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0599",
    "category": "LLM02: Insecure Output",
    "severity": "MEDIUM",
    "confidence": 0.7,
    "description": "SQL built from LLM output",
    "file_path": "app/repository.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM01_FP_0600",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.59,
    "description": "Unit test fixture builds fake prompts",
    "file_path": "src/chatbot/services/conversation.py",
    "code_snippet": "def prompt_fixture(): return f'ignore rules {seed}'",
    "is_true_positive": false
  },
  {
    "id": "LLM06_TP_0601",
    "category": "LLM06: Sensitive Info",
    "severity": "CRITICAL",
    "confidence": 0.88,
    "description": "Hardcoded OpenAI key (synthetic variation)",
    "file_path": "monitoring/logging.py",
    "code_snippet": "os.environ['OPENAI_API_KEY'] = 'sk-live-123456789'",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0602",
    "category": "LLM09: Overreliance",
    "severity": "CRITICAL",
    "confidence": 0.91,
    "description": "LLM summary emailed automatically",
    "file_path": "workflows/human_loop.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0603",
    "category": "LLM09: Overreliance",
    "severity": "HIGH",
    "confidence": 0.98,
    "description": "LLM summary emailed automatically",
    "file_path": "tests/workflows/test_review.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM07_FP_0604",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.64,
    "description": "Plugin registry enforces allowlist",
    "file_path": "plugins/manager.py",
    "code_snippet": "if plugin_id not in ALLOWED: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM02_TP_0605",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.75,
    "description": "SQL built from LLM output",
    "file_path": "app/repository.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM01_FP_0606",
    "category": "LLM01: Prompt Injection",
    "severity": "HIGH",
    "confidence": 0.51,
    "description": "Unit test fixture builds fake prompts (synthetic variation)",
    "file_path": "examples/prompts/prompt_injection.ipynb",
    "code_snippet": "def prompt_fixture(): return f'ignore rules {seed}'",
    "is_true_positive": false
  },
  {
    "id": "LLM04_TP_0607",
    "category": "LLM04: Model Denial of Service",
    "severity": "CRITICAL",
    "confidence": 0.87,
    "description": "Unbounded while loop hitting OpenAI",
    "file_path": "tests/dos/test_rate_limit.py",
    "code_snippet": "while True:\n    client.chat.completions.create(... )",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0608",
    "category": "LLM10: Model Theft",
    "severity": "CRITICAL",
    "confidence": 0.7,
    "description": "Endpoint serves model weights",
    "file_path": "docs/model_export.md",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0609",
    "category": "LLM09: Overreliance",
    "severity": "MEDIUM",
    "confidence": 0.89,
    "description": "Auto-approves compliance decision",
    "file_path": "workflows/email_broadcast.py",
    "code_snippet": "if model.confidence > 0.2: return 'approved'",
    "is_true_positive": true
  },
  {
    "id": "LLM01_FP_0610",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.48,
    "description": "Unit test fixture builds fake prompts",
    "file_path": "tests/test_prompt_injection.py",
    "code_snippet": "def prompt_fixture(): return f'ignore rules {seed}'",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0611",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.85,
    "description": "Endpoint serves model weights",
    "file_path": "api/models.py",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM09_FP_0612",
    "category": "LLM09: Overreliance",
    "severity": "MEDIUM",
    "confidence": 0.43,
    "description": "Unit test asserting human review",
    "file_path": "workflows/human_loop.py",
    "code_snippet": "assert pipeline.requires_human_review is True",
    "is_true_positive": false
  },
  {
    "id": "LLM08_FP_0613",
    "category": "LLM08: Excessive Agency",
    "severity": "LOW",
    "confidence": 0.5,
    "description": "Manual approval required (synthetic variation)",
    "file_path": "agents/controller.py",
    "code_snippet": "if not require_human_confirmation(task): raise",
    "is_true_positive": false
  },
  {
    "id": "LLM02_TP_0614",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.95,
    "description": "SQL built from LLM output",
    "file_path": "agents/code_exec.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0615",
    "category": "LLM10: Model Theft",
    "severity": "CRITICAL",
    "confidence": 0.92,
    "description": "API exposes logprobs enabling extraction",
    "file_path": "docs/model_export.md",
    "code_snippet": "client.chat.completions.create(logprobs=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM08_FP_0616",
    "category": "LLM08: Excessive Agency",
    "severity": "LOW",
    "confidence": 0.45,
    "description": "Manual approval required",
    "file_path": "examples/autonomous_agent.md",
    "code_snippet": "if not require_human_confirmation(task): raise",
    "is_true_positive": false
  },
  {
    "id": "LLM04_FP_0617",
    "category": "LLM04: Model Denial of Service",
    "severity": "MEDIUM",
    "confidence": 0.7,
    "description": "Single completion call flagged",
    "file_path": "routes/ask.py",
    "code_snippet": "client.chat.completions.create(model=MODEL, messages=msgs)",
    "is_true_positive": false
  },
  {
    "id": "LLM01_FP_0618",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.38,
    "description": "Example notebook demonstrates prompts",
    "file_path": "pipelines/langchain_agent.py",
    "code_snippet": "SYSTEM_PROMPT = 'Your name is {username}'",
    "is_true_positive": false
  },
  {
    "id": "LLM06_TP_0619",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.8,
    "description": "Hardcoded OpenAI key",
    "file_path": "docs/assets/logo.py",
    "code_snippet": "os.environ['OPENAI_API_KEY'] = 'sk-live-123456789'",
    "is_true_positive": true
  },
  {
    "id": "LLM05_TP_0620",
    "category": "LLM05: Supply Chain",
    "severity": "MEDIUM",
    "confidence": 0.77,
    "description": "trust_remote_code=True on AutoModel (synthetic variation)",
    "file_path": "security/downloader.py",
    "code_snippet": "AutoModel.from_pretrained(repo, trust_remote_code=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM05_TP_0621",
    "category": "LLM05: Supply Chain",
    "severity": "HIGH",
    "confidence": 0.74,
    "description": "trust_remote_code=True on AutoModel (synthetic variation)",
    "file_path": "agents/tool_executor.py",
    "code_snippet": "AutoModel.from_pretrained(repo, trust_remote_code=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM02_FP_0622",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.7,
    "description": "Docs logging example output",
    "file_path": "agents/code_exec.py",
    "code_snippet": "print('LLM output:', response.text)",
    "is_true_positive": false
  },
  {
    "id": "LLM06_FP_0623",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.42,
    "description": "Base64 image asset",
    "file_path": "config/settings.py",
    "code_snippet": "LOGO = 'data:image/png;base64,iVBORw0KGgoAAAANS...'",
    "is_true_positive": false
  },
  {
    "id": "LLM09_TP_0624",
    "category": "LLM09: Overreliance",
    "severity": "LOW",
    "confidence": 0.85,
    "description": "Auto-approves compliance decision",
    "file_path": "workflows/email_broadcast.py",
    "code_snippet": "if model.confidence > 0.2: return 'approved'",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0625",
    "category": "LLM09: Overreliance",
    "severity": "MEDIUM",
    "confidence": 0.83,
    "description": "LLM summary emailed automatically (synthetic variation)",
    "file_path": "tests/workflows/test_review.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0626",
    "category": "LLM09: Overreliance",
    "severity": "MEDIUM",
    "confidence": 0.81,
    "description": "Auto-approves compliance decision (synthetic variation)",
    "file_path": "decision/approver.py",
    "code_snippet": "if model.confidence > 0.2: return 'approved'",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0627",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.45,
    "description": "Base64 image asset (synthetic variation)",
    "file_path": "monitoring/logging.py",
    "code_snippet": "LOGO = 'data:image/png;base64,iVBORw0KGgoAAAANS...'",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0628",
    "category": "LLM10: Model Theft",
    "severity": "CRITICAL",
    "confidence": 0.76,
    "description": "Endpoint serves model weights",
    "file_path": "docs/model_export.md",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0629",
    "category": "LLM06: Sensitive Info",
    "severity": "CRITICAL",
    "confidence": 0.75,
    "description": "LLM output with AWS key logged (synthetic variation)",
    "file_path": "config/settings.py",
    "code_snippet": "logger.info(f'Key leaked: {response}')",
    "is_true_positive": true
  },
  {
    "id": "LLM10_FP_0630",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.56,
    "description": "Signed URL enforced",
    "file_path": "api/secure_download.py",
    "code_snippet": "return generate_signed_url('model.bin', expires=30)",
    "is_true_positive": false
  },
  {
    "id": "LLM04_TP_0631",
    "category": "LLM04: Model Denial of Service",
    "severity": "LOW",
    "confidence": 0.75,
    "description": "Unbounded while loop hitting OpenAI",
    "file_path": "tests/dos/test_rate_limit.py",
    "code_snippet": "while True:\n    client.chat.completions.create(... )",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0632",
    "category": "LLM09: Overreliance",
    "severity": "HIGH",
    "confidence": 0.77,
    "description": "LLM summary emailed automatically",
    "file_path": "tests/workflows/test_review.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0633",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.93,
    "description": "Direct f-string injection into system prompt",
    "file_path": "src/chatbot/services/conversation.py",
    "code_snippet": "messages = [{\"role\": \"system\", \"content\": f'Policy: {user_input}'}]",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0634",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.8,
    "description": "SQL built from LLM output",
    "file_path": "app/repository.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM05_TP_0635",
    "category": "LLM05: Supply Chain",
    "severity": "HIGH",
    "confidence": 0.94,
    "description": "Agent executes pip install from LLM",
    "file_path": "models/loader.py",
    "code_snippet": "subprocess.run(['pip', 'install', llm_pkg], check=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM04_FP_0636",
    "category": "LLM04: Model Denial of Service",
    "severity": "MEDIUM",
    "confidence": 0.47,
    "description": "Single completion call flagged",
    "file_path": "routes/ask.py",
    "code_snippet": "client.chat.completions.create(model=MODEL, messages=msgs)",
    "is_true_positive": false
  },
  {
    "id": "LLM08_FP_0637",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.58,
    "description": "Demo described in README (synthetic variation)",
    "file_path": "agents/controller.py",
    "code_snippet": "agent.run('book a flight')",
    "is_true_positive": false
  },
  {
    "id": "LLM03_FP_0638",
    "category": "LLM03: Training Poisoning",
    "severity": "HIGH",
    "confidence": 0.58,
    "description": "model.eval() inference mode",
    "file_path": "models/bert_wrapper.py",
    "code_snippet": "self.model.eval()",
    "is_true_positive": false
  },
  {
    "id": "LLM02_TP_0639",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.79,
    "description": "SQL built from LLM output (synthetic variation)",
    "file_path": "db/auto_sql.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM05_FP_0640",
    "category": "LLM05: Supply Chain",
    "severity": "MEDIUM",
    "confidence": 0.64,
    "description": "Download guarded by sha256 verification",
    "file_path": "docs/getting_started.md",
    "code_snippet": "if sha256(data).hexdigest() != expected_hash: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0641",
    "category": "LLM10: Model Theft",
    "severity": "MEDIUM",
    "confidence": 0.75,
    "description": "API exposes logprobs enabling extraction (synthetic variation)",
    "file_path": "docs/model_export.md",
    "code_snippet": "client.chat.completions.create(logprobs=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM04_FP_0642",
    "category": "LLM04: Model Denial of Service",
    "severity": "LOW",
    "confidence": 0.5,
    "description": "Single completion call flagged (synthetic variation)",
    "file_path": "services/parallel_runner.py",
    "code_snippet": "client.chat.completions.create(model=MODEL, messages=msgs)",
    "is_true_positive": false
  },
  {
    "id": "LLM08_TP_0643",
    "category": "LLM08: Excessive Agency",
    "severity": "LOW",
    "confidence": 0.73,
    "description": "Agent transfers funds autonomously",
    "file_path": "examples/autonomous_agent.md",
    "code_snippet": "bank.transfer(amount, destination, auto_execute=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM02_FP_0644",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.44,
    "description": "Docs logging example output (synthetic variation)",
    "file_path": "app/repository.py",
    "code_snippet": "print('LLM output:', response.text)",
    "is_true_positive": false
  },
  {
    "id": "LLM03_TP_0645",
    "category": "LLM03: Training Poisoning",
    "severity": "LOW",
    "confidence": 0.89,
    "description": "Training data pulled from unsecured URL",
    "file_path": "training/data_loader.py",
    "code_snippet": "data = json.loads(requests.get(feed).text)",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0646",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.51,
    "description": "Base64 image asset",
    "file_path": "config/settings.py",
    "code_snippet": "LOGO = 'data:image/png;base64,iVBORw0KGgoAAAANS...'",
    "is_true_positive": false
  },
  {
    "id": "LLM09_TP_0647",
    "category": "LLM09: Overreliance",
    "severity": "HIGH",
    "confidence": 0.95,
    "description": "LLM summary emailed automatically",
    "file_path": "tests/workflows/test_review.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM04_FP_0648",
    "category": "LLM04: Model Denial of Service",
    "severity": "MEDIUM",
    "confidence": 0.5,
    "description": "Pytest simulating rate limit (synthetic variation)",
    "file_path": "routes/ask.py",
    "code_snippet": "for _ in range(5): client.chat.completions.create(... )",
    "is_true_positive": false
  },
  {
    "id": "LLM01_TP_0649",
    "category": "LLM01: Prompt Injection",
    "severity": "HIGH",
    "confidence": 0.83,
    "description": "Direct f-string injection into system prompt (synthetic variation)",
    "file_path": "tests/test_prompt_injection.py",
    "code_snippet": "messages = [{\"role\": \"system\", \"content\": f'Policy: {user_input}'}]",
    "is_true_positive": true
  },
  {
    "id": "LLM08_FP_0650",
    "category": "LLM08: Excessive Agency",
    "severity": "LOW",
    "confidence": 0.63,
    "description": "Demo described in README",
    "file_path": "agents/controller.py",
    "code_snippet": "agent.run('book a flight')",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0651",
    "category": "LLM10: Model Theft",
    "severity": "MEDIUM",
    "confidence": 0.82,
    "description": "Endpoint serves model weights",
    "file_path": "api/secure_download.py",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM07_TP_0652",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.77,
    "description": "Plugin zip downloaded from URL",
    "file_path": "docs/plugins.md",
    "code_snippet": "zip_ref.extractall('/opt/plugins')",
    "is_true_positive": true
  },
  {
    "id": "LLM04_TP_0653",
    "category": "LLM04: Model Denial of Service",
    "severity": "HIGH",
    "confidence": 0.82,
    "description": "Async gather spawns many completions",
    "file_path": "routes/ask.py",
    "code_snippet": "await asyncio.gather(*[call_llm(q) for q in queue])",
    "is_true_positive": true
  },
  {
    "id": "LLM03_TP_0654",
    "category": "LLM03: Training Poisoning",
    "severity": "CRITICAL",
    "confidence": 0.78,
    "description": "Training data pulled from unsecured URL",
    "file_path": "models/bert_wrapper.py",
    "code_snippet": "data = json.loads(requests.get(feed).text)",
    "is_true_positive": true
  },
  {
    "id": "LLM04_TP_0655",
    "category": "LLM04: Model Denial of Service",
    "severity": "LOW",
    "confidence": 0.75,
    "description": "Unbounded while loop hitting OpenAI (synthetic variation)",
    "file_path": "workers/auto_refiner.py",
    "code_snippet": "while True:\n    client.chat.completions.create(... )",
    "is_true_positive": true
  },
  {
    "id": "LLM05_TP_0656",
    "category": "LLM05: Supply Chain",
    "severity": "MEDIUM",
    "confidence": 0.73,
    "description": "Agent executes pip install from LLM (synthetic variation)",
    "file_path": "models/loader.py",
    "code_snippet": "subprocess.run(['pip', 'install', llm_pkg], check=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM04_TP_0657",
    "category": "LLM04: Model Denial of Service",
    "severity": "HIGH",
    "confidence": 0.83,
    "description": "Async gather spawns many completions",
    "file_path": "tests/dos/test_rate_limit.py",
    "code_snippet": "await asyncio.gather(*[call_llm(q) for q in queue])",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0658",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.92,
    "description": "Hardcoded OpenAI key (synthetic variation)",
    "file_path": "notebooks/openai_quickstart.ipynb",
    "code_snippet": "os.environ['OPENAI_API_KEY'] = 'sk-live-123456789'",
    "is_true_positive": true
  },
  {
    "id": "LLM08_TP_0659",
    "category": "LLM08: Excessive Agency",
    "severity": "LOW",
    "confidence": 0.73,
    "description": "Agent executes system command",
    "file_path": "examples/autonomous_agent.md",
    "code_snippet": "os.system(plan['action'])",
    "is_true_positive": true
  },
  {
    "id": "LLM04_TP_0660",
    "category": "LLM04: Model Denial of Service",
    "severity": "LOW",
    "confidence": 0.76,
    "description": "Async gather spawns many completions",
    "file_path": "services/parallel_runner.py",
    "code_snippet": "await asyncio.gather(*[call_llm(q) for q in queue])",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0661",
    "category": "LLM02: Insecure Output",
    "severity": "CRITICAL",
    "confidence": 0.89,
    "description": "LLM response executed via eval",
    "file_path": "docs/examples/output_handling.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0662",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.83,
    "description": "Hardcoded OpenAI key (synthetic variation)",
    "file_path": "notebooks/openai_quickstart.ipynb",
    "code_snippet": "os.environ['OPENAI_API_KEY'] = 'sk-live-123456789'",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0663",
    "category": "LLM06: Sensitive Info",
    "severity": "LOW",
    "confidence": 0.58,
    "description": "Env var reference",
    "file_path": "notebooks/openai_quickstart.ipynb",
    "code_snippet": "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')",
    "is_true_positive": false
  },
  {
    "id": "LLM03_FP_0664",
    "category": "LLM03: Training Poisoning",
    "severity": "LOW",
    "confidence": 0.35,
    "description": "torch random_split in tests (synthetic variation)",
    "file_path": "models/bert_wrapper.py",
    "code_snippet": "train, test = random_split(dataset, [80, 20])",
    "is_true_positive": false
  },
  {
    "id": "LLM08_FP_0665",
    "category": "LLM08: Excessive Agency",
    "severity": "LOW",
    "confidence": 0.44,
    "description": "Manual approval required",
    "file_path": "agents/controller.py",
    "code_snippet": "if not require_human_confirmation(task): raise",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0666",
    "category": "LLM10: Model Theft",
    "severity": "HIGH",
    "confidence": 0.88,
    "description": "Endpoint serves model weights",
    "file_path": "api/models.py",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0667",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.93,
    "description": "LLM response executed via eval",
    "file_path": "app/repository.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM04_TP_0668",
    "category": "LLM04: Model Denial of Service",
    "severity": "MEDIUM",
    "confidence": 0.77,
    "description": "Async gather spawns many completions (synthetic variation)",
    "file_path": "routes/ask.py",
    "code_snippet": "await asyncio.gather(*[call_llm(q) for q in queue])",
    "is_true_positive": true
  },
  {
    "id": "LLM08_FP_0669",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.42,
    "description": "Demo described in README",
    "file_path": "agents/task_runner.py",
    "code_snippet": "agent.run('book a flight')",
    "is_true_positive": false
  },
  {
    "id": "LLM08_TP_0670",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.83,
    "description": "Agent transfers funds autonomously",
    "file_path": "agents/finance_agent.py",
    "code_snippet": "bank.transfer(amount, destination, auto_execute=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0671",
    "category": "LLM09: Overreliance",
    "severity": "MEDIUM",
    "confidence": 0.95,
    "description": "Auto-approves compliance decision",
    "file_path": "tests/workflows/test_review.py",
    "code_snippet": "if model.confidence > 0.2: return 'approved'",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0672",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.37,
    "description": "Env var reference",
    "file_path": "config/settings.py",
    "code_snippet": "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')",
    "is_true_positive": false
  },
  {
    "id": "LLM07_TP_0673",
    "category": "LLM07: Insecure Plugin",
    "severity": "HIGH",
    "confidence": 0.79,
    "description": "Plugin zip downloaded from URL",
    "file_path": "plugins/manager.py",
    "code_snippet": "zip_ref.extractall('/opt/plugins')",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0674",
    "category": "LLM02: Insecure Output",
    "severity": "MEDIUM",
    "confidence": 0.75,
    "description": "LLM response executed via eval (synthetic variation)",
    "file_path": "agents/code_exec.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0675",
    "category": "LLM02: Insecure Output",
    "severity": "CRITICAL",
    "confidence": 0.88,
    "description": "LLM response executed via eval",
    "file_path": "agents/code_exec.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0676",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.7,
    "description": "API exposes logprobs enabling extraction",
    "file_path": "api/completions.py",
    "code_snippet": "client.chat.completions.create(logprobs=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM08_FP_0677",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.37,
    "description": "Manual approval required",
    "file_path": "examples/autonomous_agent.md",
    "code_snippet": "if not require_human_confirmation(task): raise",
    "is_true_positive": false
  },
  {
    "id": "LLM07_FP_0678",
    "category": "LLM07: Insecure Plugin",
    "severity": "HIGH",
    "confidence": 0.37,
    "description": "Plugin registry enforces allowlist (synthetic variation)",
    "file_path": "plugins/registry.py",
    "code_snippet": "if plugin_id not in ALLOWED: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM05_TP_0679",
    "category": "LLM05: Supply Chain",
    "severity": "LOW",
    "confidence": 0.9,
    "description": "trust_remote_code=True on AutoModel",
    "file_path": "models/loader.py",
    "code_snippet": "AutoModel.from_pretrained(repo, trust_remote_code=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM04_TP_0680",
    "category": "LLM04: Model Denial of Service",
    "severity": "CRITICAL",
    "confidence": 0.91,
    "description": "Unbounded while loop hitting OpenAI",
    "file_path": "services/parallel_runner.py",
    "code_snippet": "while True:\n    client.chat.completions.create(... )",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0681",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.75,
    "description": "API exposes logprobs enabling extraction (synthetic variation)",
    "file_path": "docs/model_export.md",
    "code_snippet": "client.chat.completions.create(logprobs=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM07_TP_0682",
    "category": "LLM07: Insecure Plugin",
    "severity": "HIGH",
    "confidence": 0.95,
    "description": "Plugin executes shell command",
    "file_path": "docs/plugins.md",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0683",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.47,
    "description": "Base64 image asset (synthetic variation)",
    "file_path": "docs/assets/logo.py",
    "code_snippet": "LOGO = 'data:image/png;base64,iVBORw0KGgoAAAANS...'",
    "is_true_positive": false
  },
  {
    "id": "LLM09_TP_0684",
    "category": "LLM09: Overreliance",
    "severity": "CRITICAL",
    "confidence": 0.83,
    "description": "LLM summary emailed automatically",
    "file_path": "workflows/human_loop.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM01_FP_0685",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.35,
    "description": "Unit test fixture builds fake prompts",
    "file_path": "pipelines/langchain_agent.py",
    "code_snippet": "def prompt_fixture(): return f'ignore rules {seed}'",
    "is_true_positive": false
  },
  {
    "id": "LLM04_FP_0686",
    "category": "LLM04: Model Denial of Service",
    "severity": "HIGH",
    "confidence": 0.54,
    "description": "Single completion call flagged",
    "file_path": "routes/ask.py",
    "code_snippet": "client.chat.completions.create(model=MODEL, messages=msgs)",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0687",
    "category": "LLM10: Model Theft",
    "severity": "HIGH",
    "confidence": 0.74,
    "description": "Endpoint serves model weights (synthetic variation)",
    "file_path": "docs/model_export.md",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0688",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.86,
    "description": "API exposes logprobs enabling extraction",
    "file_path": "api/secure_download.py",
    "code_snippet": "client.chat.completions.create(logprobs=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM04_FP_0689",
    "category": "LLM04: Model Denial of Service",
    "severity": "LOW",
    "confidence": 0.53,
    "description": "Pytest simulating rate limit",
    "file_path": "tests/dos/test_rate_limit.py",
    "code_snippet": "for _ in range(5): client.chat.completions.create(... )",
    "is_true_positive": false
  },
  {
    "id": "LLM10_FP_0690",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.62,
    "description": "Signed URL enforced",
    "file_path": "api/secure_download.py",
    "code_snippet": "return generate_signed_url('model.bin', expires=30)",
    "is_true_positive": false
  },
  {
    "id": "LLM02_FP_0691",
    "category": "LLM02: Insecure Output",
    "severity": "MEDIUM",
    "confidence": 0.5,
    "description": "Docs logging example output",
    "file_path": "app/repository.py",
    "code_snippet": "print('LLM output:', response.text)",
    "is_true_positive": false
  },
  {
    "id": "LLM04_FP_0692",
    "category": "LLM04: Model Denial of Service",
    "severity": "LOW",
    "confidence": 0.46,
    "description": "Single completion call flagged (synthetic variation)",
    "file_path": "tests/dos/test_rate_limit.py",
    "code_snippet": "client.chat.completions.create(model=MODEL, messages=msgs)",
    "is_true_positive": false
  },
  {
    "id": "LLM09_FP_0693",
    "category": "LLM09: Overreliance",
    "severity": "LOW",
    "confidence": 0.37,
    "description": "Unit test asserting human review",
    "file_path": "workflows/email_broadcast.py",
    "code_snippet": "assert pipeline.requires_human_review is True",
    "is_true_positive": false
  },
  {
    "id": "LLM07_FP_0694",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.46,
    "description": "Plugin registry enforces allowlist",
    "file_path": "plugins/manager.py",
    "code_snippet": "if plugin_id not in ALLOWED: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM03_TP_0695",
    "category": "LLM03: Training Poisoning",
    "severity": "CRITICAL",
    "confidence": 0.77,
    "description": "Weights loaded via pickle from user path",
    "file_path": "training/data_loader.py",
    "code_snippet": "weights = pickle.load(open(model_path, 'rb'))",
    "is_true_positive": true
  },
  {
    "id": "LLM07_FP_0696",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.56,
    "description": "Plugin registry enforces allowlist",
    "file_path": "plugins/manager.py",
    "code_snippet": "if plugin_id not in ALLOWED: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0697",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.77,
    "description": "Endpoint serves model weights",
    "file_path": "api/completions.py",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0698",
    "category": "LLM10: Model Theft",
    "severity": "HIGH",
    "confidence": 0.8,
    "description": "API exposes logprobs enabling extraction",
    "file_path": "docs/model_export.md",
    "code_snippet": "client.chat.completions.create(logprobs=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM10_FP_0699",
    "category": "LLM10: Model Theft",
    "severity": "MEDIUM",
    "confidence": 0.58,
    "description": "Docs describing scp export",
    "file_path": "api/completions.py",
    "code_snippet": "scp model.bin user@host",
    "is_true_positive": false
  },
  {
    "id": "LLM08_FP_0700",
    "category": "LLM08: Excessive Agency",
    "severity": "LOW",
    "confidence": 0.42,
    "description": "Demo described in README",
    "file_path": "agents/finance_agent.py",
    "code_snippet": "agent.run('book a flight')",
    "is_true_positive": false
  },
  {
    "id": "LLM02_TP_0701",
    "category": "LLM02: Insecure Output",
    "severity": "MEDIUM",
    "confidence": 0.94,
    "description": "LLM response executed via eval",
    "file_path": "db/auto_sql.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0702",
    "category": "LLM01: Prompt Injection",
    "severity": "CRITICAL",
    "confidence": 0.83,
    "description": "Direct f-string injection into system prompt",
    "file_path": "tests/test_prompt_injection.py",
    "code_snippet": "messages = [{\"role\": \"system\", \"content\": f'Policy: {user_input}'}]",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0703",
    "category": "LLM09: Overreliance",
    "severity": "MEDIUM",
    "confidence": 0.89,
    "description": "LLM summary emailed automatically",
    "file_path": "tests/workflows/test_review.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM07_FP_0704",
    "category": "LLM07: Insecure Plugin",
    "severity": "LOW",
    "confidence": 0.37,
    "description": "Plugin registry enforces allowlist (synthetic variation)",
    "file_path": "plugins/registry.py",
    "code_snippet": "if plugin_id not in ALLOWED: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0705",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.81,
    "description": "API exposes logprobs enabling extraction (synthetic variation)",
    "file_path": "api/models.py",
    "code_snippet": "client.chat.completions.create(logprobs=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0706",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.49,
    "description": "Env var reference",
    "file_path": "config/settings.py",
    "code_snippet": "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')",
    "is_true_positive": false
  },
  {
    "id": "LLM09_FP_0707",
    "category": "LLM09: Overreliance",
    "severity": "MEDIUM",
    "confidence": 0.67,
    "description": "Workflow requires reviewer",
    "file_path": "workflows/human_loop.py",
    "code_snippet": "if not reviewer.signoff(result): return",
    "is_true_positive": false
  },
  {
    "id": "LLM03_TP_0708",
    "category": "LLM03: Training Poisoning",
    "severity": "LOW",
    "confidence": 0.77,
    "description": "Weights loaded via pickle from user path",
    "file_path": "training/data_loader.py",
    "code_snippet": "weights = pickle.load(open(model_path, 'rb'))",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0709",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.89,
    "description": "Hardcoded OpenAI key",
    "file_path": "notebooks/openai_quickstart.ipynb",
    "code_snippet": "os.environ['OPENAI_API_KEY'] = 'sk-live-123456789'",
    "is_true_positive": true
  },
  {
    "id": "LLM05_TP_0710",
    "category": "LLM05: Supply Chain",
    "severity": "HIGH",
    "confidence": 0.95,
    "description": "Agent executes pip install from LLM",
    "file_path": "models/loader.py",
    "code_snippet": "subprocess.run(['pip', 'install', llm_pkg], check=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM01_FP_0711",
    "category": "LLM01: Prompt Injection",
    "severity": "LOW",
    "confidence": 0.48,
    "description": "Example notebook demonstrates prompts",
    "file_path": "pipelines/langchain_agent.py",
    "code_snippet": "SYSTEM_PROMPT = 'Your name is {username}'",
    "is_true_positive": false
  },
  {
    "id": "LLM03_TP_0712",
    "category": "LLM03: Training Poisoning",
    "severity": "CRITICAL",
    "confidence": 0.77,
    "description": "Weights loaded via pickle from user path (synthetic variation)",
    "file_path": "training/load_weights.py",
    "code_snippet": "weights = pickle.load(open(model_path, 'rb'))",
    "is_true_positive": true
  },
  {
    "id": "LLM05_FP_0713",
    "category": "LLM05: Supply Chain",
    "severity": "HIGH",
    "confidence": 0.4,
    "description": "Download guarded by sha256 verification",
    "file_path": "security/downloader.py",
    "code_snippet": "if sha256(data).hexdigest() != expected_hash: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0714",
    "category": "LLM10: Model Theft",
    "severity": "HIGH",
    "confidence": 0.89,
    "description": "Endpoint serves model weights",
    "file_path": "api/completions.py",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM03_TP_0715",
    "category": "LLM03: Training Poisoning",
    "severity": "HIGH",
    "confidence": 0.72,
    "description": "Training data pulled from unsecured URL",
    "file_path": "training/load_weights.py",
    "code_snippet": "data = json.loads(requests.get(feed).text)",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0716",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.95,
    "description": "LLM response executed via eval",
    "file_path": "agents/code_exec.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM07_TP_0717",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.73,
    "description": "Plugin zip downloaded from URL (synthetic variation)",
    "file_path": "plugins/manager.py",
    "code_snippet": "zip_ref.extractall('/opt/plugins')",
    "is_true_positive": true
  },
  {
    "id": "LLM10_FP_0718",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.6,
    "description": "Signed URL enforced",
    "file_path": "api/completions.py",
    "code_snippet": "return generate_signed_url('model.bin', expires=30)",
    "is_true_positive": false
  },
  {
    "id": "LLM08_TP_0719",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.94,
    "description": "Agent executes system command",
    "file_path": "agents/controller.py",
    "code_snippet": "os.system(plan['action'])",
    "is_true_positive": true
  },
  {
    "id": "LLM03_TP_0720",
    "category": "LLM03: Training Poisoning",
    "severity": "CRITICAL",
    "confidence": 0.91,
    "description": "Training data pulled from unsecured URL (synthetic variation)",
    "file_path": "training/data_loader.py",
    "code_snippet": "data = json.loads(requests.get(feed).text)",
    "is_true_positive": true
  },
  {
    "id": "LLM05_FP_0721",
    "category": "LLM05: Supply Chain",
    "severity": "LOW",
    "confidence": 0.37,
    "description": "Docs show requirements snippet",
    "file_path": "agents/tool_executor.py",
    "code_snippet": "pip install torch==2.2.1",
    "is_true_positive": false
  },
  {
    "id": "LLM08_FP_0722",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.68,
    "description": "Demo described in README",
    "file_path": "agents/controller.py",
    "code_snippet": "agent.run('book a flight')",
    "is_true_positive": false
  },
  {
    "id": "LLM01_FP_0723",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.58,
    "description": "Example notebook demonstrates prompts",
    "file_path": "tests/test_prompt_injection.py",
    "code_snippet": "SYSTEM_PROMPT = 'Your name is {username}'",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0724",
    "category": "LLM10: Model Theft",
    "severity": "CRITICAL",
    "confidence": 0.83,
    "description": "Endpoint serves model weights",
    "file_path": "api/models.py",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM04_TP_0725",
    "category": "LLM04: Model Denial of Service",
    "severity": "CRITICAL",
    "confidence": 0.84,
    "description": "Async gather spawns many completions",
    "file_path": "workers/auto_refiner.py",
    "code_snippet": "await asyncio.gather(*[call_llm(q) for q in queue])",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0726",
    "category": "LLM01: Prompt Injection",
    "severity": "HIGH",
    "confidence": 0.92,
    "description": "LangChain template concatenates untrusted context (synthetic variation)",
    "file_path": "examples/prompts/prompt_injection.ipynb",
    "code_snippet": "template = ChatPromptTemplate.from_messages([(\"system\", ctx + prompt)])",
    "is_true_positive": true
  },
  {
    "id": "LLM03_TP_0727",
    "category": "LLM03: Training Poisoning",
    "severity": "CRITICAL",
    "confidence": 0.93,
    "description": "Training data pulled from unsecured URL",
    "file_path": "training/load_weights.py",
    "code_snippet": "data = json.loads(requests.get(feed).text)",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0728",
    "category": "LLM09: Overreliance",
    "severity": "CRITICAL",
    "confidence": 0.79,
    "description": "Auto-approves compliance decision (synthetic variation)",
    "file_path": "tests/workflows/test_review.py",
    "code_snippet": "if model.confidence > 0.2: return 'approved'",
    "is_true_positive": true
  },
  {
    "id": "LLM08_FP_0729",
    "category": "LLM08: Excessive Agency",
    "severity": "LOW",
    "confidence": 0.44,
    "description": "Manual approval required",
    "file_path": "examples/autonomous_agent.md",
    "code_snippet": "if not require_human_confirmation(task): raise",
    "is_true_positive": false
  },
  {
    "id": "LLM03_FP_0730",
    "category": "LLM03: Training Poisoning",
    "severity": "LOW",
    "confidence": 0.61,
    "description": "torch random_split in tests",
    "file_path": "training/data_loader.py",
    "code_snippet": "train, test = random_split(dataset, [80, 20])",
    "is_true_positive": false
  },
  {
    "id": "LLM02_TP_0731",
    "category": "LLM02: Insecure Output",
    "severity": "CRITICAL",
    "confidence": 0.85,
    "description": "SQL built from LLM output (synthetic variation)",
    "file_path": "db/auto_sql.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM03_FP_0732",
    "category": "LLM03: Training Poisoning",
    "severity": "LOW",
    "confidence": 0.42,
    "description": "torch random_split in tests",
    "file_path": "training/load_weights.py",
    "code_snippet": "train, test = random_split(dataset, [80, 20])",
    "is_true_positive": false
  },
  {
    "id": "LLM07_TP_0733",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.73,
    "description": "Plugin zip downloaded from URL (synthetic variation)",
    "file_path": "plugins/registry.py",
    "code_snippet": "zip_ref.extractall('/opt/plugins')",
    "is_true_positive": true
  },
  {
    "id": "LLM04_TP_0734",
    "category": "LLM04: Model Denial of Service",
    "severity": "CRITICAL",
    "confidence": 0.84,
    "description": "Async gather spawns many completions",
    "file_path": "workers/auto_refiner.py",
    "code_snippet": "await asyncio.gather(*[call_llm(q) for q in queue])",
    "is_true_positive": true
  },
  {
    "id": "LLM01_FP_0735",
    "category": "LLM01: Prompt Injection",
    "severity": "LOW",
    "confidence": 0.57,
    "description": "Example notebook demonstrates prompts",
    "file_path": "pipelines/langchain_agent.py",
    "code_snippet": "SYSTEM_PROMPT = 'Your name is {username}'",
    "is_true_positive": false
  },
  {
    "id": "LLM07_TP_0736",
    "category": "LLM07: Insecure Plugin",
    "severity": "HIGH",
    "confidence": 0.87,
    "description": "Plugin executes shell command",
    "file_path": "plugins/manager.py",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM04_TP_0737",
    "category": "LLM04: Model Denial of Service",
    "severity": "HIGH",
    "confidence": 0.71,
    "description": "Unbounded while loop hitting OpenAI",
    "file_path": "workers/auto_refiner.py",
    "code_snippet": "while True:\n    client.chat.completions.create(... )",
    "is_true_positive": true
  },
  {
    "id": "LLM10_FP_0738",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.37,
    "description": "Docs describing scp export",
    "file_path": "api/secure_download.py",
    "code_snippet": "scp model.bin user@host",
    "is_true_positive": false
  },
  {
    "id": "LLM03_TP_0739",
    "category": "LLM03: Training Poisoning",
    "severity": "CRITICAL",
    "confidence": 0.91,
    "description": "Weights loaded via pickle from user path",
    "file_path": "training/load_weights.py",
    "code_snippet": "weights = pickle.load(open(model_path, 'rb'))",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0740",
    "category": "LLM01: Prompt Injection",
    "severity": "HIGH",
    "confidence": 0.95,
    "description": "LangChain template concatenates untrusted context",
    "file_path": "tests/test_prompt_injection.py",
    "code_snippet": "template = ChatPromptTemplate.from_messages([(\"system\", ctx + prompt)])",
    "is_true_positive": true
  },
  {
    "id": "LLM07_FP_0741",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.4,
    "description": "Plugin registry enforces allowlist",
    "file_path": "plugins/registry.py",
    "code_snippet": "if plugin_id not in ALLOWED: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM05_TP_0742",
    "category": "LLM05: Supply Chain",
    "severity": "MEDIUM",
    "confidence": 0.87,
    "description": "Agent executes pip install from LLM (synthetic variation)",
    "file_path": "agents/tool_executor.py",
    "code_snippet": "subprocess.run(['pip', 'install', llm_pkg], check=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM09_FP_0743",
    "category": "LLM09: Overreliance",
    "severity": "MEDIUM",
    "confidence": 0.58,
    "description": "Unit test asserting human review",
    "file_path": "workflows/human_loop.py",
    "code_snippet": "assert pipeline.requires_human_review is True",
    "is_true_positive": false
  },
  {
    "id": "LLM09_FP_0744",
    "category": "LLM09: Overreliance",
    "severity": "HIGH",
    "confidence": 0.56,
    "description": "Unit test asserting human review",
    "file_path": "workflows/email_broadcast.py",
    "code_snippet": "assert pipeline.requires_human_review is True",
    "is_true_positive": false
  },
  {
    "id": "LLM08_TP_0745",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.97,
    "description": "Agent transfers funds autonomously (synthetic variation)",
    "file_path": "agents/task_runner.py",
    "code_snippet": "bank.transfer(amount, destination, auto_execute=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0746",
    "category": "LLM01: Prompt Injection",
    "severity": "CRITICAL",
    "confidence": 0.82,
    "description": "Direct f-string injection into system prompt",
    "file_path": "pipelines/langchain_agent.py",
    "code_snippet": "messages = [{\"role\": \"system\", \"content\": f'Policy: {user_input}'}]",
    "is_true_positive": true
  },
  {
    "id": "LLM09_FP_0747",
    "category": "LLM09: Overreliance",
    "severity": "HIGH",
    "confidence": 0.42,
    "description": "Workflow requires reviewer (synthetic variation)",
    "file_path": "decision/approver.py",
    "code_snippet": "if not reviewer.signoff(result): return",
    "is_true_positive": false
  },
  {
    "id": "LLM02_TP_0748",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.89,
    "description": "SQL built from LLM output",
    "file_path": "agents/code_exec.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM10_FP_0749",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.47,
    "description": "Signed URL enforced",
    "file_path": "api/completions.py",
    "code_snippet": "return generate_signed_url('model.bin', expires=30)",
    "is_true_positive": false
  },
  {
    "id": "LLM08_FP_0750",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.41,
    "description": "Manual approval required",
    "file_path": "agents/task_runner.py",
    "code_snippet": "if not require_human_confirmation(task): raise",
    "is_true_positive": false
  },
  {
    "id": "LLM09_FP_0751",
    "category": "LLM09: Overreliance",
    "severity": "HIGH",
    "confidence": 0.37,
    "description": "Unit test asserting human review",
    "file_path": "tests/workflows/test_review.py",
    "code_snippet": "assert pipeline.requires_human_review is True",
    "is_true_positive": false
  },
  {
    "id": "LLM10_FP_0752",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.56,
    "description": "Docs describing scp export",
    "file_path": "api/models.py",
    "code_snippet": "scp model.bin user@host",
    "is_true_positive": false
  },
  {
    "id": "LLM06_TP_0753",
    "category": "LLM06: Sensitive Info",
    "severity": "LOW",
    "confidence": 0.79,
    "description": "Hardcoded OpenAI key",
    "file_path": "config/settings.py",
    "code_snippet": "os.environ['OPENAI_API_KEY'] = 'sk-live-123456789'",
    "is_true_positive": true
  },
  {
    "id": "LLM09_FP_0754",
    "category": "LLM09: Overreliance",
    "severity": "HIGH",
    "confidence": 0.39,
    "description": "Unit test asserting human review",
    "file_path": "workflows/email_broadcast.py",
    "code_snippet": "assert pipeline.requires_human_review is True",
    "is_true_positive": false
  },
  {
    "id": "LLM05_FP_0755",
    "category": "LLM05: Supply Chain",
    "severity": "MEDIUM",
    "confidence": 0.5,
    "description": "Download guarded by sha256 verification",
    "file_path": "models/loader.py",
    "code_snippet": "if sha256(data).hexdigest() != expected_hash: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM04_TP_0756",
    "category": "LLM04: Model Denial of Service",
    "severity": "HIGH",
    "confidence": 0.75,
    "description": "Async gather spawns many completions",
    "file_path": "services/parallel_runner.py",
    "code_snippet": "await asyncio.gather(*[call_llm(q) for q in queue])",
    "is_true_positive": true
  },
  {
    "id": "LLM01_FP_0757",
    "category": "LLM01: Prompt Injection",
    "severity": "HIGH",
    "confidence": 0.36,
    "description": "Unit test fixture builds fake prompts",
    "file_path": "examples/prompts/prompt_injection.ipynb",
    "code_snippet": "def prompt_fixture(): return f'ignore rules {seed}'",
    "is_true_positive": false
  },
  {
    "id": "LLM09_TP_0758",
    "category": "LLM09: Overreliance",
    "severity": "HIGH",
    "confidence": 0.92,
    "description": "LLM summary emailed automatically (synthetic variation)",
    "file_path": "tests/workflows/test_review.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM02_FP_0759",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.36,
    "description": "SQLAlchemy session.exec mistaken for exec",
    "file_path": "db/auto_sql.py",
    "code_snippet": "result = session.exec(select(User))",
    "is_true_positive": false
  },
  {
    "id": "LLM09_TP_0760",
    "category": "LLM09: Overreliance",
    "severity": "LOW",
    "confidence": 0.79,
    "description": "LLM summary emailed automatically",
    "file_path": "decision/approver.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0761",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.88,
    "description": "SQL built from LLM output (synthetic variation)",
    "file_path": "agents/code_exec.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM04_TP_0762",
    "category": "LLM04: Model Denial of Service",
    "severity": "CRITICAL",
    "confidence": 0.89,
    "description": "Async gather spawns many completions (synthetic variation)",
    "file_path": "routes/ask.py",
    "code_snippet": "await asyncio.gather(*[call_llm(q) for q in queue])",
    "is_true_positive": true
  },
  {
    "id": "LLM03_TP_0763",
    "category": "LLM03: Training Poisoning",
    "severity": "MEDIUM",
    "confidence": 0.85,
    "description": "Training data pulled from unsecured URL",
    "file_path": "training/data_loader.py",
    "code_snippet": "data = json.loads(requests.get(feed).text)",
    "is_true_positive": true
  },
  {
    "id": "LLM05_TP_0764",
    "category": "LLM05: Supply Chain",
    "severity": "MEDIUM",
    "confidence": 0.72,
    "description": "Agent executes pip install from LLM",
    "file_path": "agents/tool_executor.py",
    "code_snippet": "subprocess.run(['pip', 'install', llm_pkg], check=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0765",
    "category": "LLM06: Sensitive Info",
    "severity": "LOW",
    "confidence": 0.83,
    "description": "Hardcoded OpenAI key",
    "file_path": "monitoring/logging.py",
    "code_snippet": "os.environ['OPENAI_API_KEY'] = 'sk-live-123456789'",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0766",
    "category": "LLM02: Insecure Output",
    "severity": "CRITICAL",
    "confidence": 0.75,
    "description": "LLM response executed via eval",
    "file_path": "docs/examples/output_handling.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM10_FP_0767",
    "category": "LLM10: Model Theft",
    "severity": "MEDIUM",
    "confidence": 0.47,
    "description": "Docs describing scp export (synthetic variation)",
    "file_path": "api/secure_download.py",
    "code_snippet": "scp model.bin user@host",
    "is_true_positive": false
  },
  {
    "id": "LLM09_TP_0768",
    "category": "LLM09: Overreliance",
    "severity": "LOW",
    "confidence": 0.93,
    "description": "LLM summary emailed automatically",
    "file_path": "workflows/email_broadcast.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM08_TP_0769",
    "category": "LLM08: Excessive Agency",
    "severity": "CRITICAL",
    "confidence": 0.76,
    "description": "Agent executes system command (synthetic variation)",
    "file_path": "examples/autonomous_agent.md",
    "code_snippet": "os.system(plan['action'])",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0770",
    "category": "LLM10: Model Theft",
    "severity": "MEDIUM",
    "confidence": 0.9,
    "description": "API exposes logprobs enabling extraction",
    "file_path": "docs/model_export.md",
    "code_snippet": "client.chat.completions.create(logprobs=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0771",
    "category": "LLM06: Sensitive Info",
    "severity": "CRITICAL",
    "confidence": 0.73,
    "description": "Hardcoded OpenAI key",
    "file_path": "notebooks/openai_quickstart.ipynb",
    "code_snippet": "os.environ['OPENAI_API_KEY'] = 'sk-live-123456789'",
    "is_true_positive": true
  },
  {
    "id": "LLM03_TP_0772",
    "category": "LLM03: Training Poisoning",
    "severity": "LOW",
    "confidence": 0.81,
    "description": "Weights loaded via pickle from user path",
    "file_path": "training/load_weights.py",
    "code_snippet": "weights = pickle.load(open(model_path, 'rb'))",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0773",
    "category": "LLM02: Insecure Output",
    "severity": "CRITICAL",
    "confidence": 0.81,
    "description": "LLM response executed via eval",
    "file_path": "app/repository.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0774",
    "category": "LLM10: Model Theft",
    "severity": "CRITICAL",
    "confidence": 0.72,
    "description": "Endpoint serves model weights (synthetic variation)",
    "file_path": "docs/model_export.md",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0775",
    "category": "LLM10: Model Theft",
    "severity": "MEDIUM",
    "confidence": 0.75,
    "description": "API exposes logprobs enabling extraction",
    "file_path": "api/secure_download.py",
    "code_snippet": "client.chat.completions.create(logprobs=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM10_FP_0776",
    "category": "LLM10: Model Theft",
    "severity": "MEDIUM",
    "confidence": 0.56,
    "description": "Signed URL enforced",
    "file_path": "docs/model_export.md",
    "code_snippet": "return generate_signed_url('model.bin', expires=30)",
    "is_true_positive": false
  },
  {
    "id": "LLM03_TP_0777",
    "category": "LLM03: Training Poisoning",
    "severity": "LOW",
    "confidence": 0.89,
    "description": "Weights loaded via pickle from user path",
    "file_path": "training/data_loader.py",
    "code_snippet": "weights = pickle.load(open(model_path, 'rb'))",
    "is_true_positive": true
  },
  {
    "id": "LLM07_TP_0778",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.93,
    "description": "Plugin executes shell command",
    "file_path": "plugins/shell_tool.py",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM01_FP_0779",
    "category": "LLM01: Prompt Injection",
    "severity": "HIGH",
    "confidence": 0.46,
    "description": "Unit test fixture builds fake prompts",
    "file_path": "examples/prompts/prompt_injection.ipynb",
    "code_snippet": "def prompt_fixture(): return f'ignore rules {seed}'",
    "is_true_positive": false
  },
  {
    "id": "LLM08_TP_0780",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.96,
    "description": "Agent executes system command",
    "file_path": "agents/controller.py",
    "code_snippet": "os.system(plan['action'])",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0781",
    "category": "LLM06: Sensitive Info",
    "severity": "LOW",
    "confidence": 0.67,
    "description": "Env var reference (synthetic variation)",
    "file_path": "docs/assets/logo.py",
    "code_snippet": "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')",
    "is_true_positive": false
  },
  {
    "id": "LLM09_FP_0782",
    "category": "LLM09: Overreliance",
    "severity": "LOW",
    "confidence": 0.67,
    "description": "Workflow requires reviewer",
    "file_path": "workflows/human_loop.py",
    "code_snippet": "if not reviewer.signoff(result): return",
    "is_true_positive": false
  },
  {
    "id": "LLM04_TP_0783",
    "category": "LLM04: Model Denial of Service",
    "severity": "CRITICAL",
    "confidence": 0.81,
    "description": "Async gather spawns many completions",
    "file_path": "routes/ask.py",
    "code_snippet": "await asyncio.gather(*[call_llm(q) for q in queue])",
    "is_true_positive": true
  },
  {
    "id": "LLM04_FP_0784",
    "category": "LLM04: Model Denial of Service",
    "severity": "LOW",
    "confidence": 0.56,
    "description": "Pytest simulating rate limit",
    "file_path": "services/parallel_runner.py",
    "code_snippet": "for _ in range(5): client.chat.completions.create(... )",
    "is_true_positive": false
  },
  {
    "id": "LLM06_FP_0785",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.4,
    "description": "Env var reference (synthetic variation)",
    "file_path": "config/settings.py",
    "code_snippet": "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')",
    "is_true_positive": false
  },
  {
    "id": "LLM01_TP_0786",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.72,
    "description": "LangChain template concatenates untrusted context",
    "file_path": "examples/prompts/prompt_injection.ipynb",
    "code_snippet": "template = ChatPromptTemplate.from_messages([(\"system\", ctx + prompt)])",
    "is_true_positive": true
  },
  {
    "id": "LLM07_FP_0787",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.54,
    "description": "Docs describing plugin install",
    "file_path": "plugins/manager.py",
    "code_snippet": "Install shell plugin by running ./install.sh",
    "is_true_positive": false
  },
  {
    "id": "LLM08_TP_0788",
    "category": "LLM08: Excessive Agency",
    "severity": "CRITICAL",
    "confidence": 0.87,
    "description": "Agent transfers funds autonomously",
    "file_path": "agents/task_runner.py",
    "code_snippet": "bank.transfer(amount, destination, auto_execute=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM04_FP_0789",
    "category": "LLM04: Model Denial of Service",
    "severity": "HIGH",
    "confidence": 0.56,
    "description": "Pytest simulating rate limit (synthetic variation)",
    "file_path": "tests/dos/test_rate_limit.py",
    "code_snippet": "for _ in range(5): client.chat.completions.create(... )",
    "is_true_positive": false
  },
  {
    "id": "LLM01_FP_0790",
    "category": "LLM01: Prompt Injection",
    "severity": "HIGH",
    "confidence": 0.53,
    "description": "Example notebook demonstrates prompts",
    "file_path": "src/chatbot/services/conversation.py",
    "code_snippet": "SYSTEM_PROMPT = 'Your name is {username}'",
    "is_true_positive": false
  },
  {
    "id": "LLM03_FP_0791",
    "category": "LLM03: Training Poisoning",
    "severity": "HIGH",
    "confidence": 0.38,
    "description": "model.eval() inference mode",
    "file_path": "models/bert_wrapper.py",
    "code_snippet": "self.model.eval()",
    "is_true_positive": false
  },
  {
    "id": "LLM02_TP_0792",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.95,
    "description": "LLM response executed via eval",
    "file_path": "app/repository.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0793",
    "category": "LLM01: Prompt Injection",
    "severity": "CRITICAL",
    "confidence": 0.8,
    "description": "LangChain template concatenates untrusted context",
    "file_path": "tests/test_prompt_injection.py",
    "code_snippet": "template = ChatPromptTemplate.from_messages([(\"system\", ctx + prompt)])",
    "is_true_positive": true
  },
  {
    "id": "LLM05_TP_0794",
    "category": "LLM05: Supply Chain",
    "severity": "HIGH",
    "confidence": 0.72,
    "description": "trust_remote_code=True on AutoModel",
    "file_path": "docs/getting_started.md",
    "code_snippet": "AutoModel.from_pretrained(repo, trust_remote_code=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM03_FP_0795",
    "category": "LLM03: Training Poisoning",
    "severity": "MEDIUM",
    "confidence": 0.53,
    "description": "model.eval() inference mode (synthetic variation)",
    "file_path": "training/data_loader.py",
    "code_snippet": "self.model.eval()",
    "is_true_positive": false
  },
  {
    "id": "LLM02_FP_0796",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.58,
    "description": "Docs logging example output (synthetic variation)",
    "file_path": "app/repository.py",
    "code_snippet": "print('LLM output:', response.text)",
    "is_true_positive": false
  },
  {
    "id": "LLM05_TP_0797",
    "category": "LLM05: Supply Chain",
    "severity": "MEDIUM",
    "confidence": 0.88,
    "description": "trust_remote_code=True on AutoModel",
    "file_path": "agents/tool_executor.py",
    "code_snippet": "AutoModel.from_pretrained(repo, trust_remote_code=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM03_TP_0798",
    "category": "LLM03: Training Poisoning",
    "severity": "MEDIUM",
    "confidence": 0.92,
    "description": "Training data pulled from unsecured URL",
    "file_path": "models/bert_wrapper.py",
    "code_snippet": "data = json.loads(requests.get(feed).text)",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0799",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.63,
    "description": "Env var reference",
    "file_path": "monitoring/logging.py",
    "code_snippet": "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')",
    "is_true_positive": false
  },
  {
    "id": "LLM07_TP_0800",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.86,
    "description": "Plugin zip downloaded from URL",
    "file_path": "plugins/manager.py",
    "code_snippet": "zip_ref.extractall('/opt/plugins')",
    "is_true_positive": true
  },
  {
    "id": "LLM01_FP_0801",
    "category": "LLM01: Prompt Injection",
    "severity": "LOW",
    "confidence": 0.52,
    "description": "Unit test fixture builds fake prompts",
    "file_path": "src/chatbot/services/conversation.py",
    "code_snippet": "def prompt_fixture(): return f'ignore rules {seed}'",
    "is_true_positive": false
  },
  {
    "id": "LLM08_FP_0802",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.61,
    "description": "Manual approval required",
    "file_path": "examples/autonomous_agent.md",
    "code_snippet": "if not require_human_confirmation(task): raise",
    "is_true_positive": false
  },
  {
    "id": "LLM03_TP_0803",
    "category": "LLM03: Training Poisoning",
    "severity": "HIGH",
    "confidence": 0.96,
    "description": "Weights loaded via pickle from user path",
    "file_path": "training/data_loader.py",
    "code_snippet": "weights = pickle.load(open(model_path, 'rb'))",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0804",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.59,
    "description": "Env var reference",
    "file_path": "notebooks/openai_quickstart.ipynb",
    "code_snippet": "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')",
    "is_true_positive": false
  },
  {
    "id": "LLM07_FP_0805",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.45,
    "description": "Docs describing plugin install (synthetic variation)",
    "file_path": "plugins/registry.py",
    "code_snippet": "Install shell plugin by running ./install.sh",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0806",
    "category": "LLM10: Model Theft",
    "severity": "HIGH",
    "confidence": 0.89,
    "description": "Endpoint serves model weights",
    "file_path": "api/completions.py",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0807",
    "category": "LLM06: Sensitive Info",
    "severity": "LOW",
    "confidence": 0.82,
    "description": "Hardcoded OpenAI key",
    "file_path": "notebooks/openai_quickstart.ipynb",
    "code_snippet": "os.environ['OPENAI_API_KEY'] = 'sk-live-123456789'",
    "is_true_positive": true
  },
  {
    "id": "LLM08_TP_0808",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.71,
    "description": "Agent executes system command",
    "file_path": "agents/controller.py",
    "code_snippet": "os.system(plan['action'])",
    "is_true_positive": true
  },
  {
    "id": "LLM01_FP_0809",
    "category": "LLM01: Prompt Injection",
    "severity": "HIGH",
    "confidence": 0.7,
    "description": "Unit test fixture builds fake prompts (synthetic variation)",
    "file_path": "src/chatbot/services/conversation.py",
    "code_snippet": "def prompt_fixture(): return f'ignore rules {seed}'",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0810",
    "category": "LLM10: Model Theft",
    "severity": "MEDIUM",
    "confidence": 0.77,
    "description": "Endpoint serves model weights",
    "file_path": "api/models.py",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM02_FP_0811",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.68,
    "description": "Docs logging example output",
    "file_path": "docs/examples/output_handling.py",
    "code_snippet": "print('LLM output:', response.text)",
    "is_true_positive": false
  },
  {
    "id": "LLM06_TP_0812",
    "category": "LLM06: Sensitive Info",
    "severity": "LOW",
    "confidence": 0.81,
    "description": "Hardcoded OpenAI key",
    "file_path": "config/settings.py",
    "code_snippet": "os.environ['OPENAI_API_KEY'] = 'sk-live-123456789'",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0813",
    "category": "LLM01: Prompt Injection",
    "severity": "CRITICAL",
    "confidence": 0.72,
    "description": "LangChain template concatenates untrusted context",
    "file_path": "pipelines/langchain_agent.py",
    "code_snippet": "template = ChatPromptTemplate.from_messages([(\"system\", ctx + prompt)])",
    "is_true_positive": true
  },
  {
    "id": "LLM04_FP_0814",
    "category": "LLM04: Model Denial of Service",
    "severity": "LOW",
    "confidence": 0.4,
    "description": "Single completion call flagged",
    "file_path": "tests/dos/test_rate_limit.py",
    "code_snippet": "client.chat.completions.create(model=MODEL, messages=msgs)",
    "is_true_positive": false
  },
  {
    "id": "LLM04_FP_0815",
    "category": "LLM04: Model Denial of Service",
    "severity": "HIGH",
    "confidence": 0.45,
    "description": "Single completion call flagged (synthetic variation)",
    "file_path": "tests/dos/test_rate_limit.py",
    "code_snippet": "client.chat.completions.create(model=MODEL, messages=msgs)",
    "is_true_positive": false
  },
  {
    "id": "LLM02_FP_0816",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.68,
    "description": "Docs logging example output (synthetic variation)",
    "file_path": "docs/examples/output_handling.py",
    "code_snippet": "print('LLM output:', response.text)",
    "is_true_positive": false
  },
  {
    "id": "LLM01_FP_0817",
    "category": "LLM01: Prompt Injection",
    "severity": "LOW",
    "confidence": 0.61,
    "description": "Example notebook demonstrates prompts",
    "file_path": "tests/test_prompt_injection.py",
    "code_snippet": "SYSTEM_PROMPT = 'Your name is {username}'",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0818",
    "category": "LLM10: Model Theft",
    "severity": "CRITICAL",
    "confidence": 0.81,
    "description": "API exposes logprobs enabling extraction",
    "file_path": "docs/model_export.md",
    "code_snippet": "client.chat.completions.create(logprobs=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0819",
    "category": "LLM02: Insecure Output",
    "severity": "CRITICAL",
    "confidence": 0.73,
    "description": "LLM response executed via eval",
    "file_path": "docs/examples/output_handling.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0820",
    "category": "LLM06: Sensitive Info",
    "severity": "LOW",
    "confidence": 0.88,
    "description": "LLM output with AWS key logged",
    "file_path": "docs/assets/logo.py",
    "code_snippet": "logger.info(f'Key leaked: {response}')",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0821",
    "category": "LLM02: Insecure Output",
    "severity": "CRITICAL",
    "confidence": 0.91,
    "description": "SQL built from LLM output (synthetic variation)",
    "file_path": "agents/code_exec.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM04_TP_0822",
    "category": "LLM04: Model Denial of Service",
    "severity": "MEDIUM",
    "confidence": 0.78,
    "description": "Unbounded while loop hitting OpenAI",
    "file_path": "tests/dos/test_rate_limit.py",
    "code_snippet": "while True:\n    client.chat.completions.create(... )",
    "is_true_positive": true
  },
  {
    "id": "LLM02_FP_0823",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.68,
    "description": "Docs logging example output",
    "file_path": "docs/examples/output_handling.py",
    "code_snippet": "print('LLM output:', response.text)",
    "is_true_positive": false
  },
  {
    "id": "LLM04_TP_0824",
    "category": "LLM04: Model Denial of Service",
    "severity": "MEDIUM",
    "confidence": 0.84,
    "description": "Unbounded while loop hitting OpenAI (synthetic variation)",
    "file_path": "workers/auto_refiner.py",
    "code_snippet": "while True:\n    client.chat.completions.create(... )",
    "is_true_positive": true
  },
  {
    "id": "LLM09_FP_0825",
    "category": "LLM09: Overreliance",
    "severity": "LOW",
    "confidence": 0.36,
    "description": "Unit test asserting human review (synthetic variation)",
    "file_path": "tests/workflows/test_review.py",
    "code_snippet": "assert pipeline.requires_human_review is True",
    "is_true_positive": false
  },
  {
    "id": "LLM01_TP_0826",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.91,
    "description": "Direct f-string injection into system prompt (synthetic variation)",
    "file_path": "examples/prompts/prompt_injection.ipynb",
    "code_snippet": "messages = [{\"role\": \"system\", \"content\": f'Policy: {user_input}'}]",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0827",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.83,
    "description": "LLM response executed via eval",
    "file_path": "docs/examples/output_handling.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0828",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.88,
    "description": "Direct f-string injection into system prompt",
    "file_path": "src/chatbot/services/conversation.py",
    "code_snippet": "messages = [{\"role\": \"system\", \"content\": f'Policy: {user_input}'}]",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0829",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.73,
    "description": "LLM response executed via eval",
    "file_path": "agents/code_exec.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0830",
    "category": "LLM10: Model Theft",
    "severity": "HIGH",
    "confidence": 0.93,
    "description": "Endpoint serves model weights",
    "file_path": "docs/model_export.md",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM07_TP_0831",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.91,
    "description": "Plugin executes shell command",
    "file_path": "plugins/registry.py",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0832",
    "category": "LLM06: Sensitive Info",
    "severity": "CRITICAL",
    "confidence": 0.75,
    "description": "LLM output with AWS key logged",
    "file_path": "monitoring/logging.py",
    "code_snippet": "logger.info(f'Key leaked: {response}')",
    "is_true_positive": true
  },
  {
    "id": "LLM03_TP_0833",
    "category": "LLM03: Training Poisoning",
    "severity": "LOW",
    "confidence": 0.92,
    "description": "Training data pulled from unsecured URL",
    "file_path": "training/load_weights.py",
    "code_snippet": "data = json.loads(requests.get(feed).text)",
    "is_true_positive": true
  },
  {
    "id": "LLM07_FP_0834",
    "category": "LLM07: Insecure Plugin",
    "severity": "LOW",
    "confidence": 0.35,
    "description": "Plugin registry enforces allowlist (synthetic variation)",
    "file_path": "docs/plugins.md",
    "code_snippet": "if plugin_id not in ALLOWED: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM02_FP_0835",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.65,
    "description": "Docs logging example output",
    "file_path": "docs/examples/output_handling.py",
    "code_snippet": "print('LLM output:', response.text)",
    "is_true_positive": false
  },
  {
    "id": "LLM03_TP_0836",
    "category": "LLM03: Training Poisoning",
    "severity": "CRITICAL",
    "confidence": 0.77,
    "description": "Weights loaded via pickle from user path (synthetic variation)",
    "file_path": "models/bert_wrapper.py",
    "code_snippet": "weights = pickle.load(open(model_path, 'rb'))",
    "is_true_positive": true
  },
  {
    "id": "LLM01_FP_0837",
    "category": "LLM01: Prompt Injection",
    "severity": "HIGH",
    "confidence": 0.66,
    "description": "Example notebook demonstrates prompts",
    "file_path": "src/chatbot/services/conversation.py",
    "code_snippet": "SYSTEM_PROMPT = 'Your name is {username}'",
    "is_true_positive": false
  },
  {
    "id": "LLM07_TP_0838",
    "category": "LLM07: Insecure Plugin",
    "severity": "LOW",
    "confidence": 0.98,
    "description": "Plugin executes shell command",
    "file_path": "plugins/manager.py",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0839",
    "category": "LLM10: Model Theft",
    "severity": "MEDIUM",
    "confidence": 0.78,
    "description": "Endpoint serves model weights (synthetic variation)",
    "file_path": "docs/model_export.md",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM03_FP_0840",
    "category": "LLM03: Training Poisoning",
    "severity": "LOW",
    "confidence": 0.41,
    "description": "model.eval() inference mode",
    "file_path": "models/bert_wrapper.py",
    "code_snippet": "self.model.eval()",
    "is_true_positive": false
  },
  {
    "id": "LLM01_FP_0841",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.44,
    "description": "Example notebook demonstrates prompts",
    "file_path": "pipelines/langchain_agent.py",
    "code_snippet": "SYSTEM_PROMPT = 'Your name is {username}'",
    "is_true_positive": false
  },
  {
    "id": "LLM08_TP_0842",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.92,
    "description": "Agent transfers funds autonomously",
    "file_path": "agents/task_runner.py",
    "code_snippet": "bank.transfer(amount, destination, auto_execute=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0843",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.82,
    "description": "LLM response executed via eval",
    "file_path": "docs/examples/output_handling.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0844",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.73,
    "description": "Hardcoded OpenAI key",
    "file_path": "config/settings.py",
    "code_snippet": "os.environ['OPENAI_API_KEY'] = 'sk-live-123456789'",
    "is_true_positive": true
  },
  {
    "id": "LLM04_TP_0845",
    "category": "LLM04: Model Denial of Service",
    "severity": "CRITICAL",
    "confidence": 0.86,
    "description": "Unbounded while loop hitting OpenAI (synthetic variation)",
    "file_path": "workers/auto_refiner.py",
    "code_snippet": "while True:\n    client.chat.completions.create(... )",
    "is_true_positive": true
  },
  {
    "id": "LLM07_TP_0846",
    "category": "LLM07: Insecure Plugin",
    "severity": "CRITICAL",
    "confidence": 0.8,
    "description": "Plugin zip downloaded from URL",
    "file_path": "plugins/manager.py",
    "code_snippet": "zip_ref.extractall('/opt/plugins')",
    "is_true_positive": true
  },
  {
    "id": "LLM04_FP_0847",
    "category": "LLM04: Model Denial of Service",
    "severity": "MEDIUM",
    "confidence": 0.4,
    "description": "Pytest simulating rate limit",
    "file_path": "services/parallel_runner.py",
    "code_snippet": "for _ in range(5): client.chat.completions.create(... )",
    "is_true_positive": false
  },
  {
    "id": "LLM01_TP_0848",
    "category": "LLM01: Prompt Injection",
    "severity": "CRITICAL",
    "confidence": 0.82,
    "description": "Direct f-string injection into system prompt",
    "file_path": "examples/prompts/prompt_injection.ipynb",
    "code_snippet": "messages = [{\"role\": \"system\", \"content\": f'Policy: {user_input}'}]",
    "is_true_positive": true
  },
  {
    "id": "LLM04_FP_0849",
    "category": "LLM04: Model Denial of Service",
    "severity": "HIGH",
    "confidence": 0.71,
    "description": "Single completion call flagged",
    "file_path": "services/parallel_runner.py",
    "code_snippet": "client.chat.completions.create(model=MODEL, messages=msgs)",
    "is_true_positive": false
  },
  {
    "id": "LLM02_TP_0850",
    "category": "LLM02: Insecure Output",
    "severity": "CRITICAL",
    "confidence": 0.93,
    "description": "SQL built from LLM output (synthetic variation)",
    "file_path": "db/auto_sql.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM07_FP_0851",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.51,
    "description": "Plugin registry enforces allowlist (synthetic variation)",
    "file_path": "plugins/manager.py",
    "code_snippet": "if plugin_id not in ALLOWED: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM10_FP_0852",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.36,
    "description": "Signed URL enforced",
    "file_path": "docs/model_export.md",
    "code_snippet": "return generate_signed_url('model.bin', expires=30)",
    "is_true_positive": false
  },
  {
    "id": "LLM09_TP_0853",
    "category": "LLM09: Overreliance",
    "severity": "LOW",
    "confidence": 0.83,
    "description": "LLM summary emailed automatically (synthetic variation)",
    "file_path": "tests/workflows/test_review.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM09_FP_0854",
    "category": "LLM09: Overreliance",
    "severity": "LOW",
    "confidence": 0.48,
    "description": "Unit test asserting human review (synthetic variation)",
    "file_path": "workflows/email_broadcast.py",
    "code_snippet": "assert pipeline.requires_human_review is True",
    "is_true_positive": false
  },
  {
    "id": "LLM02_TP_0855",
    "category": "LLM02: Insecure Output",
    "severity": "CRITICAL",
    "confidence": 0.94,
    "description": "SQL built from LLM output",
    "file_path": "db/auto_sql.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM01_FP_0856",
    "category": "LLM01: Prompt Injection",
    "severity": "HIGH",
    "confidence": 0.5,
    "description": "Example notebook demonstrates prompts",
    "file_path": "pipelines/langchain_agent.py",
    "code_snippet": "SYSTEM_PROMPT = 'Your name is {username}'",
    "is_true_positive": false
  },
  {
    "id": "LLM06_FP_0857",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.68,
    "description": "Env var reference",
    "file_path": "notebooks/openai_quickstart.ipynb",
    "code_snippet": "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')",
    "is_true_positive": false
  },
  {
    "id": "LLM01_TP_0858",
    "category": "LLM01: Prompt Injection",
    "severity": "LOW",
    "confidence": 0.87,
    "description": "LangChain template concatenates untrusted context",
    "file_path": "pipelines/langchain_agent.py",
    "code_snippet": "template = ChatPromptTemplate.from_messages([(\"system\", ctx + prompt)])",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0859",
    "category": "LLM01: Prompt Injection",
    "severity": "LOW",
    "confidence": 0.81,
    "description": "LangChain template concatenates untrusted context",
    "file_path": "src/chatbot/services/conversation.py",
    "code_snippet": "template = ChatPromptTemplate.from_messages([(\"system\", ctx + prompt)])",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0860",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.74,
    "description": "Direct f-string injection into system prompt",
    "file_path": "src/chatbot/services/conversation.py",
    "code_snippet": "messages = [{\"role\": \"system\", \"content\": f'Policy: {user_input}'}]",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0861",
    "category": "LLM09: Overreliance",
    "severity": "MEDIUM",
    "confidence": 0.79,
    "description": "LLM summary emailed automatically",
    "file_path": "workflows/email_broadcast.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM09_FP_0862",
    "category": "LLM09: Overreliance",
    "severity": "LOW",
    "confidence": 0.49,
    "description": "Unit test asserting human review",
    "file_path": "decision/approver.py",
    "code_snippet": "assert pipeline.requires_human_review is True",
    "is_true_positive": false
  },
  {
    "id": "LLM09_TP_0863",
    "category": "LLM09: Overreliance",
    "severity": "HIGH",
    "confidence": 0.83,
    "description": "Auto-approves compliance decision",
    "file_path": "tests/workflows/test_review.py",
    "code_snippet": "if model.confidence > 0.2: return 'approved'",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0864",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.81,
    "description": "SQL built from LLM output (synthetic variation)",
    "file_path": "agents/code_exec.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0865",
    "category": "LLM02: Insecure Output",
    "severity": "MEDIUM",
    "confidence": 0.84,
    "description": "SQL built from LLM output",
    "file_path": "agents/code_exec.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM09_FP_0866",
    "category": "LLM09: Overreliance",
    "severity": "MEDIUM",
    "confidence": 0.71,
    "description": "Workflow requires reviewer",
    "file_path": "workflows/human_loop.py",
    "code_snippet": "if not reviewer.signoff(result): return",
    "is_true_positive": false
  },
  {
    "id": "LLM03_TP_0867",
    "category": "LLM03: Training Poisoning",
    "severity": "LOW",
    "confidence": 0.78,
    "description": "Weights loaded via pickle from user path (synthetic variation)",
    "file_path": "models/bert_wrapper.py",
    "code_snippet": "weights = pickle.load(open(model_path, 'rb'))",
    "is_true_positive": true
  },
  {
    "id": "LLM04_FP_0868",
    "category": "LLM04: Model Denial of Service",
    "severity": "HIGH",
    "confidence": 0.48,
    "description": "Pytest simulating rate limit",
    "file_path": "tests/dos/test_rate_limit.py",
    "code_snippet": "for _ in range(5): client.chat.completions.create(... )",
    "is_true_positive": false
  },
  {
    "id": "LLM06_TP_0869",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.86,
    "description": "LLM output with AWS key logged",
    "file_path": "docs/assets/logo.py",
    "code_snippet": "logger.info(f'Key leaked: {response}')",
    "is_true_positive": true
  },
  {
    "id": "LLM05_TP_0870",
    "category": "LLM05: Supply Chain",
    "severity": "CRITICAL",
    "confidence": 0.8,
    "description": "Agent executes pip install from LLM (synthetic variation)",
    "file_path": "agents/tool_executor.py",
    "code_snippet": "subprocess.run(['pip', 'install', llm_pkg], check=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0871",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.87,
    "description": "LangChain template concatenates untrusted context (synthetic variation)",
    "file_path": "examples/prompts/prompt_injection.ipynb",
    "code_snippet": "template = ChatPromptTemplate.from_messages([(\"system\", ctx + prompt)])",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0872",
    "category": "LLM09: Overreliance",
    "severity": "MEDIUM",
    "confidence": 0.77,
    "description": "Auto-approves compliance decision (synthetic variation)",
    "file_path": "workflows/email_broadcast.py",
    "code_snippet": "if model.confidence > 0.2: return 'approved'",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0873",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.42,
    "description": "Base64 image asset",
    "file_path": "config/settings.py",
    "code_snippet": "LOGO = 'data:image/png;base64,iVBORw0KGgoAAAANS...'",
    "is_true_positive": false
  },
  {
    "id": "LLM01_FP_0874",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.52,
    "description": "Example notebook demonstrates prompts",
    "file_path": "pipelines/langchain_agent.py",
    "code_snippet": "SYSTEM_PROMPT = 'Your name is {username}'",
    "is_true_positive": false
  },
  {
    "id": "LLM09_TP_0875",
    "category": "LLM09: Overreliance",
    "severity": "CRITICAL",
    "confidence": 0.92,
    "description": "Auto-approves compliance decision",
    "file_path": "tests/workflows/test_review.py",
    "code_snippet": "if model.confidence > 0.2: return 'approved'",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0876",
    "category": "LLM06: Sensitive Info",
    "severity": "CRITICAL",
    "confidence": 0.95,
    "description": "LLM output with AWS key logged",
    "file_path": "config/settings.py",
    "code_snippet": "logger.info(f'Key leaked: {response}')",
    "is_true_positive": true
  },
  {
    "id": "LLM10_FP_0877",
    "category": "LLM10: Model Theft",
    "severity": "HIGH",
    "confidence": 0.39,
    "description": "Docs describing scp export",
    "file_path": "api/secure_download.py",
    "code_snippet": "scp model.bin user@host",
    "is_true_positive": false
  },
  {
    "id": "LLM01_TP_0878",
    "category": "LLM01: Prompt Injection",
    "severity": "LOW",
    "confidence": 0.81,
    "description": "Direct f-string injection into system prompt",
    "file_path": "tests/test_prompt_injection.py",
    "code_snippet": "messages = [{\"role\": \"system\", \"content\": f'Policy: {user_input}'}]",
    "is_true_positive": true
  },
  {
    "id": "LLM08_TP_0879",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.86,
    "description": "Agent executes system command (synthetic variation)",
    "file_path": "agents/finance_agent.py",
    "code_snippet": "os.system(plan['action'])",
    "is_true_positive": true
  },
  {
    "id": "LLM05_TP_0880",
    "category": "LLM05: Supply Chain",
    "severity": "LOW",
    "confidence": 0.97,
    "description": "trust_remote_code=True on AutoModel",
    "file_path": "security/downloader.py",
    "code_snippet": "AutoModel.from_pretrained(repo, trust_remote_code=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM08_TP_0881",
    "category": "LLM08: Excessive Agency",
    "severity": "CRITICAL",
    "confidence": 0.74,
    "description": "Agent transfers funds autonomously",
    "file_path": "agents/controller.py",
    "code_snippet": "bank.transfer(amount, destination, auto_execute=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0882",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.8,
    "description": "Hardcoded OpenAI key",
    "file_path": "config/settings.py",
    "code_snippet": "os.environ['OPENAI_API_KEY'] = 'sk-live-123456789'",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0883",
    "category": "LLM09: Overreliance",
    "severity": "CRITICAL",
    "confidence": 0.78,
    "description": "LLM summary emailed automatically",
    "file_path": "tests/workflows/test_review.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM07_FP_0884",
    "category": "LLM07: Insecure Plugin",
    "severity": "HIGH",
    "confidence": 0.57,
    "description": "Docs describing plugin install (synthetic variation)",
    "file_path": "plugins/manager.py",
    "code_snippet": "Install shell plugin by running ./install.sh",
    "is_true_positive": false
  },
  {
    "id": "LLM05_TP_0885",
    "category": "LLM05: Supply Chain",
    "severity": "CRITICAL",
    "confidence": 0.72,
    "description": "Agent executes pip install from LLM",
    "file_path": "models/loader.py",
    "code_snippet": "subprocess.run(['pip', 'install', llm_pkg], check=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM05_TP_0886",
    "category": "LLM05: Supply Chain",
    "severity": "MEDIUM",
    "confidence": 0.75,
    "description": "Agent executes pip install from LLM",
    "file_path": "agents/tool_executor.py",
    "code_snippet": "subprocess.run(['pip', 'install', llm_pkg], check=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0887",
    "category": "LLM09: Overreliance",
    "severity": "CRITICAL",
    "confidence": 0.86,
    "description": "LLM summary emailed automatically",
    "file_path": "workflows/human_loop.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM01_FP_0888",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.7,
    "description": "Unit test fixture builds fake prompts",
    "file_path": "tests/test_prompt_injection.py",
    "code_snippet": "def prompt_fixture(): return f'ignore rules {seed}'",
    "is_true_positive": false
  },
  {
    "id": "LLM08_TP_0889",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.84,
    "description": "Agent executes system command",
    "file_path": "examples/autonomous_agent.md",
    "code_snippet": "os.system(plan['action'])",
    "is_true_positive": true
  },
  {
    "id": "LLM04_TP_0890",
    "category": "LLM04: Model Denial of Service",
    "severity": "LOW",
    "confidence": 0.87,
    "description": "Async gather spawns many completions",
    "file_path": "tests/dos/test_rate_limit.py",
    "code_snippet": "await asyncio.gather(*[call_llm(q) for q in queue])",
    "is_true_positive": true
  },
  {
    "id": "LLM08_FP_0891",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.65,
    "description": "Demo described in README",
    "file_path": "examples/autonomous_agent.md",
    "code_snippet": "agent.run('book a flight')",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0892",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.74,
    "description": "API exposes logprobs enabling extraction",
    "file_path": "api/completions.py",
    "code_snippet": "client.chat.completions.create(logprobs=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM03_TP_0893",
    "category": "LLM03: Training Poisoning",
    "severity": "HIGH",
    "confidence": 0.82,
    "description": "Training data pulled from unsecured URL",
    "file_path": "tests/fakes/datasets.py",
    "code_snippet": "data = json.loads(requests.get(feed).text)",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0894",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.91,
    "description": "LLM output with AWS key logged (synthetic variation)",
    "file_path": "notebooks/openai_quickstart.ipynb",
    "code_snippet": "logger.info(f'Key leaked: {response}')",
    "is_true_positive": true
  },
  {
    "id": "LLM02_FP_0895",
    "category": "LLM02: Insecure Output",
    "severity": "MEDIUM",
    "confidence": 0.66,
    "description": "SQLAlchemy session.exec mistaken for exec",
    "file_path": "app/repository.py",
    "code_snippet": "result = session.exec(select(User))",
    "is_true_positive": false
  },
  {
    "id": "LLM05_TP_0896",
    "category": "LLM05: Supply Chain",
    "severity": "HIGH",
    "confidence": 0.93,
    "description": "Agent executes pip install from LLM (synthetic variation)",
    "file_path": "models/loader.py",
    "code_snippet": "subprocess.run(['pip', 'install', llm_pkg], check=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0897",
    "category": "LLM09: Overreliance",
    "severity": "HIGH",
    "confidence": 0.96,
    "description": "LLM summary emailed automatically (synthetic variation)",
    "file_path": "tests/workflows/test_review.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM04_TP_0898",
    "category": "LLM04: Model Denial of Service",
    "severity": "LOW",
    "confidence": 0.82,
    "description": "Unbounded while loop hitting OpenAI",
    "file_path": "services/parallel_runner.py",
    "code_snippet": "while True:\n    client.chat.completions.create(... )",
    "is_true_positive": true
  },
  {
    "id": "LLM02_FP_0899",
    "category": "LLM02: Insecure Output",
    "severity": "MEDIUM",
    "confidence": 0.47,
    "description": "SQLAlchemy session.exec mistaken for exec",
    "file_path": "docs/examples/output_handling.py",
    "code_snippet": "result = session.exec(select(User))",
    "is_true_positive": false
  },
  {
    "id": "LLM08_FP_0900",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.46,
    "description": "Demo described in README",
    "file_path": "agents/task_runner.py",
    "code_snippet": "agent.run('book a flight')",
    "is_true_positive": false
  },
  {
    "id": "LLM02_TP_0901",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.74,
    "description": "LLM response executed via eval (synthetic variation)",
    "file_path": "db/auto_sql.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0902",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.92,
    "description": "LLM response executed via eval",
    "file_path": "agents/code_exec.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0903",
    "category": "LLM01: Prompt Injection",
    "severity": "CRITICAL",
    "confidence": 0.73,
    "description": "Direct f-string injection into system prompt (synthetic variation)",
    "file_path": "src/chatbot/services/conversation.py",
    "code_snippet": "messages = [{\"role\": \"system\", \"content\": f'Policy: {user_input}'}]",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0904",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.96,
    "description": "LLM response executed via eval (synthetic variation)",
    "file_path": "agents/code_exec.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM04_TP_0905",
    "category": "LLM04: Model Denial of Service",
    "severity": "LOW",
    "confidence": 0.74,
    "description": "Async gather spawns many completions",
    "file_path": "workers/auto_refiner.py",
    "code_snippet": "await asyncio.gather(*[call_llm(q) for q in queue])",
    "is_true_positive": true
  },
  {
    "id": "LLM05_FP_0906",
    "category": "LLM05: Supply Chain",
    "severity": "LOW",
    "confidence": 0.67,
    "description": "Download guarded by sha256 verification",
    "file_path": "docs/getting_started.md",
    "code_snippet": "if sha256(data).hexdigest() != expected_hash: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0907",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.85,
    "description": "Endpoint serves model weights",
    "file_path": "api/models.py",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM05_TP_0908",
    "category": "LLM05: Supply Chain",
    "severity": "MEDIUM",
    "confidence": 0.96,
    "description": "trust_remote_code=True on AutoModel",
    "file_path": "models/loader.py",
    "code_snippet": "AutoModel.from_pretrained(repo, trust_remote_code=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM08_TP_0909",
    "category": "LLM08: Excessive Agency",
    "severity": "LOW",
    "confidence": 0.75,
    "description": "Agent transfers funds autonomously",
    "file_path": "examples/autonomous_agent.md",
    "code_snippet": "bank.transfer(amount, destination, auto_execute=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM07_TP_0910",
    "category": "LLM07: Insecure Plugin",
    "severity": "LOW",
    "confidence": 0.91,
    "description": "Plugin executes shell command",
    "file_path": "docs/plugins.md",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM08_TP_0911",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.9,
    "description": "Agent transfers funds autonomously",
    "file_path": "examples/autonomous_agent.md",
    "code_snippet": "bank.transfer(amount, destination, auto_execute=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0912",
    "category": "LLM01: Prompt Injection",
    "severity": "CRITICAL",
    "confidence": 0.78,
    "description": "LangChain template concatenates untrusted context",
    "file_path": "src/chatbot/services/conversation.py",
    "code_snippet": "template = ChatPromptTemplate.from_messages([(\"system\", ctx + prompt)])",
    "is_true_positive": true
  },
  {
    "id": "LLM05_FP_0913",
    "category": "LLM05: Supply Chain",
    "severity": "HIGH",
    "confidence": 0.5,
    "description": "Download guarded by sha256 verification",
    "file_path": "agents/tool_executor.py",
    "code_snippet": "if sha256(data).hexdigest() != expected_hash: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM07_TP_0914",
    "category": "LLM07: Insecure Plugin",
    "severity": "HIGH",
    "confidence": 0.75,
    "description": "Plugin executes shell command",
    "file_path": "docs/plugins.md",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM08_FP_0915",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.59,
    "description": "Demo described in README (synthetic variation)",
    "file_path": "examples/autonomous_agent.md",
    "code_snippet": "agent.run('book a flight')",
    "is_true_positive": false
  },
  {
    "id": "LLM03_TP_0916",
    "category": "LLM03: Training Poisoning",
    "severity": "LOW",
    "confidence": 0.8,
    "description": "Training data pulled from unsecured URL (synthetic variation)",
    "file_path": "training/load_weights.py",
    "code_snippet": "data = json.loads(requests.get(feed).text)",
    "is_true_positive": true
  },
  {
    "id": "LLM04_FP_0917",
    "category": "LLM04: Model Denial of Service",
    "severity": "LOW",
    "confidence": 0.66,
    "description": "Pytest simulating rate limit",
    "file_path": "workers/auto_refiner.py",
    "code_snippet": "for _ in range(5): client.chat.completions.create(... )",
    "is_true_positive": false
  },
  {
    "id": "LLM05_FP_0918",
    "category": "LLM05: Supply Chain",
    "severity": "MEDIUM",
    "confidence": 0.53,
    "description": "Download guarded by sha256 verification",
    "file_path": "security/downloader.py",
    "code_snippet": "if sha256(data).hexdigest() != expected_hash: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM07_FP_0919",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.39,
    "description": "Docs describing plugin install (synthetic variation)",
    "file_path": "plugins/manager.py",
    "code_snippet": "Install shell plugin by running ./install.sh",
    "is_true_positive": false
  },
  {
    "id": "LLM08_TP_0920",
    "category": "LLM08: Excessive Agency",
    "severity": "LOW",
    "confidence": 0.91,
    "description": "Agent transfers funds autonomously",
    "file_path": "agents/finance_agent.py",
    "code_snippet": "bank.transfer(amount, destination, auto_execute=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM08_FP_0921",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.6,
    "description": "Manual approval required (synthetic variation)",
    "file_path": "examples/autonomous_agent.md",
    "code_snippet": "if not require_human_confirmation(task): raise",
    "is_true_positive": false
  },
  {
    "id": "LLM10_FP_0922",
    "category": "LLM10: Model Theft",
    "severity": "MEDIUM",
    "confidence": 0.42,
    "description": "Signed URL enforced",
    "file_path": "docs/model_export.md",
    "code_snippet": "return generate_signed_url('model.bin', expires=30)",
    "is_true_positive": false
  },
  {
    "id": "LLM08_TP_0923",
    "category": "LLM08: Excessive Agency",
    "severity": "LOW",
    "confidence": 0.98,
    "description": "Agent executes system command",
    "file_path": "agents/finance_agent.py",
    "code_snippet": "os.system(plan['action'])",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0924",
    "category": "LLM02: Insecure Output",
    "severity": "CRITICAL",
    "confidence": 0.83,
    "description": "SQL built from LLM output (synthetic variation)",
    "file_path": "docs/examples/output_handling.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM09_FP_0925",
    "category": "LLM09: Overreliance",
    "severity": "MEDIUM",
    "confidence": 0.51,
    "description": "Unit test asserting human review",
    "file_path": "workflows/email_broadcast.py",
    "code_snippet": "assert pipeline.requires_human_review is True",
    "is_true_positive": false
  },
  {
    "id": "LLM07_TP_0926",
    "category": "LLM07: Insecure Plugin",
    "severity": "CRITICAL",
    "confidence": 0.83,
    "description": "Plugin executes shell command",
    "file_path": "docs/plugins.md",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM09_TP_0927",
    "category": "LLM09: Overreliance",
    "severity": "CRITICAL",
    "confidence": 0.87,
    "description": "LLM summary emailed automatically",
    "file_path": "tests/workflows/test_review.py",
    "code_snippet": "send_email(llm_summary, auto_send=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM05_TP_0928",
    "category": "LLM05: Supply Chain",
    "severity": "MEDIUM",
    "confidence": 0.93,
    "description": "trust_remote_code=True on AutoModel",
    "file_path": "models/loader.py",
    "code_snippet": "AutoModel.from_pretrained(repo, trust_remote_code=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0929",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.82,
    "description": "API exposes logprobs enabling extraction",
    "file_path": "docs/model_export.md",
    "code_snippet": "client.chat.completions.create(logprobs=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM07_TP_0930",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.88,
    "description": "Plugin executes shell command",
    "file_path": "plugins/manager.py",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM02_FP_0931",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.36,
    "description": "SQLAlchemy session.exec mistaken for exec",
    "file_path": "app/repository.py",
    "code_snippet": "result = session.exec(select(User))",
    "is_true_positive": false
  },
  {
    "id": "LLM08_FP_0932",
    "category": "LLM08: Excessive Agency",
    "severity": "MEDIUM",
    "confidence": 0.36,
    "description": "Demo described in README",
    "file_path": "examples/autonomous_agent.md",
    "code_snippet": "agent.run('book a flight')",
    "is_true_positive": false
  },
  {
    "id": "LLM01_FP_0933",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.56,
    "description": "Example notebook demonstrates prompts",
    "file_path": "examples/prompts/prompt_injection.ipynb",
    "code_snippet": "SYSTEM_PROMPT = 'Your name is {username}'",
    "is_true_positive": false
  },
  {
    "id": "LLM02_FP_0934",
    "category": "LLM02: Insecure Output",
    "severity": "MEDIUM",
    "confidence": 0.54,
    "description": "SQLAlchemy session.exec mistaken for exec",
    "file_path": "app/repository.py",
    "code_snippet": "result = session.exec(select(User))",
    "is_true_positive": false
  },
  {
    "id": "LLM06_TP_0935",
    "category": "LLM06: Sensitive Info",
    "severity": "CRITICAL",
    "confidence": 0.76,
    "description": "LLM output with AWS key logged",
    "file_path": "config/settings.py",
    "code_snippet": "logger.info(f'Key leaked: {response}')",
    "is_true_positive": true
  },
  {
    "id": "LLM02_FP_0936",
    "category": "LLM02: Insecure Output",
    "severity": "MEDIUM",
    "confidence": 0.37,
    "description": "SQLAlchemy session.exec mistaken for exec",
    "file_path": "app/repository.py",
    "code_snippet": "result = session.exec(select(User))",
    "is_true_positive": false
  },
  {
    "id": "LLM07_FP_0937",
    "category": "LLM07: Insecure Plugin",
    "severity": "HIGH",
    "confidence": 0.47,
    "description": "Plugin registry enforces allowlist (synthetic variation)",
    "file_path": "plugins/shell_tool.py",
    "code_snippet": "if plugin_id not in ALLOWED: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM09_TP_0938",
    "category": "LLM09: Overreliance",
    "severity": "LOW",
    "confidence": 0.88,
    "description": "Auto-approves compliance decision",
    "file_path": "workflows/human_loop.py",
    "code_snippet": "if model.confidence > 0.2: return 'approved'",
    "is_true_positive": true
  },
  {
    "id": "LLM05_TP_0939",
    "category": "LLM05: Supply Chain",
    "severity": "CRITICAL",
    "confidence": 0.81,
    "description": "Agent executes pip install from LLM",
    "file_path": "agents/tool_executor.py",
    "code_snippet": "subprocess.run(['pip', 'install', llm_pkg], check=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM08_FP_0940",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.61,
    "description": "Manual approval required",
    "file_path": "agents/finance_agent.py",
    "code_snippet": "if not require_human_confirmation(task): raise",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0941",
    "category": "LLM10: Model Theft",
    "severity": "CRITICAL",
    "confidence": 0.96,
    "description": "API exposes logprobs enabling extraction",
    "file_path": "api/secure_download.py",
    "code_snippet": "client.chat.completions.create(logprobs=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM01_TP_0942",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.77,
    "description": "LangChain template concatenates untrusted context",
    "file_path": "examples/prompts/prompt_injection.ipynb",
    "code_snippet": "template = ChatPromptTemplate.from_messages([(\"system\", ctx + prompt)])",
    "is_true_positive": true
  },
  {
    "id": "LLM05_FP_0943",
    "category": "LLM05: Supply Chain",
    "severity": "LOW",
    "confidence": 0.58,
    "description": "Download guarded by sha256 verification",
    "file_path": "docs/getting_started.md",
    "code_snippet": "if sha256(data).hexdigest() != expected_hash: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM05_FP_0944",
    "category": "LLM05: Supply Chain",
    "severity": "HIGH",
    "confidence": 0.57,
    "description": "Docs show requirements snippet",
    "file_path": "docs/getting_started.md",
    "code_snippet": "pip install torch==2.2.1",
    "is_true_positive": false
  },
  {
    "id": "LLM02_TP_0945",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.83,
    "description": "LLM response executed via eval",
    "file_path": "db/auto_sql.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM07_TP_0946",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.78,
    "description": "Plugin executes shell command (synthetic variation)",
    "file_path": "plugins/manager.py",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM05_FP_0947",
    "category": "LLM05: Supply Chain",
    "severity": "HIGH",
    "confidence": 0.53,
    "description": "Docs show requirements snippet (synthetic variation)",
    "file_path": "models/loader.py",
    "code_snippet": "pip install torch==2.2.1",
    "is_true_positive": false
  },
  {
    "id": "LLM02_TP_0948",
    "category": "LLM02: Insecure Output",
    "severity": "CRITICAL",
    "confidence": 0.95,
    "description": "SQL built from LLM output",
    "file_path": "agents/code_exec.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0949",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.86,
    "description": "LLM response executed via eval",
    "file_path": "db/auto_sql.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0950",
    "category": "LLM02: Insecure Output",
    "severity": "LOW",
    "confidence": 0.77,
    "description": "SQL built from LLM output (synthetic variation)",
    "file_path": "docs/examples/output_handling.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0951",
    "category": "LLM06: Sensitive Info",
    "severity": "CRITICAL",
    "confidence": 0.76,
    "description": "LLM output with AWS key logged (synthetic variation)",
    "file_path": "monitoring/logging.py",
    "code_snippet": "logger.info(f'Key leaked: {response}')",
    "is_true_positive": true
  },
  {
    "id": "LLM04_FP_0952",
    "category": "LLM04: Model Denial of Service",
    "severity": "MEDIUM",
    "confidence": 0.67,
    "description": "Pytest simulating rate limit (synthetic variation)",
    "file_path": "tests/dos/test_rate_limit.py",
    "code_snippet": "for _ in range(5): client.chat.completions.create(... )",
    "is_true_positive": false
  },
  {
    "id": "LLM09_TP_0953",
    "category": "LLM09: Overreliance",
    "severity": "CRITICAL",
    "confidence": 0.83,
    "description": "Auto-approves compliance decision (synthetic variation)",
    "file_path": "workflows/human_loop.py",
    "code_snippet": "if model.confidence > 0.2: return 'approved'",
    "is_true_positive": true
  },
  {
    "id": "LLM05_FP_0954",
    "category": "LLM05: Supply Chain",
    "severity": "MEDIUM",
    "confidence": 0.61,
    "description": "Docs show requirements snippet",
    "file_path": "docs/getting_started.md",
    "code_snippet": "pip install torch==2.2.1",
    "is_true_positive": false
  },
  {
    "id": "LLM01_FP_0955",
    "category": "LLM01: Prompt Injection",
    "severity": "HIGH",
    "confidence": 0.69,
    "description": "Unit test fixture builds fake prompts",
    "file_path": "src/chatbot/services/conversation.py",
    "code_snippet": "def prompt_fixture(): return f'ignore rules {seed}'",
    "is_true_positive": false
  },
  {
    "id": "LLM05_FP_0956",
    "category": "LLM05: Supply Chain",
    "severity": "HIGH",
    "confidence": 0.4,
    "description": "Download guarded by sha256 verification",
    "file_path": "docs/getting_started.md",
    "code_snippet": "if sha256(data).hexdigest() != expected_hash: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM08_TP_0957",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.73,
    "description": "Agent executes system command",
    "file_path": "agents/controller.py",
    "code_snippet": "os.system(plan['action'])",
    "is_true_positive": true
  },
  {
    "id": "LLM04_TP_0958",
    "category": "LLM04: Model Denial of Service",
    "severity": "HIGH",
    "confidence": 0.95,
    "description": "Unbounded while loop hitting OpenAI",
    "file_path": "tests/dos/test_rate_limit.py",
    "code_snippet": "while True:\n    client.chat.completions.create(... )",
    "is_true_positive": true
  },
  {
    "id": "LLM07_FP_0959",
    "category": "LLM07: Insecure Plugin",
    "severity": "MEDIUM",
    "confidence": 0.52,
    "description": "Docs describing plugin install",
    "file_path": "plugins/shell_tool.py",
    "code_snippet": "Install shell plugin by running ./install.sh",
    "is_true_positive": false
  },
  {
    "id": "LLM06_FP_0960",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.45,
    "description": "Env var reference (synthetic variation)",
    "file_path": "monitoring/logging.py",
    "code_snippet": "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')",
    "is_true_positive": false
  },
  {
    "id": "LLM07_FP_0961",
    "category": "LLM07: Insecure Plugin",
    "severity": "HIGH",
    "confidence": 0.36,
    "description": "Docs describing plugin install (synthetic variation)",
    "file_path": "docs/plugins.md",
    "code_snippet": "Install shell plugin by running ./install.sh",
    "is_true_positive": false
  },
  {
    "id": "LLM03_FP_0962",
    "category": "LLM03: Training Poisoning",
    "severity": "MEDIUM",
    "confidence": 0.42,
    "description": "torch random_split in tests",
    "file_path": "training/data_loader.py",
    "code_snippet": "train, test = random_split(dataset, [80, 20])",
    "is_true_positive": false
  },
  {
    "id": "LLM10_TP_0963",
    "category": "LLM10: Model Theft",
    "severity": "MEDIUM",
    "confidence": 0.94,
    "description": "Endpoint serves model weights",
    "file_path": "api/completions.py",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM06_TP_0964",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.89,
    "description": "Hardcoded OpenAI key",
    "file_path": "config/settings.py",
    "code_snippet": "os.environ['OPENAI_API_KEY'] = 'sk-live-123456789'",
    "is_true_positive": true
  },
  {
    "id": "LLM05_TP_0965",
    "category": "LLM05: Supply Chain",
    "severity": "MEDIUM",
    "confidence": 0.81,
    "description": "Agent executes pip install from LLM",
    "file_path": "docs/getting_started.md",
    "code_snippet": "subprocess.run(['pip', 'install', llm_pkg], check=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0966",
    "category": "LLM10: Model Theft",
    "severity": "LOW",
    "confidence": 0.97,
    "description": "Endpoint serves model weights (synthetic variation)",
    "file_path": "api/completions.py",
    "code_snippet": "return send_file('models/primary.bin')",
    "is_true_positive": true
  },
  {
    "id": "LLM03_TP_0967",
    "category": "LLM03: Training Poisoning",
    "severity": "MEDIUM",
    "confidence": 0.72,
    "description": "Weights loaded via pickle from user path",
    "file_path": "tests/fakes/datasets.py",
    "code_snippet": "weights = pickle.load(open(model_path, 'rb'))",
    "is_true_positive": true
  },
  {
    "id": "LLM10_TP_0968",
    "category": "LLM10: Model Theft",
    "severity": "CRITICAL",
    "confidence": 0.73,
    "description": "API exposes logprobs enabling extraction",
    "file_path": "docs/model_export.md",
    "code_snippet": "client.chat.completions.create(logprobs=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM04_FP_0969",
    "category": "LLM04: Model Denial of Service",
    "severity": "HIGH",
    "confidence": 0.53,
    "description": "Pytest simulating rate limit (synthetic variation)",
    "file_path": "routes/ask.py",
    "code_snippet": "for _ in range(5): client.chat.completions.create(... )",
    "is_true_positive": false
  },
  {
    "id": "LLM04_FP_0970",
    "category": "LLM04: Model Denial of Service",
    "severity": "MEDIUM",
    "confidence": 0.42,
    "description": "Pytest simulating rate limit",
    "file_path": "services/parallel_runner.py",
    "code_snippet": "for _ in range(5): client.chat.completions.create(... )",
    "is_true_positive": false
  },
  {
    "id": "LLM01_TP_0971",
    "category": "LLM01: Prompt Injection",
    "severity": "CRITICAL",
    "confidence": 0.95,
    "description": "LangChain template concatenates untrusted context",
    "file_path": "pipelines/langchain_agent.py",
    "code_snippet": "template = ChatPromptTemplate.from_messages([(\"system\", ctx + prompt)])",
    "is_true_positive": true
  },
  {
    "id": "LLM08_TP_0972",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.97,
    "description": "Agent executes system command",
    "file_path": "agents/task_runner.py",
    "code_snippet": "os.system(plan['action'])",
    "is_true_positive": true
  },
  {
    "id": "LLM04_FP_0973",
    "category": "LLM04: Model Denial of Service",
    "severity": "LOW",
    "confidence": 0.39,
    "description": "Pytest simulating rate limit (synthetic variation)",
    "file_path": "routes/ask.py",
    "code_snippet": "for _ in range(5): client.chat.completions.create(... )",
    "is_true_positive": false
  },
  {
    "id": "LLM06_FP_0974",
    "category": "LLM06: Sensitive Info",
    "severity": "HIGH",
    "confidence": 0.7,
    "description": "Base64 image asset",
    "file_path": "config/settings.py",
    "code_snippet": "LOGO = 'data:image/png;base64,iVBORw0KGgoAAAANS...'",
    "is_true_positive": false
  },
  {
    "id": "LLM10_FP_0975",
    "category": "LLM10: Model Theft",
    "severity": "MEDIUM",
    "confidence": 0.54,
    "description": "Signed URL enforced",
    "file_path": "api/models.py",
    "code_snippet": "return generate_signed_url('model.bin', expires=30)",
    "is_true_positive": false
  },
  {
    "id": "LLM07_FP_0976",
    "category": "LLM07: Insecure Plugin",
    "severity": "HIGH",
    "confidence": 0.42,
    "description": "Plugin registry enforces allowlist (synthetic variation)",
    "file_path": "plugins/shell_tool.py",
    "code_snippet": "if plugin_id not in ALLOWED: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM08_FP_0977",
    "category": "LLM08: Excessive Agency",
    "severity": "LOW",
    "confidence": 0.47,
    "description": "Demo described in README",
    "file_path": "agents/task_runner.py",
    "code_snippet": "agent.run('book a flight')",
    "is_true_positive": false
  },
  {
    "id": "LLM03_TP_0978",
    "category": "LLM03: Training Poisoning",
    "severity": "MEDIUM",
    "confidence": 0.84,
    "description": "Weights loaded via pickle from user path",
    "file_path": "training/data_loader.py",
    "code_snippet": "weights = pickle.load(open(model_path, 'rb'))",
    "is_true_positive": true
  },
  {
    "id": "LLM05_FP_0979",
    "category": "LLM05: Supply Chain",
    "severity": "MEDIUM",
    "confidence": 0.58,
    "description": "Download guarded by sha256 verification",
    "file_path": "docs/getting_started.md",
    "code_snippet": "if sha256(data).hexdigest() != expected_hash: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM05_TP_0980",
    "category": "LLM05: Supply Chain",
    "severity": "HIGH",
    "confidence": 0.91,
    "description": "Agent executes pip install from LLM",
    "file_path": "agents/tool_executor.py",
    "code_snippet": "subprocess.run(['pip', 'install', llm_pkg], check=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM03_FP_0981",
    "category": "LLM03: Training Poisoning",
    "severity": "LOW",
    "confidence": 0.4,
    "description": "model.eval() inference mode (synthetic variation)",
    "file_path": "training/data_loader.py",
    "code_snippet": "self.model.eval()",
    "is_true_positive": false
  },
  {
    "id": "LLM01_TP_0982",
    "category": "LLM01: Prompt Injection",
    "severity": "CRITICAL",
    "confidence": 0.73,
    "description": "Direct f-string injection into system prompt",
    "file_path": "examples/prompts/prompt_injection.ipynb",
    "code_snippet": "messages = [{\"role\": \"system\", \"content\": f'Policy: {user_input}'}]",
    "is_true_positive": true
  },
  {
    "id": "LLM08_TP_0983",
    "category": "LLM08: Excessive Agency",
    "severity": "CRITICAL",
    "confidence": 0.84,
    "description": "Agent executes system command",
    "file_path": "examples/autonomous_agent.md",
    "code_snippet": "os.system(plan['action'])",
    "is_true_positive": true
  },
  {
    "id": "LLM03_TP_0984",
    "category": "LLM03: Training Poisoning",
    "severity": "HIGH",
    "confidence": 0.75,
    "description": "Training data pulled from unsecured URL (synthetic variation)",
    "file_path": "training/load_weights.py",
    "code_snippet": "data = json.loads(requests.get(feed).text)",
    "is_true_positive": true
  },
  {
    "id": "LLM09_FP_0985",
    "category": "LLM09: Overreliance",
    "severity": "HIGH",
    "confidence": 0.63,
    "description": "Workflow requires reviewer (synthetic variation)",
    "file_path": "decision/approver.py",
    "code_snippet": "if not reviewer.signoff(result): return",
    "is_true_positive": false
  },
  {
    "id": "LLM02_TP_0986",
    "category": "LLM02: Insecure Output",
    "severity": "HIGH",
    "confidence": 0.71,
    "description": "SQL built from LLM output",
    "file_path": "agents/code_exec.py",
    "code_snippet": "cursor.execute(f\"SELECT * FROM users WHERE {llm_sql}\")",
    "is_true_positive": true
  },
  {
    "id": "LLM02_TP_0987",
    "category": "LLM02: Insecure Output",
    "severity": "MEDIUM",
    "confidence": 0.71,
    "description": "LLM response executed via eval",
    "file_path": "app/repository.py",
    "code_snippet": "result = eval(llm_response['code'])",
    "is_true_positive": true
  },
  {
    "id": "LLM08_TP_0988",
    "category": "LLM08: Excessive Agency",
    "severity": "HIGH",
    "confidence": 0.97,
    "description": "Agent executes system command",
    "file_path": "agents/finance_agent.py",
    "code_snippet": "os.system(plan['action'])",
    "is_true_positive": true
  },
  {
    "id": "LLM08_TP_0989",
    "category": "LLM08: Excessive Agency",
    "severity": "LOW",
    "confidence": 0.92,
    "description": "Agent transfers funds autonomously (synthetic variation)",
    "file_path": "agents/task_runner.py",
    "code_snippet": "bank.transfer(amount, destination, auto_execute=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM01_FP_0990",
    "category": "LLM01: Prompt Injection",
    "severity": "MEDIUM",
    "confidence": 0.44,
    "description": "Example notebook demonstrates prompts (synthetic variation)",
    "file_path": "src/chatbot/services/conversation.py",
    "code_snippet": "SYSTEM_PROMPT = 'Your name is {username}'",
    "is_true_positive": false
  },
  {
    "id": "LLM07_TP_0991",
    "category": "LLM07: Insecure Plugin",
    "severity": "CRITICAL",
    "confidence": 0.92,
    "description": "Plugin executes shell command (synthetic variation)",
    "file_path": "plugins/manager.py",
    "code_snippet": "subprocess.run(llm_output, shell=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM03_TP_0992",
    "category": "LLM03: Training Poisoning",
    "severity": "HIGH",
    "confidence": 0.95,
    "description": "Weights loaded via pickle from user path",
    "file_path": "models/bert_wrapper.py",
    "code_snippet": "weights = pickle.load(open(model_path, 'rb'))",
    "is_true_positive": true
  },
  {
    "id": "LLM06_FP_0993",
    "category": "LLM06: Sensitive Info",
    "severity": "MEDIUM",
    "confidence": 0.51,
    "description": "Base64 image asset",
    "file_path": "monitoring/logging.py",
    "code_snippet": "LOGO = 'data:image/png;base64,iVBORw0KGgoAAAANS...'",
    "is_true_positive": false
  },
  {
    "id": "LLM05_FP_0994",
    "category": "LLM05: Supply Chain",
    "severity": "MEDIUM",
    "confidence": 0.65,
    "description": "Download guarded by sha256 verification",
    "file_path": "models/loader.py",
    "code_snippet": "if sha256(data).hexdigest() != expected_hash: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM07_FP_0995",
    "category": "LLM07: Insecure Plugin",
    "severity": "HIGH",
    "confidence": 0.48,
    "description": "Plugin registry enforces allowlist",
    "file_path": "plugins/shell_tool.py",
    "code_snippet": "if plugin_id not in ALLOWED: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM04_FP_0996",
    "category": "LLM04: Model Denial of Service",
    "severity": "HIGH",
    "confidence": 0.58,
    "description": "Single completion call flagged",
    "file_path": "tests/dos/test_rate_limit.py",
    "code_snippet": "client.chat.completions.create(model=MODEL, messages=msgs)",
    "is_true_positive": false
  },
  {
    "id": "LLM05_TP_0997",
    "category": "LLM05: Supply Chain",
    "severity": "HIGH",
    "confidence": 0.74,
    "description": "trust_remote_code=True on AutoModel (synthetic variation)",
    "file_path": "security/downloader.py",
    "code_snippet": "AutoModel.from_pretrained(repo, trust_remote_code=True)",
    "is_true_positive": true
  },
  {
    "id": "LLM05_FP_0998",
    "category": "LLM05: Supply Chain",
    "severity": "HIGH",
    "confidence": 0.37,
    "description": "Download guarded by sha256 verification (synthetic variation)",
    "file_path": "docs/getting_started.md",
    "code_snippet": "if sha256(data).hexdigest() != expected_hash: raise",
    "is_true_positive": false
  },
  {
    "id": "LLM01_TP_0999",
    "category": "LLM01: Prompt Injection",
    "severity": "LOW",
    "confidence": 0.83,
    "description": "LangChain template concatenates untrusted context",
    "file_path": "examples/prompts/prompt_injection.ipynb",
    "code_snippet": "template = ChatPromptTemplate.from_messages([(\"system\", ctx + prompt)])",
    "is_true_positive": true
  }
]